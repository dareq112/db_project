[2025-04-14T08:36:54.033+0000] {processor.py:186} INFO - Started process (PID=2408) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:54.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:36:54.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:54.072+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:54.272+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.272+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:spark_csv_to_parquet
[2025-04-14T08:36:54.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.282+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:spark_csv_to_parquet
[2025-04-14T08:36:54.289+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.289+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:spark_csv_to_parquet
[2025-04-14T08:36:54.301+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.300+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:spark_csv_to_parquet
[2025-04-14T08:36:54.314+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.313+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:spark_csv_to_parquet
[2025-04-14T08:36:54.321+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.321+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:spark_csv_to_parquet
[2025-04-14T08:36:54.331+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.331+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:spark_csv_to_parquet
[2025-04-14T08:36:54.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:36:54.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.360+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_csv_to_parquet
[2025-04-14T08:36:54.363+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:54.363+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:36:54.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.397 seconds
[2025-04-14T08:36:58.114+0000] {processor.py:186} INFO - Started process (PID=2413) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:58.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:36:58.118+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:58.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:58.159+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:36:58.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:58.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:36:58.186+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:36:58.186+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:36:58.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T08:37:03.206+0000] {processor.py:186} INFO - Started process (PID=2418) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:03.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:37:03.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:03.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:03.253+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:03.272+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:03.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:37:03.293+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:03.293+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:37:03.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T08:37:33.539+0000] {processor.py:186} INFO - Started process (PID=2435) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:33.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:37:33.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:33.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:33.571+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:37:33.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:33.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:37:33.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:37:33.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:37:33.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T08:38:03.781+0000] {processor.py:186} INFO - Started process (PID=2452) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:03.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:38:03.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:03.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:03.809+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:03.827+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:03.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:38:03.841+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:03.841+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:38:03.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.088 seconds
[2025-04-14T08:38:15.776+0000] {processor.py:186} INFO - Started process (PID=2469) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:15.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:38:15.781+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:15.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:15.802+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:15.800+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 25
    task_id = "submit_spark_job",
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax. Maybe you meant '==' or ':=' instead of '='?
[2025-04-14T08:38:15.802+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:15.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.059 seconds
[2025-04-14T08:38:29.977+0000] {processor.py:186} INFO - Started process (PID=2474) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:29.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:38:29.982+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:29.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:30.024+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:30.181+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:30.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:38:30.195+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:30.195+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:38:30.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.262 seconds
[2025-04-14T08:38:32.077+0000] {processor.py:186} INFO - Started process (PID=2479) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:32.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:38:32.083+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:32.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:32.121+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:38:32.143+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:32.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:38:32.180+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:38:32.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:38:32.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.167 seconds
[2025-04-14T08:39:02.599+0000] {processor.py:186} INFO - Started process (PID=2496) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:02.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:39:02.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:02.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:02.625+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:02.649+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:02.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:39:02.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:02.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:39:02.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T08:39:33.036+0000] {processor.py:186} INFO - Started process (PID=2513) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:33.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:39:33.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:33.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:33.061+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:39:33.085+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:33.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:39:33.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:39:33.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:39:33.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T08:40:03.487+0000] {processor.py:186} INFO - Started process (PID=2530) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:03.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:40:03.492+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:03.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:03.517+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:03.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:03.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:40:03.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:03.559+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:40:03.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T08:40:33.950+0000] {processor.py:186} INFO - Started process (PID=2547) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:33.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:40:33.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:33.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:33.978+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:34.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:34.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:40:34.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:34.018+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:40:34.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T08:40:53.080+0000] {processor.py:186} INFO - Started process (PID=2564) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:53.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:40:53.084+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:53.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:53.140+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:40:53.181+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:53.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:40:53.204+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:40:53.204+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:40:53.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.169 seconds
[2025-04-14T08:41:23.645+0000] {processor.py:186} INFO - Started process (PID=2581) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:23.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:41:23.649+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:23.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:23.669+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:23.697+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:23.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:41:23.711+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:23.710+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:41:23.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T08:41:53.863+0000] {processor.py:186} INFO - Started process (PID=2598) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:53.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:41:53.867+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:53.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:53.891+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:41:53.914+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:53.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:41:53.929+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:41:53.929+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:41:53.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T08:42:24.341+0000] {processor.py:186} INFO - Started process (PID=2616) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:24.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:42:24.347+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:24.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:24.375+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:24.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:24.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:42:24.430+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:24.430+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:42:24.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T08:42:54.580+0000] {processor.py:186} INFO - Started process (PID=2635) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:54.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:42:54.584+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:54.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:54.616+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:42:54.647+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:54.646+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:42:54.663+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:42:54.663+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:42:54.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T08:43:24.833+0000] {processor.py:186} INFO - Started process (PID=2652) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:24.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:43:24.837+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:24.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:24.864+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:24.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:24.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:43:24.905+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:24.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:43:24.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T08:43:55.163+0000] {processor.py:186} INFO - Started process (PID=2669) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:55.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:43:55.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:55.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:55.189+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:43:55.222+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:55.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:43:55.241+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:43:55.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:43:55.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T08:44:25.503+0000] {processor.py:186} INFO - Started process (PID=2680) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:25.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:44:25.507+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:25.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:25.529+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:25.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:25.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:44:25.581+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:25.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:44:25.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T08:44:55.666+0000] {processor.py:186} INFO - Started process (PID=2697) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:55.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:44:55.669+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:55.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:55.695+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:44:55.723+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:55.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:44:55.742+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:44:55.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:44:55.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T08:45:25.935+0000] {processor.py:186} INFO - Started process (PID=2743) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:25.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:45:25.939+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:25.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:25.961+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:25.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:25.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:45:26.010+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:26.010+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:45:26.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T08:45:56.402+0000] {processor.py:186} INFO - Started process (PID=2790) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:56.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:45:56.407+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:56.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:56.432+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:45:56.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:56.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:45:56.518+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:45:56.517+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:45:56.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.150 seconds
[2025-04-14T08:46:26.920+0000] {processor.py:186} INFO - Started process (PID=2835) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:26.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:46:26.925+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:26.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:26.952+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:26.983+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:26.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:46:27.002+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:27.002+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:46:27.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T08:46:57.393+0000] {processor.py:186} INFO - Started process (PID=2852) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:57.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:46:57.397+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:57.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:57.424+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:46:57.457+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:57.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:46:57.475+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:46:57.475+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:46:57.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T08:47:27.901+0000] {processor.py:186} INFO - Started process (PID=2869) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:27.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:47:27.907+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:27.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:27.956+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:28.013+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:28.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:47:28.048+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:28.048+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:47:28.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.184 seconds
[2025-04-14T08:47:58.272+0000] {processor.py:186} INFO - Started process (PID=2886) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:58.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:47:58.278+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:58.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:58.310+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:47:58.342+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:58.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:47:58.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:47:58.360+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:47:58.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T08:48:28.955+0000] {processor.py:186} INFO - Started process (PID=2949) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:28.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:48:28.960+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:28.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:28.985+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:29.013+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:29.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:48:29.029+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:29.029+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:48:29.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T08:48:59.224+0000] {processor.py:186} INFO - Started process (PID=3008) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:59.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:48:59.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:59.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:59.249+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:48:59.275+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:59.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:48:59.293+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:48:59.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:48:59.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T08:49:29.413+0000] {processor.py:186} INFO - Started process (PID=3067) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:49:29.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:49:29.416+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:49:29.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:49:29.451+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:49:29.484+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:49:29.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:49:29.503+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:49:29.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:49:29.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.151 seconds
[2025-04-14T08:49:59.937+0000] {processor.py:186} INFO - Started process (PID=3127) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:49:59.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:49:59.945+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:49:59.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:49:59.969+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:50:00.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:50:00.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:50:00.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:50:00.038+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:50:00.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.149 seconds
[2025-04-14T08:50:30.196+0000] {processor.py:186} INFO - Started process (PID=3186) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:50:30.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:50:30.201+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:50:30.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:50:30.224+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:50:30.252+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:50:30.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:50:30.267+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:50:30.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:50:30.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T08:51:00.661+0000] {processor.py:186} INFO - Started process (PID=3245) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:00.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:51:00.665+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:00.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:00.687+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:00.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:00.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:51:00.729+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:00.729+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:51:00.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T08:51:30.855+0000] {processor.py:186} INFO - Started process (PID=3304) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:30.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:51:30.859+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:30.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:30.883+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:51:30.907+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:30.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:51:30.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:51:30.924+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:51:30.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T08:52:01.277+0000] {processor.py:186} INFO - Started process (PID=3363) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:01.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:52:01.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:01.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:01.306+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:01.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:01.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:52:01.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:01.345+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:52:01.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T08:52:31.558+0000] {processor.py:186} INFO - Started process (PID=3422) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:31.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:52:31.562+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:31.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:31.585+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:52:31.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:31.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:52:31.623+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:52:31.623+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:52:31.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T08:53:01.822+0000] {processor.py:186} INFO - Started process (PID=3481) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:01.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:53:01.825+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:01.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:01.853+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:01.880+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:01.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:53:01.896+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:01.896+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:53:01.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T08:53:32.283+0000] {processor.py:186} INFO - Started process (PID=3541) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:32.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:53:32.287+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:32.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:32.309+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:53:32.336+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:32.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:53:32.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:53:32.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:53:32.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T08:54:02.483+0000] {processor.py:186} INFO - Started process (PID=3600) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:02.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:54:02.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:02.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:02.513+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:02.545+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:02.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:54:02.581+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:02.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:54:02.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T08:54:32.934+0000] {processor.py:186} INFO - Started process (PID=3659) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:32.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:54:32.939+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:32.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:32.959+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:54:32.987+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:32.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:54:33.005+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:54:33.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:54:33.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T08:55:03.406+0000] {processor.py:186} INFO - Started process (PID=3718) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:03.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:55:03.411+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:03.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:03.440+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:03.464+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:03.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:55:03.482+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:03.481+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:55:03.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T08:55:33.864+0000] {processor.py:186} INFO - Started process (PID=3777) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:33.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:55:33.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:33.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:33.896+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:55:33.927+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:33.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:55:33.945+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:55:33.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:55:33.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T08:56:04.359+0000] {processor.py:186} INFO - Started process (PID=3836) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:04.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:56:04.363+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:04.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:04.395+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:04.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:04.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:56:04.479+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:04.478+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:56:04.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.148 seconds
[2025-04-14T08:56:34.854+0000] {processor.py:186} INFO - Started process (PID=3853) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:34.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:56:34.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:34.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:34.879+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:56:34.902+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:34.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:56:34.919+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:56:34.919+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:56:34.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T08:57:05.001+0000] {processor.py:186} INFO - Started process (PID=3870) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:05.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:57:05.005+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:05.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:05.023+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:05.046+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:05.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:57:05.062+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:05.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:57:05.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T08:57:35.476+0000] {processor.py:186} INFO - Started process (PID=3887) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:35.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:57:35.483+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:35.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:35.511+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:57:35.543+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:35.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:57:35.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:57:35.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:57:35.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T08:58:05.953+0000] {processor.py:186} INFO - Started process (PID=3904) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:05.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:58:05.959+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:05.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:05.985+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:06.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:06.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:58:06.032+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:06.031+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:58:06.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T08:58:36.399+0000] {processor.py:186} INFO - Started process (PID=3921) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:36.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:58:36.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:36.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:36.425+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:58:36.450+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:36.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:58:36.464+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:58:36.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:58:36.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T08:59:06.575+0000] {processor.py:186} INFO - Started process (PID=3938) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:06.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:59:06.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:06.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:06.600+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:06.626+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:06.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:59:06.642+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:06.642+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:59:06.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T08:59:37.026+0000] {processor.py:186} INFO - Started process (PID=3955) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:37.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T08:59:37.032+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:37.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:37.058+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T08:59:37.088+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:37.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T08:59:37.105+0000] {logging_mixin.py:190} INFO - [2025-04-14T08:59:37.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T08:59:37.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T09:00:07.358+0000] {processor.py:186} INFO - Started process (PID=3966) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:07.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:00:07.362+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:07.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:07.383+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:07.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:07.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:00:07.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:07.425+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:00:07.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T09:00:37.791+0000] {processor.py:186} INFO - Started process (PID=3983) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:37.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:00:37.798+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:37.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:37.836+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:00:37.873+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:37.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:00:37.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:00:37.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:00:37.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.149 seconds
[2025-04-14T09:01:08.061+0000] {processor.py:186} INFO - Started process (PID=4006) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:08.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:01:08.064+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:08.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:08.095+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:08.121+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:08.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:01:08.137+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:08.137+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:01:08.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T09:01:38.522+0000] {processor.py:186} INFO - Started process (PID=4023) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:38.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:01:38.527+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:38.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:38.551+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:01:38.577+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:38.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:01:38.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:01:38.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:01:38.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T09:02:09.026+0000] {processor.py:186} INFO - Started process (PID=4040) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:09.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:02:09.032+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:09.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:09.058+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:09.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:09.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:02:09.110+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:09.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:02:09.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T09:02:39.278+0000] {processor.py:186} INFO - Started process (PID=4057) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:39.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:02:39.283+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:39.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:39.310+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:02:39.343+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:39.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:02:39.363+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:02:39.362+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:02:39.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T09:03:09.475+0000] {processor.py:186} INFO - Started process (PID=4074) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:09.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:03:09.478+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:09.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:09.504+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:09.528+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:09.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:03:09.542+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:09.542+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:03:09.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:03:39.624+0000] {processor.py:186} INFO - Started process (PID=4091) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:39.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:03:39.628+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:39.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:39.654+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:03:39.683+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:39.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:03:39.702+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:03:39.702+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:03:39.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T09:04:10.017+0000] {processor.py:186} INFO - Started process (PID=4108) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:10.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:04:10.026+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:10.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:10.083+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:10.175+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:10.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:04:10.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:10.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:04:10.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.315 seconds
[2025-04-14T09:04:40.382+0000] {processor.py:186} INFO - Started process (PID=4125) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:40.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:04:40.386+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:40.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:40.411+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:04:40.437+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:40.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:04:40.455+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:04:40.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:04:40.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T09:05:10.631+0000] {processor.py:186} INFO - Started process (PID=4142) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:10.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:05:10.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:10.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:10.659+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:10.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:10.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:05:10.700+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:10.700+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:05:10.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T09:05:40.939+0000] {processor.py:186} INFO - Started process (PID=4159) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:40.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:05:40.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:40.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:40.993+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:05:41.032+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:41.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:05:41.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:05:41.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:05:41.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.163 seconds
[2025-04-14T09:06:11.333+0000] {processor.py:186} INFO - Started process (PID=4193) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:11.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:06:11.337+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:11.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:11.360+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:11.392+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:11.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:06:11.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:11.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:06:11.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T09:06:41.842+0000] {processor.py:186} INFO - Started process (PID=4252) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:41.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:06:41.846+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:41.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:41.868+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:06:41.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:41.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:06:41.912+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:06:41.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:06:41.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T09:07:12.381+0000] {processor.py:186} INFO - Started process (PID=4311) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:12.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:07:12.385+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:12.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:12.408+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:12.432+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:12.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:07:12.447+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:12.447+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:07:12.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T09:07:42.834+0000] {processor.py:186} INFO - Started process (PID=4370) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:42.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:07:42.840+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:42.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:42.865+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:07:42.896+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:42.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:07:42.914+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:07:42.914+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:07:42.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T09:08:13.587+0000] {processor.py:186} INFO - Started process (PID=4429) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:13.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:08:13.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:13.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:13.627+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:13.661+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:13.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:08:13.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:13.680+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:08:13.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T09:08:43.780+0000] {processor.py:186} INFO - Started process (PID=4488) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:43.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:08:43.784+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:43.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:43.807+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:08:43.833+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:43.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:08:43.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:08:43.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:08:43.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T09:09:14.225+0000] {processor.py:186} INFO - Started process (PID=4547) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:14.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:09:14.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:14.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:14.250+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:14.276+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:14.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:09:14.291+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:14.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:09:14.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:09:44.585+0000] {processor.py:186} INFO - Started process (PID=4606) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:44.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:09:44.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:44.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:44.612+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:09:44.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:44.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:09:44.651+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:09:44.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:09:44.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:10:14.915+0000] {processor.py:186} INFO - Started process (PID=4665) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:14.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:10:14.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:14.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:14.952+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:14.979+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:14.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:10:14.995+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:14.995+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:10:15.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T09:10:45.158+0000] {processor.py:186} INFO - Started process (PID=4725) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:45.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:10:45.165+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:45.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:45.191+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:10:45.218+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:45.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:10:45.240+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:10:45.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:10:45.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T09:11:15.366+0000] {processor.py:186} INFO - Started process (PID=4784) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:15.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:11:15.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:15.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:15.398+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:15.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:15.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:11:15.445+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:15.445+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:11:15.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T09:11:45.708+0000] {processor.py:186} INFO - Started process (PID=4843) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:45.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:11:45.714+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:45.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:45.739+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:11:45.784+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:45.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:11:45.802+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:11:45.801+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:11:45.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.139 seconds
[2025-04-14T09:12:16.419+0000] {processor.py:186} INFO - Started process (PID=4902) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:16.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:12:16.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:16.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:16.460+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:16.500+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:16.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:12:16.528+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:16.527+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:12:16.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T09:12:47.017+0000] {processor.py:186} INFO - Started process (PID=4962) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:47.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:12:47.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:47.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:47.060+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:12:47.095+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:47.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:12:47.116+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:12:47.116+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:12:47.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.138 seconds
[2025-04-14T09:13:17.551+0000] {processor.py:186} INFO - Started process (PID=5021) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:17.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:13:17.555+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:17.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:17.578+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:17.607+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:17.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:13:17.624+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:17.623+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:13:17.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:13:47.845+0000] {processor.py:186} INFO - Started process (PID=5080) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:47.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:13:47.849+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:47.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:47.873+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:13:47.900+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:47.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:13:47.915+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:13:47.914+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:13:47.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T09:14:18.176+0000] {processor.py:186} INFO - Started process (PID=5139) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:18.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:14:18.181+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:18.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:18.212+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:18.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:18.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:14:18.265+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:18.265+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:14:18.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T09:14:48.466+0000] {processor.py:186} INFO - Started process (PID=5156) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:48.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:14:48.471+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:48.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:48.495+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:14:48.520+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:48.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:14:48.534+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:14:48.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:14:48.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T09:15:18.796+0000] {processor.py:186} INFO - Started process (PID=5171) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:18.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:15:18.800+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:18.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:18.825+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:18.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:18.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:15:18.877+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:18.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:15:18.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T09:15:49.261+0000] {processor.py:186} INFO - Started process (PID=5184) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:49.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:15:49.266+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:49.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:49.305+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:15:49.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:49.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:15:49.401+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:15:49.401+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:15:49.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.658 seconds
[2025-04-14T09:16:20.145+0000] {processor.py:186} INFO - Started process (PID=5201) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:20.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:16:20.151+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:20.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:20.177+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:20.201+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:20.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:16:20.215+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:20.215+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:16:20.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T09:16:50.694+0000] {processor.py:186} INFO - Started process (PID=5218) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:50.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:16:50.701+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:50.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:50.725+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:16:50.759+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:50.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:16:50.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:16:50.780+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:16:50.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T09:17:21.059+0000] {processor.py:186} INFO - Started process (PID=5266) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:21.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:17:21.063+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:21.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:21.087+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:21.126+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:21.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:17:21.152+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:21.151+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:17:21.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T09:17:51.623+0000] {processor.py:186} INFO - Started process (PID=5311) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:51.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:17:51.628+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:51.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:51.649+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:17:51.677+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:51.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:17:51.865+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:17:51.864+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:17:51.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.268 seconds
[2025-04-14T09:18:22.014+0000] {processor.py:186} INFO - Started process (PID=5328) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:22.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:18:22.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:22.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:22.037+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:22.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:22.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:18:22.075+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:22.074+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:18:22.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.088 seconds
[2025-04-14T09:18:52.322+0000] {processor.py:186} INFO - Started process (PID=5345) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:52.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:18:52.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:52.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:52.349+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:18:52.375+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:52.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:18:52.394+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:18:52.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:18:52.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T09:19:22.768+0000] {processor.py:186} INFO - Started process (PID=5362) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:22.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:19:22.773+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:22.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:22.798+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:22.828+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:22.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:19:22.847+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:22.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:19:22.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T09:19:53.019+0000] {processor.py:186} INFO - Started process (PID=5379) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:53.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:19:53.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:53.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:53.045+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:19:53.069+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:53.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:19:53.084+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:19:53.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:19:53.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.270 seconds
[2025-04-14T09:20:23.520+0000] {processor.py:186} INFO - Started process (PID=5396) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:23.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:20:23.524+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:23.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:23.548+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:23.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:23.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:20:23.589+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:23.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:20:23.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T09:20:53.692+0000] {processor.py:186} INFO - Started process (PID=5413) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:53.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:20:53.696+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:53.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:53.726+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:20:53.762+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:53.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:20:53.783+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:20:53.783+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:20:53.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T09:21:24.180+0000] {processor.py:186} INFO - Started process (PID=5430) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:24.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:21:24.184+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:24.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:24.206+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:24.231+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:24.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:21:24.245+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:24.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:21:24.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T09:21:54.343+0000] {processor.py:186} INFO - Started process (PID=5447) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:54.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:21:54.347+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:54.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:54.385+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:21:54.424+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:54.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:21:54.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:21:54.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:21:54.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.322 seconds
[2025-04-14T09:22:24.788+0000] {processor.py:186} INFO - Started process (PID=5464) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:24.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:22:24.793+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:24.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:24.816+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:24.842+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:24.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:22:24.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:24.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:22:24.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T09:22:55.269+0000] {processor.py:186} INFO - Started process (PID=5498) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:55.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:22:55.274+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:55.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:55.303+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:22:55.340+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:55.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:22:55.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:22:55.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:22:55.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T09:23:25.814+0000] {processor.py:186} INFO - Started process (PID=5557) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:25.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:23:25.819+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:25.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:25.847+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:25.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:25.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:23:25.917+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:25.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:23:25.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.142 seconds
[2025-04-14T09:23:56.037+0000] {processor.py:186} INFO - Started process (PID=5616) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:56.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:23:56.043+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:56.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:56.069+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:23:56.096+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:56.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:23:56.114+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:23:56.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:23:56.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.292 seconds
[2025-04-14T09:24:26.725+0000] {processor.py:186} INFO - Started process (PID=5675) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:26.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:24:26.730+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:26.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:26.757+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:26.788+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:26.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:24:26.805+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:26.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:24:26.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T09:24:57.159+0000] {processor.py:186} INFO - Started process (PID=5751) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:57.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:24:57.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:57.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:57.208+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:24:57.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:57.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:24:57.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:24:57.264+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:24:57.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T09:25:27.513+0000] {processor.py:186} INFO - Started process (PID=5810) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:27.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:25:27.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:27.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:27.541+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:27.564+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:27.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:25:27.579+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:27.578+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:25:27.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T09:25:57.946+0000] {processor.py:186} INFO - Started process (PID=5841) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:57.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:25:57.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:57.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:57.973+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:25:57.997+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:57.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:25:58.012+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:25:58.012+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:25:58.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:26:28.408+0000] {processor.py:186} INFO - Started process (PID=5858) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:28.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:26:28.413+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:28.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:28.435+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:28.463+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:28.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:26:28.478+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:28.478+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:26:28.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T09:26:58.719+0000] {processor.py:186} INFO - Started process (PID=5875) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:58.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:26:58.723+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:58.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:58.744+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:26:58.768+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:58.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:26:58.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:26:58.785+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:26:58.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T09:27:29.088+0000] {processor.py:186} INFO - Started process (PID=5892) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:29.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:27:29.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:29.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:29.114+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:29.138+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:29.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:27:29.153+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:29.153+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:27:29.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:27:59.257+0000] {processor.py:186} INFO - Started process (PID=5909) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:59.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:27:59.262+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:59.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:59.292+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:27:59.318+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:59.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:27:59.334+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:27:59.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:27:59.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.301 seconds
[2025-04-14T09:28:29.870+0000] {processor.py:186} INFO - Started process (PID=5926) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:28:29.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:28:29.874+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:28:29.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:28:29.900+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:28:29.926+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:28:29.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:28:29.943+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:28:29.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:28:29.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T09:29:00.326+0000] {processor.py:186} INFO - Started process (PID=5943) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:00.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:29:00.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:00.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:00.361+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:00.389+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:00.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:29:00.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:00.405+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:29:00.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T09:29:30.641+0000] {processor.py:186} INFO - Started process (PID=6004) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:30.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:29:30.647+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:30.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:30.675+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:29:30.706+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:30.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:29:30.726+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:29:30.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:29:30.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T09:30:01.018+0000] {processor.py:186} INFO - Started process (PID=6049) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:01.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:30:01.022+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:01.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:01.045+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:01.081+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:01.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:30:01.107+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:01.107+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:30:01.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.342 seconds
[2025-04-14T09:30:31.510+0000] {processor.py:186} INFO - Started process (PID=6060) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:31.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:30:31.514+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:31.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:31.541+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:30:31.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:31.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:30:31.802+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:30:31.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:30:31.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.329 seconds
[2025-04-14T09:31:02.224+0000] {processor.py:186} INFO - Started process (PID=6077) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:02.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:31:02.230+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:02.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:02.258+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:02.285+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:02.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:31:02.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:02.300+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:31:02.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T09:31:32.546+0000] {processor.py:186} INFO - Started process (PID=6094) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:32.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:31:32.550+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:32.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:32.578+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:31:32.614+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:32.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:31:32.632+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:31:32.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:31:32.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T09:32:03.117+0000] {processor.py:186} INFO - Started process (PID=6111) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:03.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:32:03.123+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:03.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:03.159+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:03.193+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:03.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:32:03.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:03.211+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:32:03.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T09:32:33.352+0000] {processor.py:186} INFO - Started process (PID=6128) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:33.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:32:33.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:33.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:33.380+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:32:33.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:33.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:32:33.595+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:32:33.595+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:32:33.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.275 seconds
[2025-04-14T09:33:03.823+0000] {processor.py:186} INFO - Started process (PID=6145) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:03.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:33:03.827+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:03.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:03.860+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:03.887+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:03.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:33:03.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:03.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:33:03.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T09:33:34.291+0000] {processor.py:186} INFO - Started process (PID=6162) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:34.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:33:34.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:34.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:34.322+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:33:34.353+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:34.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:33:34.373+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:33:34.372+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:33:34.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T09:34:04.605+0000] {processor.py:186} INFO - Started process (PID=6179) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:04.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:34:04.610+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:04.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:04.635+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:04.661+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:04.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:34:04.677+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:04.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:34:04.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T09:34:34.811+0000] {processor.py:186} INFO - Started process (PID=6196) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:34.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:34:34.815+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:34.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:34.839+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:34:34.866+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:34.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:34:34.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:34:34.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:34:35.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.308 seconds
[2025-04-14T09:35:05.355+0000] {processor.py:186} INFO - Started process (PID=6213) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:05.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:35:05.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:05.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:05.387+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:05.576+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:05.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:35:05.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:05.590+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:35:05.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.263 seconds
[2025-04-14T09:35:36.007+0000] {processor.py:186} INFO - Started process (PID=6230) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:36.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:35:36.011+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:36.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:36.035+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:35:36.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:36.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:35:36.077+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:35:36.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:35:36.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T09:36:06.540+0000] {processor.py:186} INFO - Started process (PID=6247) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:06.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:36:06.546+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:06.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:06.573+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:06.610+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:06.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:36:06.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:06.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:36:06.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T09:36:36.884+0000] {processor.py:186} INFO - Started process (PID=6264) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:36.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:36:36.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:36.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:36.916+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:36:36.955+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:36.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:36:36.977+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:36:36.976+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:36:37.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.342 seconds
[2025-04-14T09:37:07.585+0000] {processor.py:186} INFO - Started process (PID=6281) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:07.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:37:07.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:07.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:07.613+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:07.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:07.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:37:07.819+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:07.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:37:07.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.272 seconds
[2025-04-14T09:37:37.934+0000] {processor.py:186} INFO - Started process (PID=6315) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:37.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:37:37.939+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:37.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:39.554+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:37:40.075+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:40.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:37:40.323+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:37:40.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:37:40.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 2.422 seconds
[2025-04-14T09:38:10.601+0000] {processor.py:186} INFO - Started process (PID=6374) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:10.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:38:10.607+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:10.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:10.644+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:10.677+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:10.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:38:10.697+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:10.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:38:10.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.145 seconds
[2025-04-14T09:38:40.856+0000] {processor.py:186} INFO - Started process (PID=6391) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:40.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:38:40.863+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:40.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:40.907+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:38:40.949+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:40.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:38:40.985+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:38:40.984+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:38:41.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.194 seconds
[2025-04-14T09:39:11.348+0000] {processor.py:186} INFO - Started process (PID=6454) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:11.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:39:11.355+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:11.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:11.384+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:11.416+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:11.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:39:11.434+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:11.434+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:39:11.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T09:39:42.056+0000] {processor.py:186} INFO - Started process (PID=6499) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:42.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:39:42.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:42.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:42.083+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:39:42.109+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:42.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:39:42.125+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:39:42.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:39:42.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:40:12.613+0000] {processor.py:186} INFO - Started process (PID=6516) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:12.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:40:12.616+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:12.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:12.640+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:12.665+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:12.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:40:12.681+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:12.681+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:40:12.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:40:43.072+0000] {processor.py:186} INFO - Started process (PID=6533) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:43.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:40:43.075+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:43.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:43.096+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:40:43.120+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:43.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:40:43.134+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:40:43.133+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:40:43.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T09:41:13.566+0000] {processor.py:186} INFO - Started process (PID=6550) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:13.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:41:13.577+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:13.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:13.609+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:13.650+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:13.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:41:13.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:13.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:41:13.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.181 seconds
[2025-04-14T09:41:43.812+0000] {processor.py:186} INFO - Started process (PID=6567) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:43.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:41:43.818+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:43.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:43.853+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:41:43.890+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:43.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:41:43.908+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:41:43.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:41:43.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T09:42:14.379+0000] {processor.py:186} INFO - Started process (PID=6584) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:14.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:42:14.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:14.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:14.408+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:14.435+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:14.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:42:14.451+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:14.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:42:14.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:42:44.585+0000] {processor.py:186} INFO - Started process (PID=6601) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:44.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:42:44.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:44.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:44.613+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:42:44.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:44.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:42:44.651+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:42:44.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:42:44.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:43:15.061+0000] {processor.py:186} INFO - Started process (PID=6624) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:15.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:43:15.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:15.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:15.090+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:15.119+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:15.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:43:15.136+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:15.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:43:15.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T09:43:45.550+0000] {processor.py:186} INFO - Started process (PID=6641) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:45.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:43:45.555+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:45.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:45.580+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:43:45.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:45.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:43:45.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:43:45.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:43:45.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T09:44:16.037+0000] {processor.py:186} INFO - Started process (PID=6658) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:16.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:44:16.041+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:16.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:16.065+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:16.090+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:16.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:44:16.105+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:16.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:44:16.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T09:44:46.254+0000] {processor.py:186} INFO - Started process (PID=6676) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:46.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:44:46.261+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:46.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:46.299+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:44:46.337+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:46.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:44:46.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:44:46.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:44:46.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T09:45:16.685+0000] {processor.py:186} INFO - Started process (PID=6693) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:16.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:45:16.691+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:16.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:16.720+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:16.761+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:16.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:45:16.787+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:16.786+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:45:16.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.154 seconds
[2025-04-14T09:45:47.225+0000] {processor.py:186} INFO - Started process (PID=6710) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:47.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:45:47.230+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:47.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:47.256+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:45:47.285+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:47.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:45:47.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:45:47.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:45:47.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T09:46:17.442+0000] {processor.py:186} INFO - Started process (PID=6727) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:17.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:46:17.447+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:17.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:17.479+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:17.534+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:17.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:46:17.598+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:17.597+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:46:17.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.222 seconds
[2025-04-14T09:46:48.094+0000] {processor.py:186} INFO - Started process (PID=6744) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:48.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:46:48.098+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:48.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:48.122+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:46:48.148+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:48.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:46:48.164+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:46:48.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:46:48.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:47:18.579+0000] {processor.py:186} INFO - Started process (PID=6761) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:18.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:47:18.586+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:18.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:18.609+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:18.637+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:18.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:47:18.653+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:18.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:47:18.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T09:47:49.039+0000] {processor.py:186} INFO - Started process (PID=6778) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:49.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:47:49.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:49.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:49.067+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:47:49.093+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:49.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:47:49.108+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:47:49.108+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:47:49.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:48:19.490+0000] {processor.py:186} INFO - Started process (PID=6795) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:19.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:48:19.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:19.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:19.519+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:19.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:19.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:48:19.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:19.559+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:48:19.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T09:48:49.936+0000] {processor.py:186} INFO - Started process (PID=6812) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:49.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:48:49.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:49.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:49.962+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:48:49.995+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:49.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:48:50.011+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:48:50.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:48:50.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T09:49:20.363+0000] {processor.py:186} INFO - Started process (PID=6829) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:20.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:49:20.368+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:20.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:20.395+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:20.422+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:20.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:49:20.437+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:20.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:49:20.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:49:50.791+0000] {processor.py:186} INFO - Started process (PID=6846) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:50.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:49:50.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:50.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:50.818+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:49:50.846+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:50.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:49:50.863+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:49:50.863+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:49:50.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:50:21.246+0000] {processor.py:186} INFO - Started process (PID=6863) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:21.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:50:21.250+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:21.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:21.276+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:21.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:21.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:50:21.318+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:21.318+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:50:21.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T09:50:51.696+0000] {processor.py:186} INFO - Started process (PID=6880) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:51.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:50:51.701+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:51.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:51.727+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:50:51.753+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:51.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:50:51.770+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:50:51.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:50:51.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T09:51:22.011+0000] {processor.py:186} INFO - Started process (PID=6891) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:22.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:51:22.015+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:22.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:22.038+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:22.065+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:22.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:51:22.082+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:22.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:51:22.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T09:51:52.447+0000] {processor.py:186} INFO - Started process (PID=6908) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:52.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:51:52.451+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:52.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:52.475+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:51:52.499+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:52.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:51:52.514+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:51:52.514+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:51:52.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:52:22.947+0000] {processor.py:186} INFO - Started process (PID=6926) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:22.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:52:22.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:22.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:22.975+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:22.999+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:22.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:52:23.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:23.014+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:52:23.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T09:52:53.398+0000] {processor.py:186} INFO - Started process (PID=6943) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:53.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:52:53.402+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:53.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:53.423+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:52:53.447+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:53.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:52:53.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:52:53.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:52:53.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T09:53:23.854+0000] {processor.py:186} INFO - Started process (PID=6960) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:23.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:53:23.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:23.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:23.880+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:23.904+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:23.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:53:23.919+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:23.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:53:23.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T09:53:54.302+0000] {processor.py:186} INFO - Started process (PID=6977) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:54.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:53:54.305+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:54.305+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:54.327+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:53:54.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:54.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:53:54.366+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:53:54.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:53:54.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T09:54:24.738+0000] {processor.py:186} INFO - Started process (PID=6994) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:24.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:54:24.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:24.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:24.764+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:24.788+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:24.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:54:24.803+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:24.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:54:24.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T09:54:55.183+0000] {processor.py:186} INFO - Started process (PID=7011) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:55.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:54:55.186+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:55.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:55.210+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:54:55.234+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:55.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:54:55.249+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:54:55.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:54:55.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:55:25.638+0000] {processor.py:186} INFO - Started process (PID=7028) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:25.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:55:25.642+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:25.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:25.666+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:25.690+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:25.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:55:25.704+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:25.704+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:55:25.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T09:55:56.079+0000] {processor.py:186} INFO - Started process (PID=7045) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:56.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:55:56.083+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:56.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:56.104+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:55:56.129+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:56.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:55:56.145+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:55:56.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:55:56.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T09:56:26.536+0000] {processor.py:186} INFO - Started process (PID=7062) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:26.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:56:26.541+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:26.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:26.567+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:26.592+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:26.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:56:26.606+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:26.606+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:56:26.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T09:56:57.090+0000] {processor.py:186} INFO - Started process (PID=7079) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:57.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:56:57.093+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:57.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:57.142+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:56:57.165+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:57.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:56:57.180+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:56:57.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:56:57.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T09:57:27.553+0000] {processor.py:186} INFO - Started process (PID=7096) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:27.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:57:27.557+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:27.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:27.579+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:27.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:27.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:57:27.618+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:27.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:57:27.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T09:57:57.995+0000] {processor.py:186} INFO - Started process (PID=7113) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:57.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:57:57.999+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:57.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:58.019+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:57:58.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:58.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:57:58.058+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:57:58.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:57:58.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T09:58:28.430+0000] {processor.py:186} INFO - Started process (PID=7130) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:28.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:58:28.434+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:28.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:28.458+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:28.486+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:28.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:58:28.500+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:28.500+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:58:28.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:58:58.879+0000] {processor.py:186} INFO - Started process (PID=7147) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:58.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:58:58.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:58.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:58.908+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:58:58.933+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:58.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:58:58.947+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:58:58.947+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:58:58.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T09:59:29.337+0000] {processor.py:186} INFO - Started process (PID=7164) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:29.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:59:29.341+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:29.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:29.365+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:29.390+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:29.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:59:29.406+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:29.406+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:59:29.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T09:59:59.786+0000] {processor.py:186} INFO - Started process (PID=7181) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:59.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T09:59:59.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:59.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:59.812+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T09:59:59.836+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:59.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T09:59:59.849+0000] {logging_mixin.py:190} INFO - [2025-04-14T09:59:59.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T09:59:59.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:00:30.232+0000] {processor.py:186} INFO - Started process (PID=7198) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:00:30.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:00:30.236+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:00:30.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:00:30.258+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:00:30.281+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:00:30.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:00:30.295+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:00:30.295+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:00:30.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:01:00.674+0000] {processor.py:186} INFO - Started process (PID=7215) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:00.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:01:00.678+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:00.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:00.698+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:00.722+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:00.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:01:00.736+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:00.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:01:00.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:01:31.113+0000] {processor.py:186} INFO - Started process (PID=7232) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:31.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:01:31.117+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:31.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:31.138+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:01:31.161+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:31.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:01:31.176+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:01:31.176+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:01:31.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:02:01.617+0000] {processor.py:186} INFO - Started process (PID=7249) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:01.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:02:01.622+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:01.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:01.642+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:01.672+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:01.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:02:01.686+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:01.686+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:02:01.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:02:32.063+0000] {processor.py:186} INFO - Started process (PID=7266) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:32.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:02:32.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:32.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:32.090+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:02:32.114+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:32.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:02:32.129+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:02:32.129+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:02:32.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:03:02.509+0000] {processor.py:186} INFO - Started process (PID=7283) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:02.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:03:02.514+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:02.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:02.536+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:02.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:02.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:03:02.575+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:02.575+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:03:02.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:03:32.964+0000] {processor.py:186} INFO - Started process (PID=7300) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:32.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:03:32.968+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:32.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:32.991+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:03:33.020+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:33.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:03:33.035+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:03:33.035+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:03:33.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:04:03.394+0000] {processor.py:186} INFO - Started process (PID=7317) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:03.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:04:03.398+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:03.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:03.418+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:03.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:03.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:04:03.456+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:03.456+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:04:03.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T10:04:33.828+0000] {processor.py:186} INFO - Started process (PID=7334) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:33.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:04:33.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:33.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:33.854+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:04:33.877+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:33.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:04:33.892+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:04:33.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:04:33.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:05:04.257+0000] {processor.py:186} INFO - Started process (PID=7351) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:04.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:05:04.261+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:04.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:04.282+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:04.307+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:04.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:05:04.322+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:04.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:05:04.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:05:34.679+0000] {processor.py:186} INFO - Started process (PID=7368) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:34.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:05:34.683+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:34.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:34.702+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:05:34.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:34.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:05:34.744+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:05:34.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:05:34.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:06:05.107+0000] {processor.py:186} INFO - Started process (PID=7385) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:05.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:06:05.111+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:05.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:05.133+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:05.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:05.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:06:05.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:05.172+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:06:05.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:06:35.544+0000] {processor.py:186} INFO - Started process (PID=7402) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:35.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:06:35.548+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:35.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:35.571+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:06:35.597+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:35.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:06:35.613+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:06:35.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:06:35.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T10:07:06.073+0000] {processor.py:186} INFO - Started process (PID=7419) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:06.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:07:06.079+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:06.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:06.100+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:06.125+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:06.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:07:06.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:06.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:07:06.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:07:36.505+0000] {processor.py:186} INFO - Started process (PID=7436) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:36.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:07:36.509+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:36.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:36.529+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:07:36.553+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:36.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:07:36.567+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:07:36.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:07:36.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.089 seconds
[2025-04-14T10:08:06.938+0000] {processor.py:186} INFO - Started process (PID=7453) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:06.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:08:06.942+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:06.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:06.967+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:06.991+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:06.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:08:07.006+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:07.005+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:08:07.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:08:37.374+0000] {processor.py:186} INFO - Started process (PID=7470) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:37.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:08:37.377+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:37.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:37.399+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:08:37.429+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:37.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:08:37.445+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:08:37.445+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:08:37.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:09:07.822+0000] {processor.py:186} INFO - Started process (PID=7487) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:07.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:09:07.825+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:07.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:07.848+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:07.872+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:07.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:09:07.887+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:07.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:09:07.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:09:38.268+0000] {processor.py:186} INFO - Started process (PID=7504) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:38.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:09:38.271+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:38.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:38.292+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:09:38.316+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:38.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:09:38.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:09:38.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:09:38.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T10:10:08.712+0000] {processor.py:186} INFO - Started process (PID=7521) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:08.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:10:08.716+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:08.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:08.738+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:08.762+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:08.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:10:08.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:08.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:10:08.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:10:39.143+0000] {processor.py:186} INFO - Started process (PID=7538) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:39.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:10:39.146+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:39.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:39.167+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:10:39.195+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:39.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:10:39.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:10:39.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:10:39.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:11:09.570+0000] {processor.py:186} INFO - Started process (PID=7555) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:09.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:11:09.574+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:09.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:09.596+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:09.621+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:09.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:11:09.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:09.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:11:09.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:11:40.005+0000] {processor.py:186} INFO - Started process (PID=7572) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:40.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:11:40.011+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:40.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:40.031+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:11:40.055+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:40.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:11:40.071+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:11:40.071+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:11:40.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:12:10.421+0000] {processor.py:186} INFO - Started process (PID=7589) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:10.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:12:10.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:10.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:10.449+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:10.473+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:10.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:12:10.489+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:10.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:12:10.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:12:40.824+0000] {processor.py:186} INFO - Started process (PID=7606) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:40.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:12:40.829+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:40.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:40.851+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:12:40.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:40.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:12:40.891+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:12:40.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:12:40.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:13:11.244+0000] {processor.py:186} INFO - Started process (PID=7623) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:11.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:13:11.247+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:11.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:11.272+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:11.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:11.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:13:11.312+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:11.311+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:13:11.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:13:41.676+0000] {processor.py:186} INFO - Started process (PID=7640) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:41.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:13:41.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:41.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:41.702+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:13:41.725+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:41.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:13:41.740+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:13:41.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:13:41.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:14:12.100+0000] {processor.py:186} INFO - Started process (PID=7657) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:12.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:14:12.103+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:12.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:12.127+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:12.153+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:12.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:14:12.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:12.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:14:12.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T10:14:42.537+0000] {processor.py:186} INFO - Started process (PID=7674) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:42.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:14:42.541+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:42.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:42.562+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:14:42.588+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:42.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:14:42.604+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:14:42.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:14:42.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:15:12.975+0000] {processor.py:186} INFO - Started process (PID=7691) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:12.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:15:12.979+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:12.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:12.999+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:13.024+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:13.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:15:13.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:13.038+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:15:13.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:15:43.396+0000] {processor.py:186} INFO - Started process (PID=7708) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:43.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:15:43.399+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:43.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:43.421+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:15:43.444+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:43.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:15:43.459+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:15:43.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:15:43.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:16:13.707+0000] {processor.py:186} INFO - Started process (PID=7719) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:13.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:16:13.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:13.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:13.740+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:13.768+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:13.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:16:13.787+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:13.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:16:13.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T10:16:44.165+0000] {processor.py:186} INFO - Started process (PID=7736) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:44.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:16:44.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:44.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:44.194+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:16:44.218+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:44.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:16:44.233+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:16:44.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:16:44.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:17:14.695+0000] {processor.py:186} INFO - Started process (PID=7753) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:14.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:17:14.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:14.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:14.721+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:14.746+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:14.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:17:14.760+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:14.760+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:17:14.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:17:45.145+0000] {processor.py:186} INFO - Started process (PID=7770) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:45.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:17:45.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:45.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:45.171+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:17:45.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:45.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:17:45.209+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:17:45.209+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:17:45.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:18:15.576+0000] {processor.py:186} INFO - Started process (PID=7787) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:15.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:18:15.580+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:15.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:15.604+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:15.629+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:15.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:18:15.645+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:15.645+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:18:15.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T10:18:46.038+0000] {processor.py:186} INFO - Started process (PID=7804) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:46.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:18:46.042+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:46.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:46.065+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:18:46.089+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:46.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:18:46.103+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:18:46.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:18:46.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:19:16.487+0000] {processor.py:186} INFO - Started process (PID=7821) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:16.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:19:16.490+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:16.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:16.514+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:16.540+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:16.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:19:16.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:16.553+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:19:16.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:19:46.932+0000] {processor.py:186} INFO - Started process (PID=7838) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:46.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:19:46.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:46.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:46.960+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:19:46.984+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:46.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:19:46.998+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:19:46.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:19:47.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:20:17.378+0000] {processor.py:186} INFO - Started process (PID=7854) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:17.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:20:17.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:17.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:17.403+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:17.428+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:17.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:20:17.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:17.443+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:20:17.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:20:47.825+0000] {processor.py:186} INFO - Started process (PID=7871) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:47.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:20:47.829+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:47.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:47.852+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:20:47.879+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:47.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:20:47.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:20:47.895+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:20:47.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:21:18.280+0000] {processor.py:186} INFO - Started process (PID=7888) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:18.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:21:18.284+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:18.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:18.305+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:18.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:18.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:21:18.343+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:18.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:21:18.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:21:48.715+0000] {processor.py:186} INFO - Started process (PID=7905) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:48.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:21:48.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:48.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:48.743+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:21:48.767+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:48.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:21:48.782+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:21:48.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:21:48.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:22:19.149+0000] {processor.py:186} INFO - Started process (PID=7922) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:19.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:22:19.153+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:19.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:19.175+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:19.198+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:19.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:22:19.212+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:19.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:22:19.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:22:49.582+0000] {processor.py:186} INFO - Started process (PID=7939) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:49.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:22:49.587+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:49.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:49.612+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:22:49.640+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:49.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:22:49.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:22:49.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:22:49.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T10:23:20.026+0000] {processor.py:186} INFO - Started process (PID=7957) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:20.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:23:20.030+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:20.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:20.052+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:20.076+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:20.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:23:20.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:20.091+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:23:20.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:23:50.475+0000] {processor.py:186} INFO - Started process (PID=7980) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:50.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:23:50.479+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:50.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:50.500+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:23:50.525+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:50.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:23:50.540+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:23:50.539+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:23:50.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:24:20.921+0000] {processor.py:186} INFO - Started process (PID=7997) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:20.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:24:20.925+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:20.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:20.949+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:20.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:20.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:24:20.990+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:20.990+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:24:21.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:24:51.370+0000] {processor.py:186} INFO - Started process (PID=8014) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:51.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:24:51.374+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:51.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:51.397+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:24:51.421+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:51.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:24:51.435+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:24:51.435+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:24:51.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:25:21.827+0000] {processor.py:186} INFO - Started process (PID=8031) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:21.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:25:21.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:21.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:21.859+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:21.887+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:21.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:25:21.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:21.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:25:21.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T10:25:52.312+0000] {processor.py:186} INFO - Started process (PID=8048) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:52.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:25:52.317+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:52.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:52.338+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:25:52.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:52.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:25:52.376+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:25:52.375+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:25:52.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:26:22.755+0000] {processor.py:186} INFO - Started process (PID=8065) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:22.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:26:22.759+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:22.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:22.778+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:22.802+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:22.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:26:22.816+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:22.816+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:26:22.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.089 seconds
[2025-04-14T10:26:53.185+0000] {processor.py:186} INFO - Started process (PID=8082) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:53.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:26:53.188+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:53.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:53.219+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:26:53.244+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:53.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:26:53.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:26:53.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:26:53.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T10:27:23.626+0000] {processor.py:186} INFO - Started process (PID=8099) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:23.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:27:23.631+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:23.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:23.657+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:23.684+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:23.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:27:23.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:23.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:27:23.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:27:54.077+0000] {processor.py:186} INFO - Started process (PID=8116) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:54.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:27:54.080+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:54.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:54.098+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:27:54.123+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:54.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:27:54.138+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:27:54.138+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:27:54.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T10:28:24.513+0000] {processor.py:186} INFO - Started process (PID=8133) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:24.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:28:24.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:24.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:24.539+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:24.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:24.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:28:24.579+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:24.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:28:24.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:28:54.946+0000] {processor.py:186} INFO - Started process (PID=8150) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:54.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:28:54.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:54.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:54.976+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:28:55.000+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:55.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:28:55.015+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:28:55.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:28:55.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:29:25.388+0000] {processor.py:186} INFO - Started process (PID=8167) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:25.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:29:25.392+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:25.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:25.415+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:25.439+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:25.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:29:25.454+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:25.454+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:29:25.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:29:55.830+0000] {processor.py:186} INFO - Started process (PID=8184) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:55.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:29:55.834+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:55.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:55.856+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:29:55.880+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:55.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:29:55.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:29:55.895+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:29:55.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:30:26.267+0000] {processor.py:186} INFO - Started process (PID=8201) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:26.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:30:26.270+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:26.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:26.291+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:26.315+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:26.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:30:26.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:26.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:30:26.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:30:56.698+0000] {processor.py:186} INFO - Started process (PID=8218) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:56.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:30:56.702+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:56.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:56.729+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:30:56.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:56.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:30:56.769+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:30:56.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:30:56.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:31:27.133+0000] {processor.py:186} INFO - Started process (PID=8235) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:27.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:31:27.137+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:27.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:27.160+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:27.187+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:27.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:31:27.201+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:27.201+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:31:27.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:31:57.574+0000] {processor.py:186} INFO - Started process (PID=8252) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:57.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:31:57.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:57.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:57.599+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:31:57.623+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:57.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:31:57.638+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:31:57.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:31:57.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:32:28.013+0000] {processor.py:186} INFO - Started process (PID=8269) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:28.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:32:28.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:28.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:28.041+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:28.064+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:28.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:32:28.080+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:28.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:32:28.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:32:58.450+0000] {processor.py:186} INFO - Started process (PID=8286) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:58.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:32:58.454+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:58.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:58.479+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:32:58.505+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:58.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:32:58.522+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:32:58.522+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:32:58.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T10:33:28.906+0000] {processor.py:186} INFO - Started process (PID=8303) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:28.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:33:28.910+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:28.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:28.932+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:28.956+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:28.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:33:28.973+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:28.972+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:33:29.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T10:33:59.363+0000] {processor.py:186} INFO - Started process (PID=8320) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:59.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:33:59.367+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:59.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:59.392+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:33:59.417+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:59.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:33:59.433+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:33:59.433+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:33:59.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:34:29.813+0000] {processor.py:186} INFO - Started process (PID=8337) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:34:29.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:34:29.817+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:34:29.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:34:29.837+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:34:29.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:34:29.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:34:29.876+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:34:29.876+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:34:29.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:35:00.254+0000] {processor.py:186} INFO - Started process (PID=8354) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:00.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:35:00.289+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:00.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:00.332+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:00.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:00.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:35:00.372+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:00.372+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:35:00.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T10:35:30.749+0000] {processor.py:186} INFO - Started process (PID=8371) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:30.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:35:30.754+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:30.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:30.781+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:35:30.805+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:30.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:35:30.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:35:30.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:35:30.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:36:01.192+0000] {processor.py:186} INFO - Started process (PID=8388) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:01.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:36:01.197+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:01.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:01.220+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:01.274+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:01.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:36:01.304+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:01.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:36:01.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.147 seconds
[2025-04-14T10:36:31.682+0000] {processor.py:186} INFO - Started process (PID=8405) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:31.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:36:31.686+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:31.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:31.708+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:36:31.733+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:31.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:36:31.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:36:31.747+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:36:31.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:37:02.197+0000] {processor.py:186} INFO - Started process (PID=8422) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:02.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:37:02.201+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:02.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:02.223+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:02.248+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:02.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:37:02.263+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:02.263+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:37:02.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:37:32.638+0000] {processor.py:186} INFO - Started process (PID=8439) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:32.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:37:32.642+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:32.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:32.666+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:37:32.690+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:32.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:37:32.706+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:37:32.706+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:37:32.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:38:03.077+0000] {processor.py:186} INFO - Started process (PID=8456) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:03.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:38:03.082+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:03.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:03.103+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:03.127+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:03.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:38:03.143+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:03.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:38:03.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:38:33.504+0000] {processor.py:186} INFO - Started process (PID=8473) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:33.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:38:33.507+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:33.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:33.527+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:38:33.552+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:33.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:38:33.569+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:38:33.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:38:33.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:39:03.939+0000] {processor.py:186} INFO - Started process (PID=8490) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:03.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:39:03.943+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:03.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:03.964+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:03.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:03.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:39:04.008+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:04.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:39:04.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:39:34.362+0000] {processor.py:186} INFO - Started process (PID=8507) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:34.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:39:34.366+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:34.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:34.389+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:39:34.415+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:34.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:39:34.429+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:39:34.429+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:39:34.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:40:04.795+0000] {processor.py:186} INFO - Started process (PID=8524) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:04.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:40:04.799+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:04.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:04.822+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:04.846+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:04.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:40:04.863+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:04.863+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:40:04.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:40:35.214+0000] {processor.py:186} INFO - Started process (PID=8541) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:35.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:40:35.218+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:35.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:35.242+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:40:35.266+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:35.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:40:35.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:40:35.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:40:35.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:41:05.535+0000] {processor.py:186} INFO - Started process (PID=8552) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:05.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:41:05.540+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:05.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:05.561+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:05.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:05.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:41:05.610+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:05.610+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:41:05.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T10:41:35.987+0000] {processor.py:186} INFO - Started process (PID=8569) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:35.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:41:35.991+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:35.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:36.015+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:41:36.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:36.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:41:36.054+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:41:36.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:41:36.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:42:06.509+0000] {processor.py:186} INFO - Started process (PID=8586) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:06.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:42:06.513+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:06.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:06.535+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:06.558+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:06.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:42:06.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:06.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:42:06.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:42:36.959+0000] {processor.py:186} INFO - Started process (PID=8603) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:36.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:42:36.963+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:36.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:36.986+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:42:37.010+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:37.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:42:37.025+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:42:37.024+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:42:37.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:43:07.398+0000] {processor.py:186} INFO - Started process (PID=8620) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:07.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:43:07.402+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:07.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:07.426+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:07.451+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:07.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:43:07.466+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:07.465+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:43:07.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:43:37.852+0000] {processor.py:186} INFO - Started process (PID=8637) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:37.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:43:37.856+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:37.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:37.878+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:43:37.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:37.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:43:37.919+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:43:37.919+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:43:37.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:44:08.292+0000] {processor.py:186} INFO - Started process (PID=8654) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:08.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:44:08.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:08.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:08.319+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:08.343+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:08.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:44:08.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:08.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:44:08.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:44:38.739+0000] {processor.py:186} INFO - Started process (PID=8671) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:38.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:44:38.743+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:38.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:38.764+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:44:38.789+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:38.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:44:38.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:44:38.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:44:38.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:45:09.191+0000] {processor.py:186} INFO - Started process (PID=8688) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:09.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:45:09.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:09.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:09.219+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:09.243+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:09.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:45:09.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:09.257+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:45:09.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:45:39.631+0000] {processor.py:186} INFO - Started process (PID=8705) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:39.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:45:39.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:39.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:39.655+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:45:39.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:39.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:45:39.696+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:45:39.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:45:39.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:46:10.062+0000] {processor.py:186} INFO - Started process (PID=8722) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:10.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:46:10.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:10.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:10.095+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:10.119+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:10.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:46:10.133+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:10.133+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:46:10.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:46:40.505+0000] {processor.py:186} INFO - Started process (PID=8739) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:40.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:46:40.509+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:40.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:40.530+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:46:40.555+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:40.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:46:40.569+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:46:40.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:46:40.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:47:10.950+0000] {processor.py:186} INFO - Started process (PID=8756) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:10.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:47:10.953+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:10.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:10.975+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:10.999+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:10.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:47:11.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:11.014+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:47:11.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:47:41.378+0000] {processor.py:186} INFO - Started process (PID=8773) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:41.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:47:41.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:41.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:41.406+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:47:41.431+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:41.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:47:41.445+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:47:41.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:47:41.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T10:48:11.825+0000] {processor.py:186} INFO - Started process (PID=8790) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:11.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:48:11.830+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:11.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:11.851+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:11.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:11.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:48:11.890+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:11.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:48:11.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:48:42.264+0000] {processor.py:186} INFO - Started process (PID=8807) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:42.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:48:42.269+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:42.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:42.290+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:48:42.318+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:42.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:48:42.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:48:42.332+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:48:42.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:49:12.709+0000] {processor.py:186} INFO - Started process (PID=8824) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:12.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:49:12.713+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:12.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:12.739+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:12.765+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:12.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:49:12.779+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:12.779+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:49:12.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:49:43.154+0000] {processor.py:186} INFO - Started process (PID=8841) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:43.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:49:43.159+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:43.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:43.180+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:49:43.204+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:43.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:49:43.218+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:49:43.218+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:49:43.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T10:50:13.599+0000] {processor.py:186} INFO - Started process (PID=8858) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:13.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:50:13.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:13.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:13.628+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:13.652+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:13.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:50:13.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:13.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:50:13.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:50:44.048+0000] {processor.py:186} INFO - Started process (PID=8875) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:44.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:50:44.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:44.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:44.077+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:50:44.102+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:44.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:50:44.116+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:50:44.116+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:50:44.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:51:14.509+0000] {processor.py:186} INFO - Started process (PID=8892) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:14.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:51:14.513+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:14.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:14.536+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:14.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:14.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:51:14.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:14.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:51:14.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:51:44.957+0000] {processor.py:186} INFO - Started process (PID=8909) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:44.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:51:44.961+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:44.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:44.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:51:45.012+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:45.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:51:45.030+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:51:45.030+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:51:45.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T10:52:15.398+0000] {processor.py:186} INFO - Started process (PID=8926) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:15.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:52:15.402+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:15.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:15.424+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:15.449+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:15.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:52:15.464+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:15.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:52:15.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:52:45.836+0000] {processor.py:186} INFO - Started process (PID=8943) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:45.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:52:45.840+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:45.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:45.865+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:52:45.890+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:45.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:52:45.905+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:52:45.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:52:45.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:53:16.282+0000] {processor.py:186} INFO - Started process (PID=8960) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:16.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:53:16.286+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:16.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:16.310+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:16.333+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:16.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:53:16.347+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:16.347+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:53:16.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:53:46.724+0000] {processor.py:186} INFO - Started process (PID=8977) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:46.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:53:46.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:46.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:46.750+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:53:46.775+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:46.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:53:46.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:53:46.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:53:46.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:54:17.154+0000] {processor.py:186} INFO - Started process (PID=8994) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:17.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:54:17.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:17.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:17.178+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:17.202+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:17.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:54:17.217+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:17.217+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:54:17.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T10:54:47.584+0000] {processor.py:186} INFO - Started process (PID=9011) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:47.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:54:47.588+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:47.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:47.612+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:54:47.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:47.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:54:47.650+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:54:47.650+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:54:47.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T10:55:18.028+0000] {processor.py:186} INFO - Started process (PID=9028) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:18.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:55:18.031+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:18.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:18.055+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:18.098+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:18.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:55:18.114+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:18.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:55:18.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T10:55:48.495+0000] {processor.py:186} INFO - Started process (PID=9045) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:48.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:55:48.499+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:48.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:48.523+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:55:48.550+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:48.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:55:48.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:55:48.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:55:48.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T10:56:18.945+0000] {processor.py:186} INFO - Started process (PID=9062) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:18.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:56:18.949+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:18.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:18.970+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:18.994+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:18.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:56:19.009+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:19.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:56:19.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T10:56:49.374+0000] {processor.py:186} INFO - Started process (PID=9079) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:49.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:56:49.378+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:49.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:49.403+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:56:49.427+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:49.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:56:49.442+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:56:49.441+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:56:49.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:57:19.815+0000] {processor.py:186} INFO - Started process (PID=9096) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:19.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:57:19.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:19.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:19.843+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:19.867+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:19.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:57:19.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:19.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:57:19.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T10:57:50.256+0000] {processor.py:186} INFO - Started process (PID=9113) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:50.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:57:50.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:50.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:50.282+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:57:50.309+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:50.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:57:50.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:57:50.326+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:57:50.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T10:58:20.705+0000] {processor.py:186} INFO - Started process (PID=9130) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:20.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:58:20.709+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:20.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:20.730+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:20.754+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:20.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:58:20.768+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:20.768+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:58:20.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:58:51.136+0000] {processor.py:186} INFO - Started process (PID=9147) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:51.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:58:51.140+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:51.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:51.165+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:58:51.190+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:51.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:58:51.205+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:58:51.205+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:58:51.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T10:59:21.589+0000] {processor.py:186} INFO - Started process (PID=9164) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:21.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:59:21.592+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:21.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:21.614+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:21.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:21.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:59:21.655+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:21.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:59:21.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T10:59:52.020+0000] {processor.py:186} INFO - Started process (PID=9181) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:52.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T10:59:52.024+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:52.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:52.048+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T10:59:52.073+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:52.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T10:59:52.088+0000] {logging_mixin.py:190} INFO - [2025-04-14T10:59:52.088+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T10:59:52.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T11:00:22.466+0000] {processor.py:186} INFO - Started process (PID=9198) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:22.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:00:22.471+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:22.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:22.492+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:22.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:22.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:00:22.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:22.532+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:00:22.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:00:52.904+0000] {processor.py:186} INFO - Started process (PID=9215) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:52.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:00:52.908+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:52.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:52.929+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:00:52.953+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:52.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:00:52.968+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:00:52.967+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:00:52.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T11:01:23.337+0000] {processor.py:186} INFO - Started process (PID=9232) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:23.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:01:23.342+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:23.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:23.366+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:23.391+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:23.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:01:23.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:23.405+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:01:23.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:01:53.781+0000] {processor.py:186} INFO - Started process (PID=9249) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:53.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:01:53.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:53.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:53.805+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:01:53.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:53.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:01:53.846+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:01:53.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:01:53.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T11:02:24.229+0000] {processor.py:186} INFO - Started process (PID=9272) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:24.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:02:24.233+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:24.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:24.257+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:24.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:24.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:02:24.297+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:24.297+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:02:24.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T11:02:54.666+0000] {processor.py:186} INFO - Started process (PID=9289) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:54.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:02:54.670+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:54.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:54.693+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:02:54.717+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:54.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:02:54.732+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:02:54.731+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:02:54.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:03:25.091+0000] {processor.py:186} INFO - Started process (PID=9306) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:25.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:03:25.094+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:25.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:25.120+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:25.144+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:25.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:03:25.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:25.158+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:03:25.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:03:55.506+0000] {processor.py:186} INFO - Started process (PID=9323) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:55.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:03:55.510+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:55.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:55.530+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:03:55.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:55.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:03:55.569+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:03:55.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:03:55.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:04:25.950+0000] {processor.py:186} INFO - Started process (PID=9340) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:25.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:04:25.956+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:25.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:25.982+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:26.010+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:26.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:04:26.026+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:26.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:04:26.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T11:04:56.401+0000] {processor.py:186} INFO - Started process (PID=9357) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:56.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:04:56.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:56.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:56.427+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:04:56.451+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:56.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:04:56.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:04:56.466+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:04:56.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:05:26.835+0000] {processor.py:186} INFO - Started process (PID=9374) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:26.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:05:26.839+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:26.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:26.860+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:26.884+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:26.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:05:26.901+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:26.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:05:26.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:05:57.275+0000] {processor.py:186} INFO - Started process (PID=9391) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:57.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:05:57.279+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:57.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:57.300+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:05:57.327+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:57.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:05:57.342+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:05:57.342+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:05:57.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:06:27.698+0000] {processor.py:186} INFO - Started process (PID=9408) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:27.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:06:27.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:27.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:27.731+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:27.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:27.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:06:27.770+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:27.770+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:06:27.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T11:06:58.023+0000] {processor.py:186} INFO - Started process (PID=9419) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:58.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:06:58.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:58.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:58.048+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:06:58.076+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:58.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:06:58.096+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:06:58.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:06:58.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T11:07:28.587+0000] {processor.py:186} INFO - Started process (PID=9436) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:28.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:07:28.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:28.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:28.615+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:28.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:28.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:07:28.653+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:28.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:07:28.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:07:59.047+0000] {processor.py:186} INFO - Started process (PID=9453) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:59.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:07:59.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:59.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:59.074+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:07:59.104+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:59.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:07:59.126+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:07:59.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:07:59.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T11:08:29.512+0000] {processor.py:186} INFO - Started process (PID=9470) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:08:29.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:08:29.516+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:08:29.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:08:29.540+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:08:29.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:08:29.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:08:29.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:08:29.577+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:08:29.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:08:59.974+0000] {processor.py:186} INFO - Started process (PID=9487) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:08:59.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:08:59.978+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:08:59.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:09:00.000+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:09:00.033+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:09:00.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:09:00.051+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:09:00.051+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:09:00.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T11:09:30.439+0000] {processor.py:186} INFO - Started process (PID=9504) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:09:30.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:09:30.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:09:30.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:09:30.468+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:09:30.492+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:09:30.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:09:30.507+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:09:30.506+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:09:30.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:10:00.904+0000] {processor.py:186} INFO - Started process (PID=9521) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:00.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:10:00.909+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:00.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:00.930+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:00.956+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:00.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:10:00.971+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:00.971+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:10:00.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:10:31.318+0000] {processor.py:186} INFO - Started process (PID=9538) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:31.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:10:31.322+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:31.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:31.346+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:10:31.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:31.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:10:31.385+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:10:31.385+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:10:31.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:11:01.752+0000] {processor.py:186} INFO - Started process (PID=9555) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:01.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:11:01.756+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:01.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:01.779+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:01.808+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:01.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:11:01.823+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:01.823+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:11:01.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T11:11:32.205+0000] {processor.py:186} INFO - Started process (PID=9572) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:32.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:11:32.208+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:32.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:32.229+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:11:32.253+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:32.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:11:32.269+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:11:32.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:11:32.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:12:02.727+0000] {processor.py:186} INFO - Started process (PID=9589) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:02.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:12:02.731+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:02.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:02.752+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:02.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:02.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:12:02.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:02.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:12:02.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:12:33.184+0000] {processor.py:186} INFO - Started process (PID=9606) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:33.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:12:33.188+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:33.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:33.211+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:12:33.235+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:33.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:12:33.249+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:12:33.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:12:33.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:13:03.638+0000] {processor.py:186} INFO - Started process (PID=9623) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:03.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:13:03.643+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:03.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:03.665+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:03.690+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:03.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:13:03.708+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:03.708+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:13:03.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T11:13:34.088+0000] {processor.py:186} INFO - Started process (PID=9640) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:34.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:13:34.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:34.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:34.113+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:13:34.137+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:34.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:13:34.152+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:13:34.152+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:13:34.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:14:04.517+0000] {processor.py:186} INFO - Started process (PID=9657) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:04.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:14:04.522+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:04.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:04.545+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:04.570+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:04.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:14:04.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:04.584+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:14:04.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T11:14:34.970+0000] {processor.py:186} INFO - Started process (PID=9674) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:34.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:14:34.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:34.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:34.998+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:14:35.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:35.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:14:35.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:14:35.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:14:35.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:15:05.421+0000] {processor.py:186} INFO - Started process (PID=9691) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:05.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:15:05.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:05.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:05.446+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:05.470+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:05.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:15:05.485+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:05.485+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:15:05.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:15:35.873+0000] {processor.py:186} INFO - Started process (PID=9708) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:35.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:15:35.878+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:35.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:35.901+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:15:35.927+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:35.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:15:35.941+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:15:35.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:15:35.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:16:06.321+0000] {processor.py:186} INFO - Started process (PID=9725) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:06.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:16:06.325+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:06.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:06.350+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:06.378+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:06.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:16:06.395+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:06.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:16:06.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T11:16:36.787+0000] {processor.py:186} INFO - Started process (PID=9742) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:36.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:16:36.791+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:36.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:36.814+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:16:36.840+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:36.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:16:36.856+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:16:36.856+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:16:36.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T11:17:07.305+0000] {processor.py:186} INFO - Started process (PID=9759) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:07.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:17:07.309+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:07.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:07.332+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:07.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:07.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:17:07.372+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:07.372+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:17:07.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:17:37.855+0000] {processor.py:186} INFO - Started process (PID=9776) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:37.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:17:37.861+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:37.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:37.890+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:37.929+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:37.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:17:37.957+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:37.957+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:17:38.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.774 seconds
[2025-04-14T11:17:48.407+0000] {processor.py:186} INFO - Started process (PID=9781) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:48.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:17:48.411+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:48.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:48.451+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:17:48.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:48.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:17:48.522+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:17:48.521+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:17:48.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.161 seconds
[2025-04-14T11:18:18.913+0000] {processor.py:186} INFO - Started process (PID=9798) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:18.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:18:18.918+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:18.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:18.944+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:18.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:18.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:18:18.991+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:18.991+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:18:19.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T11:18:49.424+0000] {processor.py:186} INFO - Started process (PID=9815) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:49.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:18:49.427+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:49.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:49.453+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:49.477+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:49.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:18:49.496+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:49.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:18:49.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T11:18:55.503+0000] {processor.py:186} INFO - Started process (PID=9826) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:55.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:18:55.507+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:55.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:55.548+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:18:55.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:55.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:18:55.607+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:18:55.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:18:55.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T11:19:25.816+0000] {processor.py:186} INFO - Started process (PID=9849) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:25.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:19:25.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:25.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:25.837+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:25.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:25.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:19:25.877+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:25.876+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:19:25.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:19:56.293+0000] {processor.py:186} INFO - Started process (PID=9866) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:56.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:19:56.297+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:56.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:56.329+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:19:56.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:56.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:19:56.375+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:19:56.374+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:19:56.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T11:20:26.564+0000] {processor.py:186} INFO - Started process (PID=9883) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:26.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:20:26.568+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:26.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:26.592+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:26.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:26.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:20:26.630+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:26.629+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:20:26.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:20:56.999+0000] {processor.py:186} INFO - Started process (PID=9900) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:57.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:20:57.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:57.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:57.024+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:20:57.048+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:57.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:20:57.062+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:20:57.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:20:57.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:21:27.428+0000] {processor.py:186} INFO - Started process (PID=9918) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:27.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:21:27.432+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:27.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:27.454+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:27.478+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:27.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:21:27.491+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:27.491+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:21:27.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:21:57.871+0000] {processor.py:186} INFO - Started process (PID=9935) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:57.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:21:57.876+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:57.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:57.898+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:21:57.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:57.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:21:57.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:21:57.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:21:57.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T11:22:28.311+0000] {processor.py:186} INFO - Started process (PID=9952) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:28.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:22:28.315+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:28.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:28.337+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:28.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:28.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:22:28.375+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:28.375+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:22:28.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T11:22:58.742+0000] {processor.py:186} INFO - Started process (PID=9969) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:58.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:22:58.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:58.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:58.772+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:22:58.796+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:58.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:22:58.811+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:22:58.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:22:58.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:23:29.199+0000] {processor.py:186} INFO - Started process (PID=9986) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:29.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:23:29.203+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:29.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:29.226+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:29.250+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:29.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:23:29.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:29.264+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:23:29.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T11:23:59.636+0000] {processor.py:186} INFO - Started process (PID=10003) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:59.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:23:59.640+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:59.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:59.662+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:23:59.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:59.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:23:59.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:23:59.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:23:59.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:24:30.087+0000] {processor.py:186} INFO - Started process (PID=10020) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:24:30.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:24:30.093+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:24:30.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:24:30.116+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:24:30.148+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:24:30.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:24:30.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:24:30.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:24:30.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T11:25:00.561+0000] {processor.py:186} INFO - Started process (PID=10037) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:00.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:25:00.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:00.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:00.590+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:00.619+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:00.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:25:00.637+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:00.637+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:25:00.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T11:25:31.021+0000] {processor.py:186} INFO - Started process (PID=10054) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:31.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:25:31.025+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:31.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:31.049+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:25:31.075+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:31.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:25:31.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:25:31.091+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:25:31.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T11:26:01.477+0000] {processor.py:186} INFO - Started process (PID=10071) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:01.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:26:01.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:01.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:01.505+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:01.530+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:01.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:26:01.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:01.544+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:26:01.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:26:31.913+0000] {processor.py:186} INFO - Started process (PID=10088) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:31.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:26:31.917+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:31.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:31.941+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:26:31.965+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:31.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:26:31.979+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:26:31.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:26:32.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:27:02.346+0000] {processor.py:186} INFO - Started process (PID=10105) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:02.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:27:02.350+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:02.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:02.375+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:02.400+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:02.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:27:02.416+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:02.416+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:27:02.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T11:27:32.788+0000] {processor.py:186} INFO - Started process (PID=10122) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:32.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:27:32.791+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:32.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:32.814+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:27:32.839+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:32.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:27:32.854+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:27:32.853+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:27:32.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:28:03.214+0000] {processor.py:186} INFO - Started process (PID=10139) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:03.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:28:03.218+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:03.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:03.240+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:03.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:03.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:28:03.278+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:03.278+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:28:03.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:28:33.656+0000] {processor.py:186} INFO - Started process (PID=10156) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:33.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:28:33.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:33.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:33.681+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:28:33.706+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:33.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:28:33.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:28:33.719+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:28:33.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:29:04.089+0000] {processor.py:186} INFO - Started process (PID=10173) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:04.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:29:04.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:04.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:04.114+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:04.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:04.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:29:04.156+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:04.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:29:04.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:29:34.525+0000] {processor.py:186} INFO - Started process (PID=10190) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:34.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:29:34.529+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:34.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:34.549+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:29:34.574+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:34.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:29:34.588+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:29:34.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:29:34.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:30:04.963+0000] {processor.py:186} INFO - Started process (PID=10207) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:04.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:30:04.967+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:04.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:04.992+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:05.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:05.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:30:05.034+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:05.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:30:05.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T11:30:35.412+0000] {processor.py:186} INFO - Started process (PID=10224) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:35.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:30:35.416+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:35.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:35.438+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:30:35.460+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:35.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:30:35.474+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:30:35.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:30:35.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T11:31:05.880+0000] {processor.py:186} INFO - Started process (PID=10241) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:05.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:31:05.884+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:05.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:05.905+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:05.931+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:05.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:31:05.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:05.947+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:31:05.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T11:31:36.746+0000] {processor.py:186} INFO - Started process (PID=10258) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:36.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:31:36.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:36.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:36.786+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:31:37.085+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:37.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:31:37.157+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:31:37.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:31:37.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 1.127 seconds
[2025-04-14T11:32:07.958+0000] {processor.py:186} INFO - Started process (PID=10320) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:07.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:32:07.961+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:07.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:07.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:08.011+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:08.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:32:08.028+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:08.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:32:08.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T11:32:38.382+0000] {processor.py:186} INFO - Started process (PID=10351) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:38.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:32:38.386+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:38.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:38.409+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:32:38.433+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:38.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:32:38.447+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:32:38.446+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:32:38.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:33:08.655+0000] {processor.py:186} INFO - Started process (PID=10385) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:08.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:33:08.661+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:08.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:08.687+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:08.731+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:08.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:33:08.757+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:08.756+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:33:08.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T11:33:38.901+0000] {processor.py:186} INFO - Started process (PID=10444) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:38.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:33:38.907+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:38.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:38.936+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:33:38.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:38.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:33:38.979+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:33:38.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:33:39.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T11:34:09.377+0000] {processor.py:186} INFO - Started process (PID=10461) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:09.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:34:09.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:09.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:09.417+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:09.465+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:09.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:34:09.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:09.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:34:09.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.451 seconds
[2025-04-14T11:34:40.164+0000] {processor.py:186} INFO - Started process (PID=10509) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:40.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:34:40.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:40.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:40.197+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:34:40.226+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:40.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:34:40.244+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:34:40.243+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:34:40.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T11:35:10.671+0000] {processor.py:186} INFO - Started process (PID=10568) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:10.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:35:10.678+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:10.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:10.723+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:10.761+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:10.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:35:10.784+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:10.784+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:35:10.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.152 seconds
[2025-04-14T11:35:40.919+0000] {processor.py:186} INFO - Started process (PID=10627) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:40.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:35:40.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:40.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:40.947+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:35:40.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:40.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:35:41.010+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:35:41.010+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:35:41.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T11:36:11.427+0000] {processor.py:186} INFO - Started process (PID=10672) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:11.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:36:11.431+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:11.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:11.453+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:11.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:11.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:36:11.499+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:11.499+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:36:11.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T11:36:41.871+0000] {processor.py:186} INFO - Started process (PID=10689) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:41.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:36:41.878+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:41.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:41.903+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:36:41.935+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:41.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:36:41.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:36:41.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:36:41.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T11:37:12.381+0000] {processor.py:186} INFO - Started process (PID=10706) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:12.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:37:12.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:12.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:12.405+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:12.433+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:12.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:37:12.449+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:12.449+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:37:12.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T11:37:42.869+0000] {processor.py:186} INFO - Started process (PID=10723) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:42.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:37:42.874+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:42.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:42.901+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:37:42.930+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:42.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:37:42.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:37:42.951+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:37:42.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T11:38:13.342+0000] {processor.py:186} INFO - Started process (PID=10740) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:13.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:38:13.346+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:13.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:13.370+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:13.398+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:13.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:38:13.414+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:13.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:38:13.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T11:38:43.844+0000] {processor.py:186} INFO - Started process (PID=10774) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:43.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:38:43.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:43.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:43.869+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:38:43.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:43.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:38:43.914+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:38:43.913+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:38:43.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T11:39:14.265+0000] {processor.py:186} INFO - Started process (PID=10830) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:14.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:39:14.273+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:14.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:14.305+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:14.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:14.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:39:14.353+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:14.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:39:14.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T11:39:44.789+0000] {processor.py:186} INFO - Started process (PID=10858) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:44.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:39:44.794+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:44.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:44.820+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:39:44.860+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:44.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:39:44.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:39:44.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:39:44.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T11:40:15.113+0000] {processor.py:186} INFO - Started process (PID=10875) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:15.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:40:15.117+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:15.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:15.139+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:15.174+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:15.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:40:15.198+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:15.197+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:40:15.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T11:40:45.307+0000] {processor.py:186} INFO - Started process (PID=10892) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:45.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:40:45.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:45.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:45.344+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:40:45.371+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:45.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:40:45.387+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:40:45.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:40:45.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T11:41:15.502+0000] {processor.py:186} INFO - Started process (PID=10953) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:15.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:41:15.509+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:15.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:15.536+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:15.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:15.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:41:15.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:15.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:41:15.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T11:41:46.393+0000] {processor.py:186} INFO - Started process (PID=10999) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:46.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:41:46.398+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:46.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:46.419+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:41:46.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:46.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:41:46.470+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:41:46.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:41:46.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T11:42:16.714+0000] {processor.py:186} INFO - Started process (PID=11016) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:16.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:42:16.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:16.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:16.740+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:16.765+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:16.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:42:16.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:16.780+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:42:16.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T11:42:47.191+0000] {processor.py:186} INFO - Started process (PID=11033) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:47.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:42:47.195+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:47.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:47.220+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:42:47.244+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:47.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:42:47.258+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:42:47.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:42:47.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:43:17.744+0000] {processor.py:186} INFO - Started process (PID=11050) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:17.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:43:17.753+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:17.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:17.778+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:17.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:17.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:43:17.837+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:17.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:43:17.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T11:43:48.255+0000] {processor.py:186} INFO - Started process (PID=11067) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:48.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:43:48.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:48.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:48.280+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:43:48.304+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:48.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:43:48.319+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:43:48.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:43:48.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T11:44:18.699+0000] {processor.py:186} INFO - Started process (PID=11085) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:18.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:44:18.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:18.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:18.724+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:18.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:18.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:44:18.773+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:18.773+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:44:18.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T11:44:49.187+0000] {processor.py:186} INFO - Started process (PID=11102) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:49.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:44:49.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:49.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:49.232+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:44:49.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:49.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:44:49.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:44:49.281+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:44:49.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T11:45:19.665+0000] {processor.py:186} INFO - Started process (PID=11119) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:19.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:45:19.670+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:19.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:19.696+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:19.723+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:19.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:45:19.738+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:19.738+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:45:19.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T11:45:50.218+0000] {processor.py:186} INFO - Started process (PID=11136) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:50.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:45:50.225+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:50.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:50.258+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:45:50.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:50.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:45:50.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:45:50.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:45:50.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.174 seconds
[2025-04-14T11:46:20.561+0000] {processor.py:186} INFO - Started process (PID=11153) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:20.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:46:20.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:20.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:20.588+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:20.611+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:20.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:46:20.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:20.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:46:20.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T11:46:51.355+0000] {processor.py:186} INFO - Started process (PID=11170) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:51.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:46:51.363+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:51.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:51.410+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:46:51.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:51.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:46:51.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:46:51.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:46:51.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.179 seconds
[2025-04-14T11:47:21.681+0000] {processor.py:186} INFO - Started process (PID=11187) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:21.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:47:21.687+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:21.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:21.712+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:21.740+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:21.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:47:21.758+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:21.758+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:47:21.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T11:47:52.163+0000] {processor.py:186} INFO - Started process (PID=11204) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:52.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:47:52.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:52.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:52.191+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:47:52.223+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:52.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:47:52.240+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:47:52.239+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:47:52.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T11:48:22.633+0000] {processor.py:186} INFO - Started process (PID=11221) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:22.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:48:22.638+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:22.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:22.665+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:22.698+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:22.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:48:22.717+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:22.716+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:48:22.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T11:48:53.123+0000] {processor.py:186} INFO - Started process (PID=11238) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:53.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:48:53.128+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:53.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:53.151+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:48:53.176+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:53.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:48:53.190+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:48:53.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:48:53.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T11:49:23.622+0000] {processor.py:186} INFO - Started process (PID=11255) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:23.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:49:23.630+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:23.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:23.657+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:23.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:23.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:49:23.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:23.712+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:49:23.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T11:49:53.848+0000] {processor.py:186} INFO - Started process (PID=11272) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:53.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:49:53.852+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:53.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:53.875+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:49:53.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:53.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:49:53.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:49:53.924+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:49:53.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T11:50:24.086+0000] {processor.py:186} INFO - Started process (PID=11290) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:24.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:50:24.090+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:24.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:24.113+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:24.140+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:24.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:50:24.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:24.158+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:50:24.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T11:50:54.559+0000] {processor.py:186} INFO - Started process (PID=11307) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:54.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:50:54.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:54.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:54.585+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:50:54.611+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:54.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:50:54.626+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:50:54.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:50:54.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T11:51:25.022+0000] {processor.py:186} INFO - Started process (PID=11324) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:25.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:51:25.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:25.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:25.063+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:25.101+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:25.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:51:25.122+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:25.121+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:51:25.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T11:51:55.353+0000] {processor.py:186} INFO - Started process (PID=11341) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:55.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:51:55.362+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:55.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:55.384+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:51:55.413+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:55.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:51:55.432+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:51:55.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:51:55.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T11:52:25.837+0000] {processor.py:186} INFO - Started process (PID=11358) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:25.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:52:25.842+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:25.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:25.877+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:25.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:25.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:52:25.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:25.922+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:52:25.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T11:52:56.367+0000] {processor.py:186} INFO - Started process (PID=11375) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:56.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:52:56.373+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:56.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:56.407+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:52:56.442+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:56.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:52:56.462+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:52:56.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:52:56.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T11:53:26.876+0000] {processor.py:186} INFO - Started process (PID=11392) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:26.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:53:26.881+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:26.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:26.907+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:26.935+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:26.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:53:26.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:26.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:53:26.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T11:53:57.346+0000] {processor.py:186} INFO - Started process (PID=11409) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:57.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:53:57.350+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:57.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:57.368+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:53:57.392+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:57.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:53:57.407+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:53:57.407+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:53:57.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.089 seconds
[2025-04-14T11:54:27.820+0000] {processor.py:186} INFO - Started process (PID=11426) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:27.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:54:27.826+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:27.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:27.852+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:27.885+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:27.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:54:27.901+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:27.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:54:27.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T11:54:58.033+0000] {processor.py:186} INFO - Started process (PID=11443) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:58.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:54:58.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:58.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:58.063+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:54:58.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:58.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:54:58.118+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:54:58.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:54:58.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T11:55:28.513+0000] {processor.py:186} INFO - Started process (PID=11461) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:28.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:55:28.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:28.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:28.541+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:28.575+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:28.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:55:28.598+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:28.598+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:55:28.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T11:55:59.048+0000] {processor.py:186} INFO - Started process (PID=11478) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:59.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:55:59.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:59.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:59.076+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:55:59.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:59.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:55:59.118+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:55:59.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:55:59.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T11:56:29.540+0000] {processor.py:186} INFO - Started process (PID=11495) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:56:29.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:56:29.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:56:29.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:56:29.566+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:56:29.592+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:56:29.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:56:29.607+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:56:29.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:56:29.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T11:56:59.958+0000] {processor.py:186} INFO - Started process (PID=11512) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:56:59.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:56:59.962+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:56:59.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:56:59.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:57:00.008+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:57:00.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:57:00.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:57:00.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:57:00.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T11:57:30.995+0000] {processor.py:186} INFO - Started process (PID=11529) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:57:31.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:57:31.010+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:57:31.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:57:31.067+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:57:31.111+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:57:31.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:57:31.142+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:57:31.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:57:31.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.211 seconds
[2025-04-14T11:58:01.719+0000] {processor.py:186} INFO - Started process (PID=11546) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:01.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:58:01.727+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:01.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:01.757+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:01.801+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:01.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:58:01.821+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:01.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:58:01.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.140 seconds
[2025-04-14T11:58:32.577+0000] {processor.py:186} INFO - Started process (PID=11563) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:32.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:58:32.582+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:32.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:32.650+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:58:32.753+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:32.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:58:32.825+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:58:32.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:58:32.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.368 seconds
[2025-04-14T11:59:03.331+0000] {processor.py:186} INFO - Started process (PID=11581) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:03.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:59:03.336+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:03.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:03.359+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:03.389+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:03.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:59:03.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:03.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:59:03.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T11:59:33.889+0000] {processor.py:186} INFO - Started process (PID=11598) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:33.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T11:59:33.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:33.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:33.918+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T11:59:33.943+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:33.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T11:59:33.960+0000] {logging_mixin.py:190} INFO - [2025-04-14T11:59:33.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T11:59:33.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T12:00:04.360+0000] {processor.py:186} INFO - Started process (PID=11615) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:04.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:00:04.364+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:04.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:04.386+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:04.434+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:04.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:00:04.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:04.486+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:00:04.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.184 seconds
[2025-04-14T12:00:34.739+0000] {processor.py:186} INFO - Started process (PID=11632) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:34.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:00:34.744+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:34.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:34.777+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:00:34.811+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:34.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:00:34.834+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:00:34.833+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:00:34.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T12:01:04.918+0000] {processor.py:186} INFO - Started process (PID=11649) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:04.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:01:04.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:04.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:04.941+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:04.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:04.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:01:04.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:04.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:01:05.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T12:01:35.762+0000] {processor.py:186} INFO - Started process (PID=11667) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:35.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:01:35.773+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:35.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:35.815+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:01:35.877+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:35.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:01:35.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:01:35.902+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:01:35.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.180 seconds
[2025-04-14T12:02:06.510+0000] {processor.py:186} INFO - Started process (PID=11687) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:06.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:02:06.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:06.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:06.555+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:06.595+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:06.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:02:06.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:06.624+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:02:06.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.163 seconds
[2025-04-14T12:02:36.893+0000] {processor.py:186} INFO - Started process (PID=11701) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:36.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:02:36.900+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:36.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:36.929+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:02:36.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:36.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:02:36.996+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:02:36.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:02:37.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.145 seconds
[2025-04-14T12:03:07.401+0000] {processor.py:186} INFO - Started process (PID=11716) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:07.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:03:07.406+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:07.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:07.438+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:07.476+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:07.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:03:07.498+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:07.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:03:07.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T12:03:37.932+0000] {processor.py:186} INFO - Started process (PID=11733) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:37.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:03:37.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:37.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:37.959+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:03:37.984+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:37.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:03:37.999+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:03:37.999+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:03:38.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T12:04:08.398+0000] {processor.py:186} INFO - Started process (PID=11750) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:08.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:04:08.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:08.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:08.430+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:08.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:08.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:04:08.513+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:08.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:04:08.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.171 seconds
[2025-04-14T12:04:38.938+0000] {processor.py:186} INFO - Started process (PID=11773) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:38.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:04:38.942+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:38.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:38.967+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:04:38.993+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:38.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:04:39.008+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:04:39.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:04:39.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T12:05:09.421+0000] {processor.py:186} INFO - Started process (PID=11790) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:09.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:05:09.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:09.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:09.446+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:09.470+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:09.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:05:09.484+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:09.484+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:05:09.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T12:05:39.888+0000] {processor.py:186} INFO - Started process (PID=11807) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:39.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:05:39.893+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:39.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:39.917+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:05:39.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:39.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:05:39.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:05:39.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:05:39.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T12:06:10.355+0000] {processor.py:186} INFO - Started process (PID=11824) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:10.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:06:10.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:10.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:10.381+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:10.404+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:10.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:06:10.419+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:10.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:06:10.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T12:06:40.816+0000] {processor.py:186} INFO - Started process (PID=11841) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:40.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:06:40.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:40.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:40.849+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:06:40.878+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:40.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:06:40.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:06:40.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:06:40.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T12:07:11.031+0000] {processor.py:186} INFO - Started process (PID=11858) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:11.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:07:11.035+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:11.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:11.059+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:11.088+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:11.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:07:11.105+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:11.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:07:11.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T12:07:41.507+0000] {processor.py:186} INFO - Started process (PID=11875) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:41.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:07:41.511+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:41.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:41.535+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:07:41.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:41.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:07:41.579+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:07:41.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:07:41.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T12:08:11.997+0000] {processor.py:186} INFO - Started process (PID=11892) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:11.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:08:12.002+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:12.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:12.024+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:12.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:12.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:08:12.068+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:12.068+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:08:12.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T12:08:42.433+0000] {processor.py:186} INFO - Started process (PID=11909) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:42.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:08:42.437+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:42.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:42.459+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:08:42.486+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:42.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:08:42.503+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:08:42.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:08:42.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T12:09:12.652+0000] {processor.py:186} INFO - Started process (PID=11926) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:12.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:09:12.658+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:12.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:12.683+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:12.710+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:12.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:09:12.726+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:12.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:09:12.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T12:09:43.130+0000] {processor.py:186} INFO - Started process (PID=11943) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:43.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:09:43.134+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:43.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:43.154+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:09:43.183+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:43.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:09:43.199+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:09:43.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:09:43.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T12:10:13.653+0000] {processor.py:186} INFO - Started process (PID=11960) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:13.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:10:13.657+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:13.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:13.687+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:13.716+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:13.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:10:13.736+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:13.735+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:10:13.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T12:10:44.154+0000] {processor.py:186} INFO - Started process (PID=11977) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:44.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:10:44.160+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:44.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:44.185+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:10:44.219+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:44.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:10:44.237+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:10:44.237+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:10:44.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T12:11:14.620+0000] {processor.py:186} INFO - Started process (PID=11994) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:14.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:11:14.624+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:14.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:14.648+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:14.673+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:14.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:11:14.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:14.692+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:11:14.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T12:11:45.097+0000] {processor.py:186} INFO - Started process (PID=12011) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:45.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:11:45.102+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:45.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:45.126+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:11:45.154+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:45.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:11:45.171+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:11:45.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:11:45.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T12:12:03.335+0000] {processor.py:186} INFO - Started process (PID=12022) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:03.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:12:03.339+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:12:03.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:03.379+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:12:03.374+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 3, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:12:03.382+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:03.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.079 seconds
[2025-04-14T12:12:33.851+0000] {processor.py:186} INFO - Started process (PID=12039) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:33.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:12:33.856+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:12:33.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:33.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:12:33.869+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 3, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:12:33.877+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:12:33.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.055 seconds
[2025-04-14T12:13:04.279+0000] {processor.py:186} INFO - Started process (PID=12056) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:04.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:13:04.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:04.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:04.306+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:04.301+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 3, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:13:04.308+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:04.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.058 seconds
[2025-04-14T12:13:12.502+0000] {processor.py:186} INFO - Started process (PID=12067) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:12.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:13:12.509+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:12.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:12.541+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:12.540+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 22
    dest=,
    ^^^^^
SyntaxError: expected argument value expression
[2025-04-14T12:13:12.542+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:12.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.069 seconds
[2025-04-14T12:13:19.625+0000] {processor.py:186} INFO - Started process (PID=12072) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:19.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:13:19.628+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:19.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:19.655+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:19.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 23
    dest=,
    ^^^^^
SyntaxError: expected argument value expression
[2025-04-14T12:13:19.656+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:19.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.064 seconds
[2025-04-14T12:13:32.889+0000] {processor.py:186} INFO - Started process (PID=12077) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:32.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:13:32.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:32.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:32.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:32.922+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 23
    dest=,
    ^^^^^
SyntaxError: expected argument value expression
[2025-04-14T12:13:32.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:32.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.065 seconds
[2025-04-14T12:13:43.689+0000] {processor.py:186} INFO - Started process (PID=12094) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:43.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:13:43.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:43.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:43.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:13:43.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:13:43.744+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:13:43.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T12:14:14.144+0000] {processor.py:186} INFO - Started process (PID=12111) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:14.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:14:14.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:14.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:14.183+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:14.177+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:14:14.185+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:14.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.072 seconds
[2025-04-14T12:14:24.297+0000] {processor.py:186} INFO - Started process (PID=12116) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:24.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:14:24.301+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:24.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:24.350+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:24.341+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:14:24.354+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:24.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.087 seconds
[2025-04-14T12:14:26.396+0000] {processor.py:186} INFO - Started process (PID=12121) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:26.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:14:26.400+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:26.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:26.435+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:26.428+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:14:26.438+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:26.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.073 seconds
[2025-04-14T12:14:34.590+0000] {processor.py:186} INFO - Started process (PID=12126) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:34.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:14:34.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:34.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:34.655+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:14:34.648+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:14:34.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:14:34.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T12:15:04.822+0000] {processor.py:186} INFO - Started process (PID=12143) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:04.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:15:04.826+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:15:04.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:04.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:15:04.844+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:15:04.850+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:04.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.056 seconds
[2025-04-14T12:15:35.209+0000] {processor.py:186} INFO - Started process (PID=12160) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:35.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:15:35.212+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:15:35.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:35.234+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:15:35.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:15:35.236+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:15:35.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.054 seconds
[2025-04-14T12:16:05.640+0000] {processor.py:186} INFO - Started process (PID=12177) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:05.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:16:05.644+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:16:05.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:05.672+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:16:05.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:16:05.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:05.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.066 seconds
[2025-04-14T12:16:35.800+0000] {processor.py:186} INFO - Started process (PID=12194) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:35.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:16:35.803+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:16:35.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:35.828+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:16:35.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:16:35.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:16:35.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.058 seconds
[2025-04-14T12:17:06.238+0000] {processor.py:186} INFO - Started process (PID=12211) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:06.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:17:06.241+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:06.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:06.266+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:06.262+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:17:06.269+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:06.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.071 seconds
[2025-04-14T12:17:24.120+0000] {processor.py:186} INFO - Started process (PID=12228) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:24.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:17:24.124+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:24.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:24.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:24.159+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:17:24.172+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:24.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T12:17:54.555+0000] {processor.py:186} INFO - Started process (PID=12245) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:54.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:17:54.558+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:54.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:54.588+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:17:54.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:17:54.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:17:54.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.068 seconds
[2025-04-14T12:18:25.031+0000] {processor.py:186} INFO - Started process (PID=12262) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:25.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:18:25.034+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:18:25.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:25.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:18:25.060+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:18:25.069+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:25.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.075 seconds
[2025-04-14T12:18:55.484+0000] {processor.py:186} INFO - Started process (PID=12279) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:55.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:18:55.488+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:18:55.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:55.510+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:18:55.505+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:18:55.513+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:18:55.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.062 seconds
[2025-04-14T12:19:25.908+0000] {processor.py:186} INFO - Started process (PID=12296) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:25.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:19:25.913+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:19:25.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:25.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:19:25.932+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:19:25.941+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:25.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.065 seconds
[2025-04-14T12:19:56.329+0000] {processor.py:186} INFO - Started process (PID=12313) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:56.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:19:56.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:19:56.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:56.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:19:56.351+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:19:56.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:19:56.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.059 seconds
[2025-04-14T12:20:26.763+0000] {processor.py:186} INFO - Started process (PID=12330) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:26.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:20:26.766+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:20:26.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:26.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:20:26.785+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:20:26.792+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:26.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.056 seconds
[2025-04-14T12:20:56.927+0000] {processor.py:186} INFO - Started process (PID=12347) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:56.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:20:56.930+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:20:56.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:56.959+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:20:56.952+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:20:56.962+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:20:56.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.069 seconds
[2025-04-14T12:21:27.365+0000] {processor.py:186} INFO - Started process (PID=12364) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:27.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:21:27.368+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:21:27.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:27.393+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:21:27.388+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:21:27.397+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:27.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.064 seconds
[2025-04-14T12:21:57.812+0000] {processor.py:186} INFO - Started process (PID=12381) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:57.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:21:57.816+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:21:57.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:57.843+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:21:57.837+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:21:57.845+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:21:57.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.066 seconds
[2025-04-14T12:22:28.260+0000] {processor.py:186} INFO - Started process (PID=12398) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:28.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:22:28.263+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:22:28.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:28.284+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:22:28.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:22:28.286+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:28.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.056 seconds
[2025-04-14T12:22:58.396+0000] {processor.py:186} INFO - Started process (PID=12415) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:58.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:22:58.399+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:22:58.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:58.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:22:58.422+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.operators.gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/operators/gcs.py)
[2025-04-14T12:22:58.429+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:22:58.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.065 seconds
[2025-04-14T12:23:18.661+0000] {processor.py:186} INFO - Started process (PID=12427) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:18.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:23:18.665+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:23:18.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:18.735+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:23:18.726+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:23:18.740+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:18.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T12:23:34.638+0000] {processor.py:186} INFO - Started process (PID=12438) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:34.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:23:34.641+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:23:34.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:34.751+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:23:34.741+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:23:34.768+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:23:34.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.167 seconds
[2025-04-14T12:24:05.180+0000] {processor.py:186} INFO - Started process (PID=12455) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:05.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:24:05.183+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:24:05.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:05.210+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:24:05.204+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:24:05.213+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:05.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.083 seconds
[2025-04-14T12:24:35.653+0000] {processor.py:186} INFO - Started process (PID=12472) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:35.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:24:35.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:24:35.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:35.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:24:35.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:24:35.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:24:35.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.088 seconds
[2025-04-14T12:25:06.105+0000] {processor.py:186} INFO - Started process (PID=12489) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:06.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:25:06.108+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:25:06.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:06.138+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:25:06.130+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:25:06.140+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:06.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.065 seconds
[2025-04-14T12:25:36.553+0000] {processor.py:186} INFO - Started process (PID=12506) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:36.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:25:36.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:25:36.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:36.600+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:25:36.592+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:25:36.602+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:25:36.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.085 seconds
[2025-04-14T12:26:07.015+0000] {processor.py:186} INFO - Started process (PID=12523) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:07.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:26:07.019+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:26:07.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:07.059+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:26:07.048+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:26:07.068+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:07.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T12:26:37.215+0000] {processor.py:186} INFO - Started process (PID=12540) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:37.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:26:37.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:26:37.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:37.254+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:26:37.245+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:26:37.257+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:26:37.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.082 seconds
[2025-04-14T12:27:07.578+0000] {processor.py:186} INFO - Started process (PID=12551) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:07.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:27:07.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:27:07.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:07.626+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:27:07.616+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:27:07.630+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:07.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.089 seconds
[2025-04-14T12:27:38.058+0000] {processor.py:186} INFO - Started process (PID=12568) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:38.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:27:38.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:27:38.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:38.095+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:27:38.085+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:27:38.098+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:27:38.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.075 seconds
[2025-04-14T12:28:08.193+0000] {processor.py:186} INFO - Started process (PID=12585) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:28:08.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:28:08.196+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:28:08.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:28:08.219+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:28:08.213+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:28:08.221+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:28:08.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.055 seconds
[2025-04-14T12:29:37.218+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:29:37.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:29:37.224+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:29:37.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:29:37.254+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:29:37.246+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:29:37.257+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:29:37.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T12:30:07.850+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:07.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:30:07.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:30:07.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:07.892+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:30:07.884+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:30:07.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:07.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T12:30:38.289+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:38.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:30:38.294+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:30:38.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:38.319+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:30:38.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:30:38.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:30:38.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.061 seconds
[2025-04-14T12:31:08.716+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:08.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:31:08.722+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:31:08.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:08.750+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:31:08.744+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:31:08.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:08.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.070 seconds
[2025-04-14T12:31:38.893+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:38.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:31:38.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:31:38.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:38.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:31:38.918+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:31:38.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:31:38.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.060 seconds
[2025-04-14T12:32:09.108+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:32:09.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:32:09.115+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:32:09.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:32:09.135+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:32:09.131+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:32:09.137+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:32:09.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.061 seconds
[2025-04-14T12:47:14.946+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:14.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:47:14.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:47:14.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:15.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:47:14.994+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:47:15.006+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:15.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T12:47:45.400+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:45.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:47:45.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:47:45.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:45.438+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:47:45.433+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:47:45.441+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:47:45.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.071 seconds
[2025-04-14T12:48:15.876+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:15.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:48:15.882+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:48:15.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:15.909+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:48:15.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:48:15.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:15.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.074 seconds
[2025-04-14T12:48:46.330+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:46.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:48:46.336+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:48:46.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:46.367+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:48:46.360+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:48:46.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:48:46.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.076 seconds
[2025-04-14T12:49:16.890+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:16.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:49:16.901+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:16.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:16.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:16.919+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.transfers.gcs'
[2025-04-14T12:49:16.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:16.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.066 seconds
[2025-04-14T12:49:32.211+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:32.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:49:32.216+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:32.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:32.253+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:32.248+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.local_to_gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.transfers.local_to_gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/local_to_gcs.py)
[2025-04-14T12:49:32.255+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:32.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.074 seconds
[2025-04-14T12:49:58.276+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:58.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:49:58.281+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:58.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:58.319+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:49:58.312+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.transfers.local_to_gcs import LocalFilesystemToGoogleCloudStorageOperator
ImportError: cannot import name 'LocalFilesystemToGoogleCloudStorageOperator' from 'airflow.providers.google.cloud.transfers.local_to_gcs' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/local_to_gcs.py)
[2025-04-14T12:49:58.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:49:58.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.079 seconds
[2025-04-14T12:50:27.482+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:27.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:50:27.490+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:50:27.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:27.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:50:27.535+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.local_to_gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.operators.local_to_gcs'
[2025-04-14T12:50:27.548+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:27.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T12:50:58.010+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:58.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:50:58.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:50:58.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:58.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:50:58.035+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.local_to_gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.operators.local_to_gcs'
[2025-04-14T12:50:58.042+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:50:58.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.067 seconds
[2025-04-14T12:51:28.486+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:28.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:51:28.492+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:28.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:28.520+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:28.514+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 4, in <module>
    from airflow.providers.google.cloud.operators.local_to_gcs import LocalFilesystemToGoogleCloudStorageOperator
ModuleNotFoundError: No module named 'airflow.providers.google.cloud.operators.local_to_gcs'
[2025-04-14T12:51:28.523+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:28.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.076 seconds
[2025-04-14T12:51:47.701+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:47.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:51:47.705+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:47.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:47.743+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:47.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 21, in <module>
    upload_spark_to_gcs = LocalFilesystemToGoogleCloudStorageOperator(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'LocalFilesystemToGoogleCloudStorageOperator' is not defined
[2025-04-14T12:51:47.747+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:47.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.075 seconds
[2025-04-14T12:51:57.961+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:57.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:51:57.966+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:57.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:58.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:51:57.997+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 29, in <module>
    upload_spark_to_gcs = LocalFilesystemToGoogleCloudStorageOperator(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'LocalFilesystemToGoogleCloudStorageOperator' is not defined
[2025-04-14T12:51:58.006+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:51:58.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.072 seconds
[2025-04-14T12:52:15.033+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:15.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:15.039+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:15.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:15.070+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:15.069+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 18
    object_name="code/main_spark.py"
                
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-04-14T12:52:15.072+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:15.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.075 seconds
[2025-04-14T12:52:26.161+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:26.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:26.165+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:26.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:26.202+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:26.196+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 29, in <module>
    upload_spark_to_gcs = LocalFilesystemToGoogleCloudStorageOperator(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'LocalFilesystemToGoogleCloudStorageOperator' is not defined
[2025-04-14T12:52:26.205+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:26.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.074 seconds
[2025-04-14T12:52:27.190+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:27.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:27.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:27.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:27.233+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:27.226+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 29, in <module>
    upload_spark_to_gcs = LocalFilesystemToGoogleCloudStorageOperator(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'LocalFilesystemToGoogleCloudStorageOperator' is not defined
[2025-04-14T12:52:27.236+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:27.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.076 seconds
[2025-04-14T12:52:36.150+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:36.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:36.154+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:36.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:36.201+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:36.538+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:36.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:52:36.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:36.554+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:52:36.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.450 seconds
[2025-04-14T12:52:49.790+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:49.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:49.794+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:49.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:49.836+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:49.852+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:49.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:52:49.869+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:49.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:52:49.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T12:52:51.866+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:51.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:52:51.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:51.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:51.919+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:52:51.943+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:51.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:52:51.967+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:52:51.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:52:52.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T12:53:08.242+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:08.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:53:08.248+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:08.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:08.301+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:08.340+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:08.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:53:08.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:08.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:53:08.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.171 seconds
[2025-04-14T12:53:30.490+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:30.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:53:30.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:30.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:30.529+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:53:30.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:30.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:53:30.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:53:30.578+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:53:30.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T12:54:01.093+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:01.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:54:01.099+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:01.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:01.123+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:01.151+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:01.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:54:01.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:01.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:54:01.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T12:54:31.601+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:31.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:54:31.607+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:31.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:31.635+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:54:31.668+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:31.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:54:31.691+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:54:31.690+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:54:31.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T12:55:02.087+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:02.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:55:02.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:02.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:02.113+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:02.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:02.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:55:02.154+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:02.153+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:55:02.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T12:55:32.550+0000] {processor.py:186} INFO - Started process (PID=530) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:32.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:55:32.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:32.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:32.573+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:55:32.598+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:32.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:55:32.613+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:55:32.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:55:32.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T12:56:02.775+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:02.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:56:02.782+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:02.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:02.807+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:02.838+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:02.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:56:02.869+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:02.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:56:02.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T12:56:33.294+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:33.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:56:33.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:33.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:33.337+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:56:33.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:33.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:56:33.390+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:56:33.389+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:56:33.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T12:57:03.639+0000] {processor.py:186} INFO - Started process (PID=584) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:03.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:57:03.643+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:03.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:03.666+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:03.691+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:03.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:57:03.705+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:03.705+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:57:03.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T12:57:34.123+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:34.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:57:34.127+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:34.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:34.152+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:57:34.178+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:34.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:57:34.192+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:57:34.192+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:57:34.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T12:58:04.628+0000] {processor.py:186} INFO - Started process (PID=619) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:04.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:58:04.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:04.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:04.735+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:04.774+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:04.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:58:04.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:04.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:58:04.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.201 seconds
[2025-04-14T12:58:34.894+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:34.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:58:34.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:34.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:34.925+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:58:34.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:34.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:58:34.971+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:58:34.970+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:58:35.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T12:59:05.370+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:59:05.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T12:59:05.374+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:59:05.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:59:05.396+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T12:59:05.421+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:59:05.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T12:59:05.436+0000] {logging_mixin.py:190} INFO - [2025-04-14T12:59:05.436+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T12:59:05.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T13:00:48.585+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:00:48.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:00:48.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:00:48.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:00:48.620+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:00:48.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:00:48.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:00:48.675+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:00:48.675+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:00:48.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T13:01:19.086+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:19.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:01:19.096+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:19.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:19.143+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:19.207+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:19.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:01:19.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:19.259+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:01:19.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.235 seconds
[2025-04-14T13:01:49.745+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:49.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:01:49.750+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:49.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:49.779+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:01:49.816+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:49.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:01:49.839+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:01:49.839+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:01:49.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T13:02:20.234+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:20.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:02:20.238+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:20.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:20.274+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:20.314+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:20.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:02:20.340+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:20.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:02:20.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T13:02:50.720+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:50.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:02:50.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:50.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:50.747+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:02:50.773+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:50.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:02:50.789+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:02:50.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:02:50.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T13:03:21.177+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:21.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:03:21.181+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:21.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:21.207+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:21.232+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:21.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:03:21.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:21.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:03:21.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T13:03:51.630+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:51.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:03:51.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:51.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:51.657+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:03:51.683+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:51.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:03:51.700+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:03:51.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:03:51.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T13:04:22.329+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:22.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:04:22.334+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:22.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:22.361+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:22.391+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:22.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:04:22.407+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:22.406+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:04:22.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T13:04:46.502+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:46.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:04:46.506+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:46.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:46.541+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:04:46.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:46.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:04:46.580+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:04:46.580+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:04:46.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T13:05:16.871+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:16.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:05:16.874+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:16.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:16.897+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:16.921+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:16.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:05:16.935+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:16.935+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:05:16.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T13:05:47.307+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:47.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:05:47.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:47.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:47.336+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:05:47.363+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:47.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:05:47.378+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:05:47.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:05:47.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T13:06:09.708+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:09.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:06:09.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:09.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:09.759+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:09.791+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:09.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:06:09.810+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:09.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:06:09.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.157 seconds
[2025-04-14T13:06:40.262+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:40.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:06:40.266+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:40.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:40.291+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:06:40.320+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:40.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:06:40.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:06:40.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:06:40.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T13:07:10.707+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:10.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:07:10.710+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:10.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:10.734+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:10.760+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:10.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:07:10.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:10.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:07:10.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T13:07:41.163+0000] {processor.py:186} INFO - Started process (PID=466) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:41.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:07:41.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:41.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:41.203+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:07:41.232+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:41.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:07:41.249+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:07:41.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:07:41.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T13:08:11.355+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:11.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:08:11.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:11.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:11.386+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:11.413+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:11.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:08:11.429+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:11.429+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:08:11.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T13:08:41.828+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:41.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:08:41.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:41.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:41.855+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:08:41.884+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:41.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:08:41.901+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:08:41.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:08:41.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T13:09:12.295+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:12.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:09:12.298+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:12.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:12.322+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:12.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:12.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:09:12.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:12.361+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:09:12.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T13:09:42.570+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:42.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:09:42.575+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:42.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:42.608+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:09:42.658+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:42.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:09:42.708+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:09:42.708+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:09:42.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.191 seconds
[2025-04-14T13:10:11.010+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:11.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:10:11.013+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:11.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:11.050+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:11.082+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:11.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:10:11.104+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:11.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:10:11.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T13:10:13.114+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:13.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:10:13.118+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:13.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:13.158+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:13.193+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:13.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:10:13.213+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:13.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:10:13.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T13:10:31.394+0000] {processor.py:186} INFO - Started process (PID=561) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:31.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:10:31.398+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:31.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:31.463+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:31.496+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:31.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:10:31.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:31.518+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:10:31.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.182 seconds
[2025-04-14T13:10:51.457+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:51.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:10:51.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:51.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:51.498+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:10:51.534+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:51.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:10:51.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:10:51.559+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:10:51.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.182 seconds
[2025-04-14T13:11:22.183+0000] {processor.py:186} INFO - Started process (PID=646) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:22.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:11:22.186+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:22.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:22.217+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:22.258+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:22.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:11:22.285+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:22.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:11:22.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.139 seconds
[2025-04-14T13:11:52.439+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:52.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:11:52.446+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:52.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:52.481+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:11:52.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:52.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:11:52.538+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:11:52.538+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:11:52.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T13:12:22.939+0000] {processor.py:186} INFO - Started process (PID=688) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:22.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:12:22.942+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:22.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:22.973+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:23.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:23.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:12:23.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:23.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:12:23.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T13:12:53.405+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:53.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:12:53.409+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:53.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:53.442+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:12:53.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:53.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:12:53.502+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:12:53.502+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:12:53.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T13:13:23.774+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:23.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:13:23.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:23.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:23.816+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:23.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:23.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:13:23.884+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:23.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:13:23.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.150 seconds
[2025-04-14T13:13:54.193+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:54.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:13:54.197+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:54.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:54.227+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:13:54.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:54.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:13:54.279+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:13:54.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:13:54.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T13:14:24.721+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:24.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:14:24.725+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:24.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:24.754+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:24.793+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:24.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:14:24.815+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:24.814+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:14:24.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T13:14:55.586+0000] {processor.py:186} INFO - Started process (PID=792) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:55.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:14:55.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:55.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:55.630+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:14:55.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:55.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:14:55.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:14:55.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:14:55.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.212 seconds
[2025-04-14T13:15:25.916+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:25.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:15:25.920+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:25.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:25.945+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:25.977+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:25.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:15:26.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:26.002+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:15:26.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T13:15:56.133+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:56.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:15:56.136+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:56.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:56.169+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:15:56.204+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:56.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:15:56.233+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:15:56.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:15:56.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T13:16:26.662+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:26.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:16:26.666+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:26.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:26.698+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:26.743+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:26.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:16:26.767+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:26.767+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:16:26.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T13:16:56.956+0000] {processor.py:186} INFO - Started process (PID=936) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:56.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:16:56.959+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:56.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:56.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:16:57.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:57.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:16:57.047+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:16:57.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:16:57.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T13:17:27.617+0000] {processor.py:186} INFO - Started process (PID=996) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:27.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:17:27.620+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:27.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:27.650+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:27.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:27.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:17:27.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:27.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:17:27.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T13:17:57.806+0000] {processor.py:186} INFO - Started process (PID=1027) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:57.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:17:57.809+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:57.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:57.836+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:17:57.865+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:57.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:17:57.882+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:17:57.882+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:17:57.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T13:18:28.277+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:28.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:18:28.281+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:28.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:28.308+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:28.341+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:28.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:18:28.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:28.360+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:18:28.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T13:18:58.895+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:58.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:18:58.899+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:58.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:58.939+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:18:58.976+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:58.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:18:58.996+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:18:58.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:18:59.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.172 seconds
[2025-04-14T13:19:29.287+0000] {processor.py:186} INFO - Started process (PID=1168) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:29.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:19:29.290+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:29.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:29.316+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:29.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:29.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:19:29.367+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:29.367+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:19:29.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T13:19:59.606+0000] {processor.py:186} INFO - Started process (PID=1228) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:59.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:19:59.611+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:59.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:59.637+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:19:59.666+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:59.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:19:59.683+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:19:59.683+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:19:59.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T13:20:29.789+0000] {processor.py:186} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:20:29.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:20:29.793+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:20:29.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:20:29.818+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:20:29.843+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:20:29.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:20:29.857+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:20:29.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:20:29.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:21:00.304+0000] {processor.py:186} INFO - Started process (PID=1346) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:00.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:21:00.307+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:00.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:00.329+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:00.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:00.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:21:00.369+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:00.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:21:00.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T13:21:30.730+0000] {processor.py:186} INFO - Started process (PID=1405) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:30.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:21:30.733+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:30.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:30.756+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:21:30.782+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:30.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:21:30.799+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:21:30.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:21:30.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T13:22:01.173+0000] {processor.py:186} INFO - Started process (PID=1464) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:01.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:22:01.176+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:01.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:01.200+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:01.228+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:01.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:22:01.250+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:01.250+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:22:01.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T13:22:31.627+0000] {processor.py:186} INFO - Started process (PID=1523) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:31.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:22:31.630+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:31.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:31.660+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:22:31.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:31.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:22:31.700+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:22:31.700+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:22:31.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T13:23:02.054+0000] {processor.py:186} INFO - Started process (PID=1568) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:02.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:23:02.056+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:02.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:02.078+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:02.103+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:02.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:23:02.118+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:02.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:23:02.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.091 seconds
[2025-04-14T13:23:32.497+0000] {processor.py:186} INFO - Started process (PID=1585) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:32.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:23:32.500+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:32.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:32.521+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:23:32.547+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:32.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:23:32.561+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:23:32.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:23:32.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T13:24:02.922+0000] {processor.py:186} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:02.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:24:02.926+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:02.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:02.949+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:02.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:02.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:24:02.989+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:02.989+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:24:03.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T13:24:33.366+0000] {processor.py:186} INFO - Started process (PID=1619) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:33.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:24:33.369+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:33.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:33.391+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:24:33.418+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:33.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:24:33.434+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:24:33.434+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:24:33.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T13:25:03.828+0000] {processor.py:186} INFO - Started process (PID=1636) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:03.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:25:03.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:03.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:03.855+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:03.882+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:03.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:25:03.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:03.897+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:25:03.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T13:25:34.255+0000] {processor.py:186} INFO - Started process (PID=1653) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:34.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:25:34.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:34.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:34.285+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:25:34.316+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:34.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:25:34.336+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:25:34.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:25:34.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T13:26:04.716+0000] {processor.py:186} INFO - Started process (PID=1670) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:04.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:26:04.719+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:04.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:04.744+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:04.771+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:04.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:26:04.787+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:04.786+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:26:04.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T13:26:35.141+0000] {processor.py:186} INFO - Started process (PID=1687) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:35.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:26:35.145+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:35.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:35.167+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:26:35.192+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:35.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:26:35.207+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:26:35.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:26:35.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T13:27:05.598+0000] {processor.py:186} INFO - Started process (PID=1704) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:05.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:27:05.602+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:05.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:05.626+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:05.651+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:05.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:27:05.665+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:05.665+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:27:05.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:27:36.028+0000] {processor.py:186} INFO - Started process (PID=1721) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:36.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:27:36.031+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:36.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:36.054+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:27:36.078+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:36.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:27:36.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:27:36.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:27:36.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T13:28:06.447+0000] {processor.py:186} INFO - Started process (PID=1738) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:06.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:28:06.450+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:06.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:06.474+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:06.498+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:06.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:28:06.513+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:06.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:28:06.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T13:28:36.873+0000] {processor.py:186} INFO - Started process (PID=1755) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:36.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:28:36.876+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:36.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:36.899+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:28:36.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:36.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:28:36.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:28:36.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:28:36.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:29:07.301+0000] {processor.py:186} INFO - Started process (PID=1772) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:07.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:29:07.304+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:07.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:07.327+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:07.352+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:07.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:29:07.367+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:07.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:29:07.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T13:29:37.760+0000] {processor.py:186} INFO - Started process (PID=1789) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:37.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:29:37.764+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:37.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:37.789+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:29:37.818+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:37.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:29:37.837+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:29:37.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:29:37.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T13:30:08.270+0000] {processor.py:186} INFO - Started process (PID=1806) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:08.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:30:08.273+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:08.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:08.299+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:08.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:08.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:30:08.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:08.350+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:30:08.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T13:30:38.827+0000] {processor.py:186} INFO - Started process (PID=1823) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:38.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:30:38.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:38.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:38.861+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:30:38.886+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:38.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:30:38.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:30:38.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:30:38.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T13:31:09.320+0000] {processor.py:186} INFO - Started process (PID=1840) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:09.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:31:09.322+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:09.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:09.344+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:09.371+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:09.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:31:09.388+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:09.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:31:09.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T13:31:39.760+0000] {processor.py:186} INFO - Started process (PID=1857) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:39.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:31:39.762+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:39.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:39.789+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:31:39.816+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:39.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:31:39.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:31:39.831+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:31:39.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T13:32:10.185+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:10.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:32:10.188+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:10.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:10.211+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:10.240+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:10.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:32:10.260+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:10.259+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:32:10.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T13:32:40.641+0000] {processor.py:186} INFO - Started process (PID=1891) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:40.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:32:40.647+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:40.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:40.683+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:32:40.721+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:40.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:32:40.744+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:32:40.743+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:32:40.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T13:33:11.236+0000] {processor.py:186} INFO - Started process (PID=1908) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:11.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:33:11.241+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:11.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:11.278+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:11.312+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:11.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:33:11.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:11.330+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:33:11.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T13:33:41.664+0000] {processor.py:186} INFO - Started process (PID=1959) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:41.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:33:41.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:41.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:41.700+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:33:41.734+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:41.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:33:41.751+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:33:41.751+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:33:41.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T13:34:11.869+0000] {processor.py:186} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:11.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:34:11.873+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:11.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:11.902+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:11.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:11.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:34:11.958+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:11.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:34:11.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T13:34:42.210+0000] {processor.py:186} INFO - Started process (PID=2071) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:42.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:34:42.213+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:42.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:42.240+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:34:42.266+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:42.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:34:42.281+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:34:42.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:34:42.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T13:35:12.663+0000] {processor.py:186} INFO - Started process (PID=2130) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:12.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:35:12.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:12.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:12.697+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:12.727+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:12.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:35:12.744+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:12.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:35:12.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T13:35:43.794+0000] {processor.py:186} INFO - Started process (PID=2189) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:43.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:35:43.798+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:43.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:43.828+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:35:43.861+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:43.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:35:43.879+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:35:43.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:35:43.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T13:36:14.399+0000] {processor.py:186} INFO - Started process (PID=2247) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:14.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:36:14.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:14.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:14.429+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:14.459+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:14.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:36:14.476+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:14.476+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:36:14.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T13:36:44.892+0000] {processor.py:186} INFO - Started process (PID=2306) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:44.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:36:44.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:44.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:44.922+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:36:44.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:44.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:36:44.963+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:36:44.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:36:44.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T13:37:15.366+0000] {processor.py:186} INFO - Started process (PID=2365) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:15.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:37:15.369+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:15.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:15.394+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:15.428+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:15.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:37:15.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:15.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:37:15.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T13:37:45.897+0000] {processor.py:186} INFO - Started process (PID=2424) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:45.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:37:45.902+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:45.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:45.934+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:37:45.966+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:45.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:37:45.982+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:37:45.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:37:46.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T13:38:16.695+0000] {processor.py:186} INFO - Started process (PID=2469) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:16.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:38:16.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:16.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:16.722+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:16.749+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:16.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:38:16.766+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:16.766+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:38:16.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T13:38:46.947+0000] {processor.py:186} INFO - Started process (PID=2486) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:46.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:38:46.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:46.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:46.976+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:38:47.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:47.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:38:47.042+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:38:47.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:38:47.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T13:39:17.483+0000] {processor.py:186} INFO - Started process (PID=2503) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:17.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:39:17.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:17.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:17.513+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:17.548+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:17.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:39:17.572+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:17.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:39:17.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T13:39:47.975+0000] {processor.py:186} INFO - Started process (PID=2520) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:47.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:39:47.978+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:47.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:48.006+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:39:48.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:48.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:39:48.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:39:48.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:39:48.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T13:40:18.470+0000] {processor.py:186} INFO - Started process (PID=2537) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:18.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:40:18.473+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:18.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:18.498+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:18.535+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:18.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:40:18.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:18.554+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:40:18.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T13:40:48.980+0000] {processor.py:186} INFO - Started process (PID=2554) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:48.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:40:48.985+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:48.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:49.016+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:40:49.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:49.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:40:49.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:40:49.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:40:49.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T13:41:19.330+0000] {processor.py:186} INFO - Started process (PID=2571) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:19.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:41:19.333+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:19.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:19.358+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:19.397+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:19.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:41:19.418+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:19.417+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:41:19.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T13:41:49.848+0000] {processor.py:186} INFO - Started process (PID=2588) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:49.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:41:49.851+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:49.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:49.873+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:41:49.900+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:49.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:41:49.914+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:41:49.914+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:41:49.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T13:42:20.184+0000] {processor.py:186} INFO - Started process (PID=2605) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:20.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:42:20.191+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:20.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:20.224+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:20.260+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:20.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:42:20.279+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:20.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:42:20.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T13:42:50.708+0000] {processor.py:186} INFO - Started process (PID=2622) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:50.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:42:50.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:50.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:50.736+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:42:50.768+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:50.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:42:50.799+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:42:50.798+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:42:50.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T13:43:20.985+0000] {processor.py:186} INFO - Started process (PID=2639) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:20.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:43:20.989+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:20.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:21.013+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:21.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:21.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:43:21.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:21.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:43:21.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T13:43:51.880+0000] {processor.py:186} INFO - Started process (PID=2656) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:51.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:43:51.886+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:51.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:51.939+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:43:51.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:51.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:43:51.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:43:51.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:43:52.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.152 seconds
[2025-04-14T13:44:22.388+0000] {processor.py:186} INFO - Started process (PID=2673) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:22.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:44:22.390+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:22.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:22.416+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:22.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:22.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:44:22.460+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:22.460+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:44:22.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T13:44:52.878+0000] {processor.py:186} INFO - Started process (PID=2691) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:52.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:44:52.882+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:52.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:52.909+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:44:52.942+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:52.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:44:52.961+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:44:52.961+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:44:52.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T13:45:23.097+0000] {processor.py:186} INFO - Started process (PID=2708) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:23.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:45:23.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:23.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:23.127+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:23.154+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:23.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:45:23.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:23.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:45:23.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T13:45:53.655+0000] {processor.py:186} INFO - Started process (PID=2725) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:53.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:45:53.658+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:53.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:53.681+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:45:53.707+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:53.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:45:53.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:45:53.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:45:53.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T13:46:24.113+0000] {processor.py:186} INFO - Started process (PID=2742) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:24.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:46:24.117+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:24.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:24.142+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:24.178+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:24.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:46:24.202+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:24.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:46:24.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T13:46:54.606+0000] {processor.py:186} INFO - Started process (PID=2760) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:54.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:46:54.610+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:54.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:54.633+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:46:54.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:54.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:46:54.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:46:54.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:46:54.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T13:47:24.866+0000] {processor.py:186} INFO - Started process (PID=2778) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:24.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:47:24.871+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:24.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:24.899+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:24.930+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:24.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:47:24.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:24.947+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:47:24.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T13:47:55.364+0000] {processor.py:186} INFO - Started process (PID=2795) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:55.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:47:55.368+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:55.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:55.395+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:47:55.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:55.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:47:55.442+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:47:55.442+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:47:55.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T13:48:25.564+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:25.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:48:25.571+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:25.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:25.596+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:25.638+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:25.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:48:25.657+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:25.657+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:48:25.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T13:48:56.076+0000] {processor.py:186} INFO - Started process (PID=2829) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:56.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:48:56.079+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:56.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:56.100+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:48:56.127+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:56.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:48:56.147+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:48:56.147+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:48:56.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T13:49:26.358+0000] {processor.py:186} INFO - Started process (PID=2846) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:26.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:49:26.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:26.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:26.384+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:26.411+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:26.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:49:26.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:26.426+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:49:26.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T13:49:56.868+0000] {processor.py:186} INFO - Started process (PID=2863) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:56.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:49:56.871+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:56.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:56.899+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:49:56.932+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:56.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:49:56.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:49:56.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:49:56.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T13:50:27.049+0000] {processor.py:186} INFO - Started process (PID=2880) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:27.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:50:27.051+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:27.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:27.081+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:27.110+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:27.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:50:27.128+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:27.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:50:27.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T13:50:57.573+0000] {processor.py:186} INFO - Started process (PID=2897) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:57.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:50:57.577+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:57.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:57.609+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:50:57.640+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:57.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:50:57.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:50:57.656+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:50:57.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T13:51:27.927+0000] {processor.py:186} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:27.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:51:27.930+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:27.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:27.952+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:27.984+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:27.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:51:28.002+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:28.001+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:51:28.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T13:51:58.400+0000] {processor.py:186} INFO - Started process (PID=2931) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:58.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:51:58.406+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:58.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:58.435+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:51:58.463+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:58.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:51:58.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:51:58.481+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:51:58.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T13:52:28.859+0000] {processor.py:186} INFO - Started process (PID=2948) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:28.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:52:28.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:28.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:28.883+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:28.912+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:28.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:52:28.929+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:28.929+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:52:28.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T13:52:59.093+0000] {processor.py:186} INFO - Started process (PID=2966) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:59.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:52:59.097+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:59.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:59.123+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:52:59.151+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:59.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:52:59.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:52:59.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:52:59.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T13:53:29.550+0000] {processor.py:186} INFO - Started process (PID=2983) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:53:29.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:53:29.553+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:53:29.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:53:29.577+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:53:29.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:53:29.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:53:29.618+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:53:29.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:53:29.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T13:54:00.021+0000] {processor.py:186} INFO - Started process (PID=3000) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:00.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:54:00.024+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:00.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:00.047+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:00.073+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:00.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:54:00.088+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:00.088+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:54:00.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T13:54:30.463+0000] {processor.py:186} INFO - Started process (PID=3017) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:30.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:54:30.465+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:30.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:30.488+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:54:30.515+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:30.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:54:30.530+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:54:30.530+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:54:30.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T13:55:01.223+0000] {processor.py:186} INFO - Started process (PID=3034) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:01.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:55:01.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:01.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:01.259+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:01.320+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:01.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:55:01.393+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:01.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:55:01.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.281 seconds
[2025-04-14T13:55:31.832+0000] {processor.py:186} INFO - Started process (PID=3045) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:31.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:55:31.835+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:31.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:31.857+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:55:31.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:31.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:55:31.909+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:55:31.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:55:31.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T13:56:02.104+0000] {processor.py:186} INFO - Started process (PID=3062) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:02.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:56:02.109+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:02.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:02.131+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:02.162+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:02.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:56:02.180+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:02.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:56:02.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T13:56:32.558+0000] {processor.py:186} INFO - Started process (PID=3079) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:32.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:56:32.561+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:32.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:32.585+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:56:32.610+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:32.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:56:32.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:56:32.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:56:32.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:57:03.039+0000] {processor.py:186} INFO - Started process (PID=3096) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:03.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:57:03.042+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:03.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:03.065+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:03.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:03.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:57:03.105+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:03.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:57:03.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:57:33.512+0000] {processor.py:186} INFO - Started process (PID=3113) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:33.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:57:33.515+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:33.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:33.540+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:57:33.572+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:33.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:57:33.595+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:57:33.595+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:57:33.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T13:58:03.869+0000] {processor.py:186} INFO - Started process (PID=3130) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:03.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:58:03.872+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:03.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:03.898+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:03.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:03.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:58:03.939+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:03.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:58:03.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T13:58:34.322+0000] {processor.py:186} INFO - Started process (PID=3147) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:34.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:58:34.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:34.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:34.348+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:58:34.379+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:34.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:58:34.398+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:58:34.398+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:58:34.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T13:59:04.795+0000] {processor.py:186} INFO - Started process (PID=3164) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:04.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:59:04.798+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:04.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:04.819+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:04.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:04.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:59:04.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:04.862+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:59:04.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T13:59:35.245+0000] {processor.py:186} INFO - Started process (PID=3181) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:35.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T13:59:35.248+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:35.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:35.272+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T13:59:35.299+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:35.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T13:59:35.314+0000] {logging_mixin.py:190} INFO - [2025-04-14T13:59:35.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T13:59:35.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T14:00:05.579+0000] {processor.py:186} INFO - Started process (PID=3198) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:05.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:00:05.583+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:05.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:05.608+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:05.645+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:05.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:00:05.665+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:05.665+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:00:05.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T14:00:36.589+0000] {processor.py:186} INFO - Started process (PID=3215) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:36.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:00:36.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:36.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:36.619+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:00:36.646+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:36.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:00:36.662+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:00:36.661+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:00:36.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:01:06.840+0000] {processor.py:186} INFO - Started process (PID=3232) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:06.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:01:06.843+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:06.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:06.868+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:06.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:06.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:01:06.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:06.921+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:01:06.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T14:01:37.333+0000] {processor.py:186} INFO - Started process (PID=3249) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:37.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:01:37.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:37.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:37.363+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:01:37.397+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:37.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:01:37.420+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:01:37.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:01:37.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T14:02:07.828+0000] {processor.py:186} INFO - Started process (PID=3266) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:07.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:02:07.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:07.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:07.854+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:07.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:07.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:02:07.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:07.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:02:07.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T14:02:38.238+0000] {processor.py:186} INFO - Started process (PID=3283) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:38.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:02:38.241+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:38.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:38.266+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:02:38.292+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:38.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:02:38.307+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:02:38.307+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:02:38.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T14:03:08.718+0000] {processor.py:186} INFO - Started process (PID=3300) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:08.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:03:08.722+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:08.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:08.749+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:08.778+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:08.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:03:08.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:08.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:03:08.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T14:03:38.979+0000] {processor.py:186} INFO - Started process (PID=3317) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:38.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:03:38.984+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:38.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:39.015+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:03:39.043+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:39.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:03:39.059+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:03:39.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:03:39.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T14:04:09.162+0000] {processor.py:186} INFO - Started process (PID=3335) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:09.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:04:09.166+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:09.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:09.195+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:09.230+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:09.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:04:09.255+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:09.254+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:04:09.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T14:04:39.566+0000] {processor.py:186} INFO - Started process (PID=3352) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:39.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:04:39.570+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:39.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:39.599+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:04:39.627+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:39.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:04:39.646+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:04:39.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:04:39.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T14:05:09.970+0000] {processor.py:186} INFO - Started process (PID=3369) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:09.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:05:09.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:09.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:10.011+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:10.046+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:10.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:05:10.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:10.066+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:05:10.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T14:05:40.298+0000] {processor.py:186} INFO - Started process (PID=3387) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:40.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:05:40.303+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:40.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:40.325+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:05:40.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:40.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:05:40.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:05:40.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:05:40.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T14:06:10.463+0000] {processor.py:186} INFO - Started process (PID=3404) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:10.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:06:10.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:10.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:10.489+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:10.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:10.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:06:10.537+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:10.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:06:10.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T14:06:40.638+0000] {processor.py:186} INFO - Started process (PID=3421) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:40.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:06:40.643+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:40.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:40.670+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:06:40.702+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:40.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:06:40.719+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:06:40.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:06:40.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T14:07:10.934+0000] {processor.py:186} INFO - Started process (PID=3438) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:10.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:07:10.937+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:10.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:10.961+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:11.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:10.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:07:11.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:11.018+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:07:11.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:07:41.420+0000] {processor.py:186} INFO - Started process (PID=3455) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:41.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:07:41.423+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:41.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:41.448+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:07:41.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:41.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:07:41.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:07:41.495+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:07:41.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T14:08:11.891+0000] {processor.py:186} INFO - Started process (PID=3472) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:11.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:08:11.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:11.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:11.929+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:11.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:11.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:08:12.046+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:12.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:08:12.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.245 seconds
[2025-04-14T14:08:42.543+0000] {processor.py:186} INFO - Started process (PID=3490) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:42.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:08:42.547+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:42.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:42.579+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:08:42.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:42.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:08:42.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:08:42.634+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:08:42.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T14:09:13.030+0000] {processor.py:186} INFO - Started process (PID=3507) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:13.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:09:13.033+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:13.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:13.059+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:13.085+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:13.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:09:13.099+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:13.099+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:09:13.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T14:09:43.619+0000] {processor.py:186} INFO - Started process (PID=3524) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:43.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:09:43.622+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:43.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:43.647+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:09:43.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:43.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:09:43.694+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:09:43.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:09:43.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T14:10:14.090+0000] {processor.py:186} INFO - Started process (PID=3541) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:14.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:10:14.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:14.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:14.113+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:14.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:14.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:10:14.156+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:14.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:10:14.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T14:10:44.558+0000] {processor.py:186} INFO - Started process (PID=3558) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:44.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:10:44.561+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:44.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:44.589+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:10:44.627+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:44.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:10:44.647+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:10:44.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:10:44.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T14:11:14.926+0000] {processor.py:186} INFO - Started process (PID=3581) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:14.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:11:14.931+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:14.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:14.953+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:14.982+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:14.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:11:15.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:15.001+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:11:15.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T14:11:47.633+0000] {processor.py:186} INFO - Started process (PID=3594) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:47.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:11:47.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:47.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:47.663+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:11:47.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:47.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:11:47.727+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:11:47.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:11:47.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T14:12:17.928+0000] {processor.py:186} INFO - Started process (PID=3609) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:17.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:12:17.931+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:17.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:17.956+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:17.982+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:17.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:12:17.998+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:17.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:12:18.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T14:12:48.144+0000] {processor.py:186} INFO - Started process (PID=3625) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:48.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:12:48.147+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:48.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:48.180+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:12:48.215+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:48.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:12:48.247+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:12:48.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:12:48.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T14:13:18.476+0000] {processor.py:186} INFO - Started process (PID=3642) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:18.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:13:18.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:18.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:18.505+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:18.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:18.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:13:18.549+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:18.548+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:13:18.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T14:13:48.899+0000] {processor.py:186} INFO - Started process (PID=3659) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:48.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:13:48.902+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:48.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:48.925+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:13:48.953+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:48.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:13:48.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:13:48.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:13:48.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T14:14:19.341+0000] {processor.py:186} INFO - Started process (PID=3682) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:19.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:14:19.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:19.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:19.368+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:19.394+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:19.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:14:19.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:19.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:14:19.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T14:14:49.659+0000] {processor.py:186} INFO - Started process (PID=3693) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:49.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:14:49.663+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:49.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:49.684+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:14:49.716+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:49.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:14:49.735+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:14:49.735+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:14:49.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:15:20.167+0000] {processor.py:186} INFO - Started process (PID=3710) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:20.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:15:20.174+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:20.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:20.212+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:20.260+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:20.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:15:20.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:20.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:15:20.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.162 seconds
[2025-04-14T14:15:50.408+0000] {processor.py:186} INFO - Started process (PID=3727) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:50.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:15:50.411+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:50.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:50.436+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:15:50.466+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:50.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:15:50.483+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:15:50.483+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:15:50.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T14:16:20.643+0000] {processor.py:186} INFO - Started process (PID=3744) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:20.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:16:20.647+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:20.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:20.673+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:20.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:20.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:16:20.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:20.719+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:16:20.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:16:50.807+0000] {processor.py:186} INFO - Started process (PID=3761) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:50.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:16:50.811+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:50.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:50.837+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:16:50.863+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:50.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:16:50.884+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:16:50.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:16:50.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:17:21.296+0000] {processor.py:186} INFO - Started process (PID=3778) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:21.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:17:21.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:21.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:21.326+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:21.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:21.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:17:21.371+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:21.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:17:21.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:17:51.477+0000] {processor.py:186} INFO - Started process (PID=3795) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:51.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:17:51.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:51.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:51.503+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:17:51.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:51.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:17:51.547+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:17:51.546+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:17:51.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T14:18:21.973+0000] {processor.py:186} INFO - Started process (PID=3812) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:21.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:18:21.976+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:21.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:22.002+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:22.033+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:22.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:18:22.049+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:22.049+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:18:22.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T14:18:52.476+0000] {processor.py:186} INFO - Started process (PID=3829) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:52.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:18:52.479+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:52.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:52.504+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:18:52.530+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:52.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:18:52.545+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:18:52.545+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:18:52.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T14:19:22.944+0000] {processor.py:186} INFO - Started process (PID=3846) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:22.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:19:22.947+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:22.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:22.972+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:23.000+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:22.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:19:23.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:23.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:19:23.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T14:19:53.439+0000] {processor.py:186} INFO - Started process (PID=3863) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:53.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:19:53.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:53.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:53.468+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:19:53.499+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:53.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:19:53.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:19:53.518+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:19:53.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T14:20:24.322+0000] {processor.py:186} INFO - Started process (PID=3880) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:24.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:20:24.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:24.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:24.363+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:24.401+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:24.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:20:24.422+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:24.422+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:20:24.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T14:20:54.557+0000] {processor.py:186} INFO - Started process (PID=3902) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:54.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:20:54.561+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:54.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:54.595+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:20:54.631+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:54.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:20:54.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:20:54.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:20:54.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.193 seconds
[2025-04-14T14:21:25.158+0000] {processor.py:186} INFO - Started process (PID=3934) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:25.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:21:25.163+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:25.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:25.186+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:25.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:25.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:21:25.238+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:25.238+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:21:25.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T14:21:55.381+0000] {processor.py:186} INFO - Started process (PID=3960) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:55.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:21:55.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:55.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:55.407+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:21:55.436+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:55.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:21:55.457+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:21:55.456+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:21:55.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T14:22:25.927+0000] {processor.py:186} INFO - Started process (PID=3984) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:25.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:22:25.931+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:25.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:25.962+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:25.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:25.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:22:26.012+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:26.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:22:26.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T14:22:56.295+0000] {processor.py:186} INFO - Started process (PID=4006) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:56.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:22:56.298+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:56.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:56.320+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:22:56.346+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:56.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:22:56.364+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:22:56.363+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:22:56.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T14:23:26.557+0000] {processor.py:186} INFO - Started process (PID=4028) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:26.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:23:26.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:26.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:26.590+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:26.621+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:26.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:23:26.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:26.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:23:26.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T14:23:57.233+0000] {processor.py:186} INFO - Started process (PID=4051) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:57.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:23:57.238+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:57.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:57.262+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:23:57.303+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:57.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:23:57.322+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:23:57.321+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:23:57.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T14:24:27.805+0000] {processor.py:186} INFO - Started process (PID=4073) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:27.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:24:27.810+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:27.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:27.846+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:27.894+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:27.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:24:27.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:27.922+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:24:27.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.164 seconds
[2025-04-14T14:24:58.025+0000] {processor.py:186} INFO - Started process (PID=4095) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:58.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:24:58.028+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:58.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:58.049+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:24:58.074+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:58.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:24:58.089+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:24:58.088+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:24:58.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.092 seconds
[2025-04-14T14:25:28.183+0000] {processor.py:186} INFO - Started process (PID=4117) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:28.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:25:28.185+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:28.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:28.207+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:28.235+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:28.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:25:28.250+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:28.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:25:28.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T14:25:58.378+0000] {processor.py:186} INFO - Started process (PID=4139) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:58.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:25:58.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:58.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:58.413+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:25:58.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:58.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:25:58.466+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:25:58.466+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:25:58.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T14:26:28.660+0000] {processor.py:186} INFO - Started process (PID=4161) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:28.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:26:28.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:28.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:28.705+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:28.752+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:28.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:26:28.772+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:28.772+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:26:28.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.149 seconds
[2025-04-14T14:26:59.416+0000] {processor.py:186} INFO - Started process (PID=4196) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:59.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:26:59.419+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:59.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:59.441+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:26:59.474+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:59.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:26:59.491+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:26:59.491+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:26:59.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T14:27:30.397+0000] {processor.py:186} INFO - Started process (PID=4219) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:27:30.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:27:30.400+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:27:30.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:27:30.428+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:27:30.459+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:27:30.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:27:30.477+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:27:30.476+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:27:30.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:28:00.593+0000] {processor.py:186} INFO - Started process (PID=4241) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:00.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:28:00.596+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:00.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:00.621+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:00.651+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:00.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:28:00.670+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:00.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:28:00.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T14:28:31.005+0000] {processor.py:186} INFO - Started process (PID=4268) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:31.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:28:31.009+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:31.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:31.037+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:28:31.065+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:31.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:28:31.085+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:28:31.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:28:31.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T14:29:01.353+0000] {processor.py:186} INFO - Started process (PID=4290) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:01.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:29:01.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:01.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:01.402+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:01.438+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:01.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:29:01.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:01.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:29:01.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.158 seconds
[2025-04-14T14:29:31.640+0000] {processor.py:186} INFO - Started process (PID=4325) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:31.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:29:31.644+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:31.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:31.671+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:29:31.705+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:31.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:29:31.732+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:29:31.732+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:29:31.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T14:30:01.868+0000] {processor.py:186} INFO - Started process (PID=4347) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:01.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:30:01.872+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:01.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:01.898+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:01.937+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:01.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:30:01.962+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:01.961+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:30:01.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T14:30:32.391+0000] {processor.py:186} INFO - Started process (PID=4369) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:32.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:30:32.394+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:32.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:32.426+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:30:32.453+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:32.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:30:32.471+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:30:32.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:30:32.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T14:31:02.675+0000] {processor.py:186} INFO - Started process (PID=4412) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:02.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:31:02.679+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:02.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:02.701+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:02.726+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:02.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:31:02.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:02.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:31:02.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T14:31:32.925+0000] {processor.py:186} INFO - Started process (PID=4434) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:32.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:31:32.929+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:32.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:32.964+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:31:33.008+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:33.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:31:33.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:31:33.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:31:33.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T14:32:03.460+0000] {processor.py:186} INFO - Started process (PID=4456) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:03.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:32:03.463+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:03.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:03.485+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:03.513+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:03.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:32:03.529+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:03.529+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:32:03.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T14:32:33.971+0000] {processor.py:186} INFO - Started process (PID=4499) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:33.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:32:33.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:33.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:33.996+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:32:34.022+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:34.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:32:34.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:32:34.040+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:32:34.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T14:33:04.717+0000] {processor.py:186} INFO - Started process (PID=4521) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:04.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:33:04.721+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:04.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:04.747+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:04.798+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:04.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:33:04.826+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:04.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:33:04.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.158 seconds
[2025-04-14T14:33:35.275+0000] {processor.py:186} INFO - Started process (PID=4543) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:35.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:33:35.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:35.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:35.308+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:33:35.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:35.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:33:35.352+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:33:35.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:33:35.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T14:34:05.543+0000] {processor.py:186} INFO - Started process (PID=4565) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:05.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:34:05.547+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:05.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:05.569+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:05.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:05.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:34:05.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:05.609+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:34:05.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T14:34:35.740+0000] {processor.py:186} INFO - Started process (PID=4587) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:35.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:34:35.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:35.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:35.773+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:34:35.803+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:35.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:34:35.823+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:34:35.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:34:35.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T14:35:05.996+0000] {processor.py:186} INFO - Started process (PID=4609) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:05.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:35:05.999+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:05.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:06.025+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:06.051+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:06.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:35:06.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:06.067+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:35:06.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T14:35:36.386+0000] {processor.py:186} INFO - Started process (PID=4631) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:36.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:35:36.392+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:36.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:36.428+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:35:36.474+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:36.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:35:36.497+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:35:36.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:35:36.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T14:36:07.039+0000] {processor.py:186} INFO - Started process (PID=4680) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:07.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:36:07.041+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:07.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:07.065+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:07.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:07.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:36:07.106+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:07.105+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:36:07.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T14:36:37.641+0000] {processor.py:186} INFO - Started process (PID=4729) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:37.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:36:37.645+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:37.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:37.665+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:36:37.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:37.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:36:37.707+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:36:37.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:36:37.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T14:37:08.202+0000] {processor.py:186} INFO - Started process (PID=4778) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:08.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:37:08.221+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:08.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:08.419+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:09.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:09.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:37:10.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:10.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:37:10.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 1.888 seconds
[2025-04-14T14:37:40.869+0000] {processor.py:186} INFO - Started process (PID=4803) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:40.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:37:40.874+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:40.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:40.905+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:37:40.942+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:40.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:37:40.962+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:37:40.962+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:37:40.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T14:38:11.274+0000] {processor.py:186} INFO - Started process (PID=4825) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:11.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:38:11.278+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:11.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:11.300+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:11.327+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:11.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:38:11.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:11.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:38:11.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T14:38:41.902+0000] {processor.py:186} INFO - Started process (PID=4847) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:41.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:38:41.905+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:41.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:41.940+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:38:41.968+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:41.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:38:41.987+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:38:41.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:38:42.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T14:39:12.324+0000] {processor.py:186} INFO - Started process (PID=4869) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:12.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:39:12.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:12.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:12.372+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:12.404+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:12.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:39:12.421+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:12.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:39:12.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T14:39:42.867+0000] {processor.py:186} INFO - Started process (PID=4891) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:42.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:39:42.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:42.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:42.894+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:39:42.921+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:42.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:39:42.939+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:39:42.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:39:42.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:40:13.600+0000] {processor.py:186} INFO - Started process (PID=4913) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:13.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:40:13.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:13.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:13.631+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:13.662+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:13.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:40:13.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:13.685+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:40:13.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T14:40:44.515+0000] {processor.py:186} INFO - Started process (PID=4935) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:44.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:40:44.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:44.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:44.548+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:40:44.580+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:44.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:40:44.600+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:40:44.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:40:44.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T14:41:15.071+0000] {processor.py:186} INFO - Started process (PID=4957) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:15.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:41:15.078+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:15.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:15.116+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:15.161+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:15.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:41:15.182+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:15.182+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:41:15.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.158 seconds
[2025-04-14T14:41:45.346+0000] {processor.py:186} INFO - Started process (PID=4979) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:45.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:41:45.350+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:45.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:45.375+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:41:45.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:45.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:41:45.420+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:41:45.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:41:45.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T14:42:15.732+0000] {processor.py:186} INFO - Started process (PID=5001) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:15.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:42:15.736+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:15.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:15.759+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:15.787+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:15.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:42:15.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:15.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:42:15.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T14:42:45.941+0000] {processor.py:186} INFO - Started process (PID=5023) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:45.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:42:45.944+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:45.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:45.967+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:42:45.995+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:45.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:42:46.013+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:42:46.012+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:42:46.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:43:16.257+0000] {processor.py:186} INFO - Started process (PID=5045) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:16.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:43:16.261+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:16.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:16.296+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:16.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:16.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:43:16.356+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:16.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:43:16.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T14:43:46.678+0000] {processor.py:186} INFO - Started process (PID=5067) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:46.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:43:46.681+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:46.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:46.729+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:43:46.759+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:46.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:43:46.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:43:46.784+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:43:46.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.145 seconds
[2025-04-14T14:44:16.887+0000] {processor.py:186} INFO - Started process (PID=5089) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:16.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:44:16.890+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:16.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:16.929+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:16.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:16.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:44:17.002+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:17.002+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:44:17.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.157 seconds
[2025-04-14T14:44:47.400+0000] {processor.py:186} INFO - Started process (PID=5111) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:47.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:44:47.405+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:47.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:47.432+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:44:47.466+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:47.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:44:47.490+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:44:47.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:44:47.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T14:45:17.724+0000] {processor.py:186} INFO - Started process (PID=5133) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:17.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:45:17.727+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:17.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:17.748+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:17.782+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:17.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:45:17.810+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:17.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:45:17.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T14:45:48.280+0000] {processor.py:186} INFO - Started process (PID=5156) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:48.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:45:48.285+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:48.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:48.312+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:45:48.349+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:48.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:45:48.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:45:48.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:45:48.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T14:46:18.729+0000] {processor.py:186} INFO - Started process (PID=5178) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:18.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:46:18.731+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:18.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:18.756+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:18.788+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:18.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:46:18.822+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:18.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:46:18.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T14:46:49.189+0000] {processor.py:186} INFO - Started process (PID=5200) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:49.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:46:49.192+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:49.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:49.216+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:46:49.249+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:49.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:46:49.268+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:46:49.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:46:49.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T14:47:19.487+0000] {processor.py:186} INFO - Started process (PID=5222) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:19.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:47:19.489+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:19.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:19.513+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:19.541+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:19.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:47:19.558+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:19.558+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:47:19.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T14:47:49.976+0000] {processor.py:186} INFO - Started process (PID=5238) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:49.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:47:49.980+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:49.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:50.016+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:47:50.047+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:50.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:47:50.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:47:50.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:47:50.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T14:48:20.338+0000] {processor.py:186} INFO - Started process (PID=5260) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:20.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:48:20.341+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:20.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:20.363+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:20.391+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:20.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:48:20.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:20.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:48:20.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T14:48:50.755+0000] {processor.py:186} INFO - Started process (PID=5282) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:50.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:48:50.759+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:50.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:50.791+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:48:50.830+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:50.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:48:50.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:48:50.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:48:50.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T14:49:21.186+0000] {processor.py:186} INFO - Started process (PID=5304) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:21.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:49:21.196+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:21.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:21.253+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:21.324+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:21.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:49:21.380+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:21.380+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:49:21.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.284 seconds
[2025-04-14T14:49:51.909+0000] {processor.py:186} INFO - Started process (PID=5326) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:51.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:49:51.913+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:51.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:51.938+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:49:51.967+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:51.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:49:51.988+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:49:51.987+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:49:52.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T14:50:22.334+0000] {processor.py:186} INFO - Started process (PID=5349) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:22.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:50:22.337+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:22.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:22.364+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_parquet' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:22.391+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:22.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:50:22.409+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:22.409+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_parquet to None, run_after=None
[2025-04-14T14:50:22.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:50:39.457+0000] {processor.py:186} INFO - Started process (PID=5368) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:39.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:50:39.461+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:39.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:39.488+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:39.485+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 23
    "spark_csv_to_bigquery,
    ^
SyntaxError: unterminated string literal (detected at line 23)
[2025-04-14T14:50:39.489+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:39.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.063 seconds
[2025-04-14T14:50:41.587+0000] {processor.py:186} INFO - Started process (PID=5373) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:41.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:50:41.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:41.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:41.627+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:41.625+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job/spark_job.py", line 23
    "spark_csv_to_bigquery',
    ^
SyntaxError: unterminated string literal (detected at line 23)
[2025-04-14T14:50:41.629+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:41.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.090 seconds
[2025-04-14T14:50:46.780+0000] {processor.py:186} INFO - Started process (PID=5378) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:46.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:50:46.784+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:46.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:46.828+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:50:47.032+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.029+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:spark_csv_to_bigquery
[2025-04-14T14:50:47.048+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.047+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:spark_csv_to_bigquery
[2025-04-14T14:50:47.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.059+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:spark_csv_to_bigquery
[2025-04-14T14:50:47.070+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.069+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:spark_csv_to_bigquery
[2025-04-14T14:50:47.078+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.077+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:spark_csv_to_bigquery
[2025-04-14T14:50:47.090+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.090+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:spark_csv_to_bigquery
[2025-04-14T14:50:47.102+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.102+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:spark_csv_to_bigquery
[2025-04-14T14:50:47.103+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:50:47.121+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.121+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_csv_to_bigquery
[2025-04-14T14:50:47.122+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:50:47.122+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:50:47.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.372 seconds
[2025-04-14T14:51:17.355+0000] {processor.py:186} INFO - Started process (PID=5434) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:17.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:51:17.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:17.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:17.382+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:17.411+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:17.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:51:17.429+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:17.429+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:51:17.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T14:51:47.888+0000] {processor.py:186} INFO - Started process (PID=5456) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:47.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:51:47.896+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:47.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:47.927+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:51:47.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:47.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:51:47.984+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:51:47.984+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:51:48.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T14:52:18.863+0000] {processor.py:186} INFO - Started process (PID=5478) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:18.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:52:18.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:18.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:18.918+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:18.957+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:18.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:52:18.980+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:18.980+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:52:19.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.160 seconds
[2025-04-14T14:52:49.291+0000] {processor.py:186} INFO - Started process (PID=5500) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:49.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:52:49.294+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:49.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:49.315+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:52:49.349+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:49.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:52:49.366+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:52:49.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:52:49.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T14:53:19.851+0000] {processor.py:186} INFO - Started process (PID=5522) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:19.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:53:19.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:19.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:19.904+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:19.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:19.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:53:19.986+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:19.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:53:20.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.175 seconds
[2025-04-14T14:53:50.152+0000] {processor.py:186} INFO - Started process (PID=5578) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:50.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:53:50.156+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:50.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:50.199+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:53:50.260+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:50.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:53:50.287+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:53:50.287+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:53:50.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.183 seconds
[2025-04-14T14:54:21.122+0000] {processor.py:186} INFO - Started process (PID=5642) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:21.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:54:21.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:21.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:21.308+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:21.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:21.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:54:21.682+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:21.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:54:21.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.784 seconds
[2025-04-14T14:54:52.428+0000] {processor.py:186} INFO - Started process (PID=5664) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:52.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:54:52.447+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:52.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:52.501+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:54:52.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:52.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:54:52.648+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:54:52.647+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:54:53.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.660 seconds
[2025-04-14T14:55:23.676+0000] {processor.py:186} INFO - Started process (PID=5686) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:23.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:55:23.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:23.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:23.705+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:23.734+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:23.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:55:23.752+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:23.752+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:55:23.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T14:55:54.280+0000] {processor.py:186} INFO - Started process (PID=5708) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:54.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:55:54.284+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:54.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:54.310+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:55:54.353+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:54.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:55:54.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:55:54.381+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:55:54.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.144 seconds
[2025-04-14T14:56:24.843+0000] {processor.py:186} INFO - Started process (PID=5730) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:24.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:56:24.846+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:24.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:24.868+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:24.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:24.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:56:24.916+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:24.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:56:24.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T14:56:55.155+0000] {processor.py:186} INFO - Started process (PID=5752) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:55.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:56:55.159+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:55.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:55.180+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:56:55.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:55.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:56:55.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:56:55.229+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:56:55.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T14:57:25.629+0000] {processor.py:186} INFO - Started process (PID=5774) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:25.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:57:25.632+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:25.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:25.653+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:25.681+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:25.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:57:25.698+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:25.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:57:25.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T14:57:57.755+0000] {processor.py:186} INFO - Started process (PID=5825) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:57.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:57:57.994+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:57.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:58.090+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:57:58.137+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:58.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:57:58.159+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:57:58.159+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:57:58.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 1.690 seconds
[2025-04-14T14:58:28.728+0000] {processor.py:186} INFO - Started process (PID=5871) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:28.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:58:28.732+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:28.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:28.761+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:28.796+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:28.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:58:28.818+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:28.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:58:28.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T14:58:59.465+0000] {processor.py:186} INFO - Started process (PID=5941) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:59.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:58:59.469+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:59.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:59.500+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:58:59.534+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:59.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:58:59.555+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:58:59.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:58:59.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T14:59:29.839+0000] {processor.py:186} INFO - Started process (PID=5991) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:59:29.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T14:59:29.843+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:59:29.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:59:29.863+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T14:59:29.890+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:59:29.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T14:59:29.908+0000] {logging_mixin.py:190} INFO - [2025-04-14T14:59:29.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T14:59:29.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T15:00:00.263+0000] {processor.py:186} INFO - Started process (PID=6013) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:00.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:00:00.267+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:00.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:00.296+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:00.327+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:00.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:00:00.344+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:00.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:00:00.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T15:00:30.772+0000] {processor.py:186} INFO - Started process (PID=6035) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:30.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:00:30.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:30.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:30.799+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:00:30.826+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:30.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:00:30.841+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:00:30.841+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:00:30.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T15:01:01.257+0000] {processor.py:186} INFO - Started process (PID=6057) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:01.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:01:01.263+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:01.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:01.292+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:01.323+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:01.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:01:01.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:01.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:01:01.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.144 seconds
[2025-04-14T15:01:31.636+0000] {processor.py:186} INFO - Started process (PID=6125) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:31.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:01:31.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:31.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:31.669+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:01:31.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:31.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:01:31.721+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:01:31.721+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:01:31.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T15:02:02.165+0000] {processor.py:186} INFO - Started process (PID=6189) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:02.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:02:02.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:02.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:02.192+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:02.226+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:02.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:02:02.248+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:02.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:02:02.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T15:02:32.548+0000] {processor.py:186} INFO - Started process (PID=6241) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:32.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:02:32.552+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:32.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:32.599+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:02:32.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:32.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:02:32.694+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:02:32.693+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:02:32.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.243 seconds
[2025-04-14T15:03:03.296+0000] {processor.py:186} INFO - Started process (PID=6305) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:03.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:03:03.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:03.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:03.325+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:03.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:03.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:03:03.379+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:03.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:03:03.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:03:33.774+0000] {processor.py:186} INFO - Started process (PID=6369) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:33.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:03:33.777+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:33.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:33.803+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:03:33.838+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:33.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:03:33.857+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:03:33.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:03:33.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T15:04:04.431+0000] {processor.py:186} INFO - Started process (PID=6433) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:04.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:04:04.435+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:04.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:04.467+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:04.506+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:04.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:04:04.527+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:04.526+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:04:04.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T15:04:34.677+0000] {processor.py:186} INFO - Started process (PID=6497) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:34.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:04:34.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:34.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:34.703+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:04:34.731+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:34.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:04:34.748+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:04:34.747+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:04:34.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T15:05:05.300+0000] {processor.py:186} INFO - Started process (PID=6564) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:05.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:05:05.304+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:05.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:05.333+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:05.369+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:05.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:05:05.393+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:05.393+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:05:05.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T15:05:36.004+0000] {processor.py:186} INFO - Started process (PID=6618) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:36.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:05:36.007+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:36.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:36.032+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:05:36.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:36.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:05:36.084+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:05:36.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:05:36.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T15:06:06.956+0000] {processor.py:186} INFO - Started process (PID=6689) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:06.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:06:06.962+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:06.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:06.992+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:07.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:07.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:06:07.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:07.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:06:07.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.151 seconds
[2025-04-14T15:06:37.547+0000] {processor.py:186} INFO - Started process (PID=6739) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:37.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:06:37.551+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:37.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:37.575+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:06:37.605+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:37.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:06:37.626+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:06:37.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:06:37.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T15:07:07.956+0000] {processor.py:186} INFO - Started process (PID=6761) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:07.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:07:07.960+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:07.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:07.997+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:08.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:08.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:07:08.057+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:08.057+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:07:08.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T15:07:38.425+0000] {processor.py:186} INFO - Started process (PID=6783) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:38.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:07:38.428+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:38.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:38.446+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:07:38.472+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:38.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:07:38.490+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:07:38.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:07:38.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T15:08:08.920+0000] {processor.py:186} INFO - Started process (PID=6805) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:08.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:08:08.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:08.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:08.956+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:08.989+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:08.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:08:09.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:09.014+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:08:09.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T15:08:39.553+0000] {processor.py:186} INFO - Started process (PID=6827) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:39.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:08:39.560+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:39.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:39.592+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:08:39.625+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:39.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:08:39.646+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:08:39.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:08:39.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.154 seconds
[2025-04-14T15:09:09.868+0000] {processor.py:186} INFO - Started process (PID=6855) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:09.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:09:09.872+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:09.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:09.904+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:09.934+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:09.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:09:09.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:09.951+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:09:09.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:09:40.390+0000] {processor.py:186} INFO - Started process (PID=6897) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:40.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:09:40.395+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:40.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:40.434+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:09:40.481+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:40.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:09:40.516+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:09:40.516+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:09:40.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.166 seconds
[2025-04-14T15:10:10.922+0000] {processor.py:186} INFO - Started process (PID=6961) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:10.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:10:10.925+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:10.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:10.947+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:10.972+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:10.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:10:10.988+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:10.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:10:11.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T15:10:41.530+0000] {processor.py:186} INFO - Started process (PID=7024) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:41.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:10:41.536+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:41.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:41.591+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:10:41.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:41.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:10:41.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:10:41.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:10:41.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.260 seconds
[2025-04-14T15:11:12.719+0000] {processor.py:186} INFO - Started process (PID=7097) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:12.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:11:12.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:12.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:12.753+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:12.793+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:12.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:11:12.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:12.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:11:12.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T15:11:43.208+0000] {processor.py:186} INFO - Started process (PID=7161) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:43.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:11:43.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:43.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:43.233+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:11:43.262+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:43.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:11:43.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:11:43.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:11:43.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T15:12:13.713+0000] {processor.py:186} INFO - Started process (PID=7225) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:13.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:12:13.717+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:13.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:13.741+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:13.768+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:13.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:12:13.784+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:13.783+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:12:13.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T15:12:43.988+0000] {processor.py:186} INFO - Started process (PID=7289) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:43.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:12:43.991+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:43.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:44.014+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:12:44.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:44.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:12:44.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:12:44.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:12:44.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T15:13:14.522+0000] {processor.py:186} INFO - Started process (PID=7353) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:14.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:13:14.528+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:14.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:14.564+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:14.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:14.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:13:14.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:14.615+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:13:14.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T15:13:45.156+0000] {processor.py:186} INFO - Started process (PID=7417) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:45.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:13:45.160+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:45.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:45.184+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:13:45.214+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:45.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:13:45.230+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:13:45.230+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:13:45.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T15:14:15.398+0000] {processor.py:186} INFO - Started process (PID=7481) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:15.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:14:15.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:15.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:15.435+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:15.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:15.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:14:15.488+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:15.488+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:14:15.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T15:14:45.749+0000] {processor.py:186} INFO - Started process (PID=7545) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:45.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:14:45.752+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:45.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:45.773+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:14:45.803+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:45.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:14:45.824+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:14:45.823+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:14:45.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T15:15:16.195+0000] {processor.py:186} INFO - Started process (PID=7609) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:16.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:15:16.198+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:16.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:16.223+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:16.255+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:16.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:15:16.275+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:16.275+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:15:16.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T15:15:46.563+0000] {processor.py:186} INFO - Started process (PID=7674) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:46.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:15:46.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:46.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:46.588+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:15:46.616+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:46.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:15:46.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:15:46.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:15:46.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T15:16:16.983+0000] {processor.py:186} INFO - Started process (PID=7738) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:16.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:16:16.987+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:16.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:17.015+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:17.049+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:17.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:16:17.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:17.067+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:16:17.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:16:47.633+0000] {processor.py:186} INFO - Started process (PID=7760) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:47.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:16:47.638+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:47.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:47.665+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:16:47.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:47.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:16:47.722+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:16:47.722+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:16:47.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T15:17:17.913+0000] {processor.py:186} INFO - Started process (PID=7782) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:17.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:17:17.917+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:17.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:17.953+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:18.000+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:17.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:17:18.055+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:18.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:17:18.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.187 seconds
[2025-04-14T15:17:48.293+0000] {processor.py:186} INFO - Started process (PID=7804) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:48.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:17:48.295+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:48.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:48.326+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:17:48.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:48.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:17:48.378+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:17:48.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:17:48.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T15:18:18.688+0000] {processor.py:186} INFO - Started process (PID=7826) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:18.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:18:18.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:18.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:18.719+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:18.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:18.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:18:18.772+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:18.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:18:18.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T15:18:48.943+0000] {processor.py:186} INFO - Started process (PID=7853) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:48.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:18:48.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:48.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:48.986+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:18:49.019+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:49.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:18:49.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:18:49.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:18:49.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T15:19:19.611+0000] {processor.py:186} INFO - Started process (PID=7890) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:19.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:19:19.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:19.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:19.645+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:19.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:19.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:19:19.733+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:19.733+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:19:19.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.167 seconds
[2025-04-14T15:19:49.954+0000] {processor.py:186} INFO - Started process (PID=7912) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:49.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:19:49.961+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:49.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:49.995+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:19:50.039+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:50.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:19:50.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:19:50.067+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:19:50.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.155 seconds
[2025-04-14T15:20:20.656+0000] {processor.py:186} INFO - Started process (PID=7940) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:20.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:20:20.661+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:20.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:20.699+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:20.748+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:20.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:20:21.304+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:21.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:20:21.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.696 seconds
[2025-04-14T15:20:51.794+0000] {processor.py:186} INFO - Started process (PID=7985) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:51.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:20:51.800+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:51.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:51.825+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:20:51.858+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:51.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:20:51.879+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:20:51.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:20:51.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T15:21:22.319+0000] {processor.py:186} INFO - Started process (PID=8008) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:22.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:21:22.325+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:22.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:22.357+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:22.402+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:22.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:21:22.454+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:22.453+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:21:22.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.183 seconds
[2025-04-14T15:21:52.630+0000] {processor.py:186} INFO - Started process (PID=8036) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:52.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:21:52.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:52.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:52.688+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:21:52.739+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:52.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:21:52.787+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:21:52.786+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:21:52.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.225 seconds
[2025-04-14T15:22:23.637+0000] {processor.py:186} INFO - Started process (PID=8073) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:23.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:22:23.641+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:23.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:23.663+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:23.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:23.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:22:23.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:23.703+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:22:23.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T15:22:54.592+0000] {processor.py:186} INFO - Started process (PID=8095) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:54.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:22:54.597+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:54.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:54.627+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:22:54.672+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:54.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:22:54.691+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:22:54.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:22:54.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T15:23:25.182+0000] {processor.py:186} INFO - Started process (PID=8118) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:25.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:23:25.185+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:25.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:25.208+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:25.240+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:25.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:23:25.258+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:25.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:23:25.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T15:23:55.716+0000] {processor.py:186} INFO - Started process (PID=8140) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:55.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:23:55.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:55.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:55.748+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:23:55.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:55.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:23:55.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:23:55.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:23:55.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T15:24:26.107+0000] {processor.py:186} INFO - Started process (PID=8162) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:26.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:24:26.110+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:26.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:26.141+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:26.173+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:26.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:24:26.195+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:26.194+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:24:26.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:24:56.742+0000] {processor.py:186} INFO - Started process (PID=8184) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:56.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:24:56.746+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:56.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:56.768+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:24:56.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:56.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:24:56.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:24:56.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:24:56.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T15:25:26.964+0000] {processor.py:186} INFO - Started process (PID=8206) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:26.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:25:26.967+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:26.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:26.991+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:27.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:27.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:25:27.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:27.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:25:27.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T15:25:57.356+0000] {processor.py:186} INFO - Started process (PID=8228) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:57.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:25:57.359+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:57.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:57.394+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:25:57.428+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:57.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:25:57.449+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:25:57.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:25:57.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T15:26:27.930+0000] {processor.py:186} INFO - Started process (PID=8244) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:27.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:26:27.934+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:27.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:27.963+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:27.997+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:27.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:26:28.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:28.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:26:28.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T15:26:58.244+0000] {processor.py:186} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:58.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:26:58.249+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:58.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:58.282+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:26:58.319+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:58.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:26:58.338+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:26:58.337+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:26:58.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T15:27:28.479+0000] {processor.py:186} INFO - Started process (PID=8288) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:28.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:27:28.482+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:28.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:28.516+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:28.549+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:28.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:27:28.571+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:28.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:27:28.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T15:27:58.817+0000] {processor.py:186} INFO - Started process (PID=8310) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:58.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:27:58.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:58.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:58.847+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:27:58.882+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:58.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:27:58.899+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:27:58.898+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:27:58.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T15:28:29.076+0000] {processor.py:186} INFO - Started process (PID=8332) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:29.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:28:29.080+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:29.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:29.109+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:29.146+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:29.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:28:29.166+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:29.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:28:29.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T15:28:59.496+0000] {processor.py:186} INFO - Started process (PID=8354) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:59.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:28:59.499+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:59.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:59.532+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:28:59.571+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:59.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:28:59.596+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:28:59.595+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:28:59.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T15:29:30.073+0000] {processor.py:186} INFO - Started process (PID=8376) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:29:30.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:29:30.077+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:29:30.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:29:30.103+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:29:30.135+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:29:30.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:29:30.154+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:29:30.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:29:30.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T15:30:00.618+0000] {processor.py:186} INFO - Started process (PID=8398) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:00.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:30:00.623+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:00.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:00.652+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:00.689+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:00.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:30:00.708+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:00.708+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:30:00.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T15:30:31.002+0000] {processor.py:186} INFO - Started process (PID=8420) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:31.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:30:31.005+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:31.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:31.039+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:30:31.074+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:31.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:30:31.098+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:30:31.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:30:31.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T15:31:01.707+0000] {processor.py:186} INFO - Started process (PID=8442) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:01.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:31:01.711+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:01.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:01.750+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:01.793+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:01.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:31:01.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:01.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:31:01.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.147 seconds
[2025-04-14T15:31:32.314+0000] {processor.py:186} INFO - Started process (PID=8464) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:32.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:31:32.317+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:32.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:32.350+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:31:32.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:32.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:31:32.401+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:31:32.401+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:31:32.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T15:32:02.866+0000] {processor.py:186} INFO - Started process (PID=8486) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:02.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:32:02.869+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:02.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:02.896+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:02.927+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:02.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:32:02.946+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:02.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:32:02.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T15:32:33.410+0000] {processor.py:186} INFO - Started process (PID=8508) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:33.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:32:33.413+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:33.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:33.446+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:32:33.479+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:33.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:32:33.506+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:32:33.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:32:33.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T15:33:03.811+0000] {processor.py:186} INFO - Started process (PID=8530) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:03.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:33:03.814+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:03.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:03.841+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:03.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:03.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:33:03.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:03.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:33:03.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T15:33:34.351+0000] {processor.py:186} INFO - Started process (PID=8552) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:34.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:33:34.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:34.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:34.384+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:33:34.414+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:34.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:33:34.431+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:33:34.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:33:34.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T15:34:04.880+0000] {processor.py:186} INFO - Started process (PID=8574) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:04.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:34:04.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:04.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:04.909+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:04.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:04.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:34:04.958+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:04.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:34:04.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T15:34:35.219+0000] {processor.py:186} INFO - Started process (PID=8596) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:35.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:34:35.222+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:35.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:35.257+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:34:35.289+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:35.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:34:35.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:34:35.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:34:35.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T15:35:05.619+0000] {processor.py:186} INFO - Started process (PID=8618) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:05.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:35:05.622+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:05.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:05.654+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:05.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:05.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:35:05.707+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:05.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:35:05.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T15:35:36.012+0000] {processor.py:186} INFO - Started process (PID=8640) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:36.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:35:36.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:36.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:36.042+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:35:36.073+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:36.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:35:36.091+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:35:36.090+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:35:36.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T15:36:06.318+0000] {processor.py:186} INFO - Started process (PID=8662) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:06.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:36:06.321+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:06.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:06.354+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:06.389+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:06.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:36:06.409+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:06.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:36:06.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T15:36:36.708+0000] {processor.py:186} INFO - Started process (PID=8684) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:36.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:36:36.711+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:36.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:36.742+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:36:36.777+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:36.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:36:36.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:36:36.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:36:36.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T15:37:07.090+0000] {processor.py:186} INFO - Started process (PID=8706) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:07.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:37:07.094+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:07.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:07.122+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:07.152+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:07.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:37:07.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:07.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:37:07.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T15:37:37.638+0000] {processor.py:186} INFO - Started process (PID=8728) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:37.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:37:37.641+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:37.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:37.672+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:37:37.704+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:37.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:37:37.721+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:37:37.721+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:37:37.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T15:38:08.031+0000] {processor.py:186} INFO - Started process (PID=8750) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:08.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:38:08.033+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:08.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:08.071+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:08.103+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:08.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:38:08.126+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:08.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:38:08.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T15:38:38.600+0000] {processor.py:186} INFO - Started process (PID=8772) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:38.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:38:38.603+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:38.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:38.632+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:38:38.666+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:38.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:38:38.684+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:38:38.684+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:38:38.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T15:39:08.967+0000] {processor.py:186} INFO - Started process (PID=8794) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:08.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:39:08.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:08.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:08.994+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:09.024+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:09.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:39:09.042+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:09.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:39:09.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T15:39:39.287+0000] {processor.py:186} INFO - Started process (PID=8816) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:39.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:39:39.293+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:39.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:39.321+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:39:39.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:39.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:39:39.377+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:39:39.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:39:39.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T15:40:09.889+0000] {processor.py:186} INFO - Started process (PID=8838) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:09.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:40:09.892+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:09.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:09.933+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:09.963+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:09.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:40:09.986+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:09.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:40:10.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T15:40:40.224+0000] {processor.py:186} INFO - Started process (PID=8860) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:40.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:40:40.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:40.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:40.257+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:40:40.287+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:40.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:40:40.303+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:40:40.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:40:40.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T15:41:10.705+0000] {processor.py:186} INFO - Started process (PID=8882) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:10.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:41:10.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:10.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:10.739+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:10.772+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:10.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:41:10.792+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:10.792+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:41:10.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T15:41:41.170+0000] {processor.py:186} INFO - Started process (PID=8904) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:41.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:41:41.173+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:41.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:41.206+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:41:41.251+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:41.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:41:41.286+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:41:41.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:41:41.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T15:42:11.761+0000] {processor.py:186} INFO - Started process (PID=8920) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:11.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:42:11.764+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:11.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:11.798+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:11.838+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:11.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:42:11.864+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:11.863+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:42:11.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T15:42:42.086+0000] {processor.py:186} INFO - Started process (PID=8942) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:42.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:42:42.089+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:42.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:42.119+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:42:42.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:42.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:42:42.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:42:42.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:42:42.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T15:43:12.345+0000] {processor.py:186} INFO - Started process (PID=8964) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:12.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:43:12.348+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:12.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:12.381+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:12.414+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:12.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:43:12.438+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:12.438+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:43:12.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T15:43:42.928+0000] {processor.py:186} INFO - Started process (PID=8986) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:42.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:43:42.934+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:42.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:42.965+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:43:42.997+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:42.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:43:43.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:43:43.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:43:43.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T15:44:13.140+0000] {processor.py:186} INFO - Started process (PID=9008) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:13.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:44:13.144+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:13.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:13.176+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:13.208+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:13.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:44:13.226+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:13.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:44:13.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T15:44:43.497+0000] {processor.py:186} INFO - Started process (PID=9030) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:43.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:44:43.501+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:43.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:43.529+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:44:43.562+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:43.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:44:43.581+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:44:43.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:44:43.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T15:45:14.069+0000] {processor.py:186} INFO - Started process (PID=9052) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:14.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:45:14.073+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:14.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:14.105+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:14.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:14.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:45:14.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:14.157+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:45:14.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T15:45:44.312+0000] {processor.py:186} INFO - Started process (PID=9074) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:44.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:45:44.316+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:44.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:44.339+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:45:44.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:44.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:45:44.387+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:45:44.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:45:44.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T15:46:14.527+0000] {processor.py:186} INFO - Started process (PID=9096) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:14.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:46:14.531+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:14.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:14.562+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:14.594+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:14.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:46:14.612+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:14.612+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:46:14.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T15:46:44.872+0000] {processor.py:186} INFO - Started process (PID=9118) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:44.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:46:44.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:44.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:44.904+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:46:44.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:44.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:46:44.960+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:46:44.960+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:46:45.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.152 seconds
[2025-04-14T15:47:15.451+0000] {processor.py:186} INFO - Started process (PID=9140) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:15.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:47:15.456+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:15.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:15.483+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:15.515+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:15.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:47:15.533+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:15.533+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:47:15.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:47:45.758+0000] {processor.py:186} INFO - Started process (PID=9162) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:45.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:47:45.763+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:45.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:45.797+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:47:45.831+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:45.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:47:45.850+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:47:45.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:47:45.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T15:48:16.324+0000] {processor.py:186} INFO - Started process (PID=9190) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:16.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:48:16.327+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:16.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:16.358+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:16.389+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:16.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:48:16.408+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:16.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:48:16.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T15:48:46.642+0000] {processor.py:186} INFO - Started process (PID=9213) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:46.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:48:46.645+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:46.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:46.684+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:48:46.719+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:46.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:48:46.740+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:48:46.739+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:48:46.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T15:49:17.216+0000] {processor.py:186} INFO - Started process (PID=9235) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:17.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:49:17.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:17.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:17.251+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:17.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:17.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:49:17.297+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:17.297+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:49:17.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T15:49:47.574+0000] {processor.py:186} INFO - Started process (PID=9257) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:47.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:49:47.577+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:47.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:47.605+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:49:47.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:47.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:49:47.653+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:49:47.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:49:47.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T15:50:17.864+0000] {processor.py:186} INFO - Started process (PID=9279) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:17.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:50:17.867+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:17.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:17.897+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:17.932+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:17.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:50:17.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:17.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:50:17.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T15:50:48.235+0000] {processor.py:186} INFO - Started process (PID=9301) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:48.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:50:48.238+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:48.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:48.267+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:50:48.295+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:48.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:50:48.312+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:50:48.311+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:50:48.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T15:51:18.605+0000] {processor.py:186} INFO - Started process (PID=9323) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:18.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:51:18.608+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:18.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:18.637+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:18.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:18.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:51:18.684+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:18.684+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:51:18.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T15:51:48.867+0000] {processor.py:186} INFO - Started process (PID=9345) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:48.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:51:48.871+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:48.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:48.900+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:51:48.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:48.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:51:48.958+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:51:48.957+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:51:48.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T15:52:19.256+0000] {processor.py:186} INFO - Started process (PID=9367) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:19.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:52:19.260+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:19.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:19.293+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:19.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:19.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:52:19.344+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:19.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:52:19.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T15:52:49.666+0000] {processor.py:186} INFO - Started process (PID=9389) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:49.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:52:49.669+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:49.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:49.697+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:52:49.729+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:49.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:52:49.748+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:52:49.748+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:52:49.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T15:53:19.938+0000] {processor.py:186} INFO - Started process (PID=9411) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:19.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:53:19.941+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:19.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:19.970+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:20.003+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:20.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:53:20.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:20.023+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:53:20.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T15:53:50.360+0000] {processor.py:186} INFO - Started process (PID=9433) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:50.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:53:50.365+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:50.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:50.396+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:53:50.429+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:50.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:53:50.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:53:50.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:53:50.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T15:54:20.746+0000] {processor.py:186} INFO - Started process (PID=9455) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:20.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:54:20.749+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:20.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:20.778+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:20.806+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:20.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:54:20.823+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:20.823+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:54:20.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T15:54:51.318+0000] {processor.py:186} INFO - Started process (PID=9477) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:51.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:54:51.321+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:51.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:51.345+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:54:51.375+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:51.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:54:51.395+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:54:51.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:54:51.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T15:55:21.747+0000] {processor.py:186} INFO - Started process (PID=9499) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:21.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:55:21.752+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:21.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:21.795+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:21.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:21.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:55:21.880+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:21.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:55:21.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.184 seconds
[2025-04-14T15:55:52.220+0000] {processor.py:186} INFO - Started process (PID=9521) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:52.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:55:52.223+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:52.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:52.255+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:55:52.288+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:52.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:55:52.307+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:55:52.306+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:55:52.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T15:56:22.903+0000] {processor.py:186} INFO - Started process (PID=9543) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:22.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:56:22.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:22.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:22.930+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:22.959+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:22.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:56:22.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:22.975+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:56:22.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T15:56:53.218+0000] {processor.py:186} INFO - Started process (PID=9565) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:53.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:56:53.221+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:53.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:53.253+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:56:53.286+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:53.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:56:53.308+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:56:53.308+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:56:53.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T15:57:23.496+0000] {processor.py:186} INFO - Started process (PID=9587) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:23.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:57:23.501+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:23.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:23.530+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:23.562+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:23.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:57:23.579+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:23.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:57:23.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T15:57:54.041+0000] {processor.py:186} INFO - Started process (PID=9603) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:54.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:57:54.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:54.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:54.071+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:57:54.106+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:54.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:57:54.126+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:57:54.126+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:57:54.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T15:58:24.280+0000] {processor.py:186} INFO - Started process (PID=9625) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:24.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:58:24.283+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:24.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:24.307+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:24.338+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:24.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:58:24.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:24.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:58:24.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T15:58:54.809+0000] {processor.py:186} INFO - Started process (PID=9647) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:54.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:58:54.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:54.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:54.846+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:58:54.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:54.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:58:54.912+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:58:54.912+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:58:54.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.142 seconds
[2025-04-14T15:59:25.217+0000] {processor.py:186} INFO - Started process (PID=9669) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:25.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:59:25.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:25.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:25.252+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:25.284+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:25.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:59:25.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:25.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:59:25.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T15:59:55.751+0000] {processor.py:186} INFO - Started process (PID=9691) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:55.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T15:59:55.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:55.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:55.783+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T15:59:55.811+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:55.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T15:59:55.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T15:59:55.832+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T15:59:55.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T16:00:26.029+0000] {processor.py:186} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:26.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:00:26.033+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:26.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:26.063+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:26.097+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:26.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:00:26.115+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:26.115+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:00:26.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T16:00:56.384+0000] {processor.py:186} INFO - Started process (PID=9735) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:56.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:00:56.386+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:56.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:56.417+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:00:56.449+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:56.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:00:56.468+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:00:56.468+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:00:56.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T16:01:26.892+0000] {processor.py:186} INFO - Started process (PID=9757) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:26.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:01:26.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:26.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:26.923+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:26.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:26.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:01:26.970+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:26.970+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:01:26.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T16:01:57.171+0000] {processor.py:186} INFO - Started process (PID=9779) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:57.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:01:57.178+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:57.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:57.204+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:01:57.237+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:57.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:01:57.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:01:57.257+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:01:57.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T16:02:27.750+0000] {processor.py:186} INFO - Started process (PID=9801) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:27.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:02:27.753+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:27.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:27.783+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:27.816+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:27.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:02:27.833+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:27.833+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:02:27.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T16:02:58.032+0000] {processor.py:186} INFO - Started process (PID=9823) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:58.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:02:58.036+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:58.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:58.065+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:02:58.095+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:58.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:02:58.112+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:02:58.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:02:58.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T16:03:28.312+0000] {processor.py:186} INFO - Started process (PID=9845) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:28.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:03:28.316+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:28.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:28.346+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:28.376+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:28.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:03:28.392+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:28.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:03:28.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T16:03:58.571+0000] {processor.py:186} INFO - Started process (PID=9867) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:58.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:03:58.575+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:58.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:58.607+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:03:58.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:58.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:03:58.658+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:03:58.658+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:03:58.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T16:04:28.964+0000] {processor.py:186} INFO - Started process (PID=9889) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:28.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:04:28.968+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:28.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:29.005+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:29.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:29.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:04:29.058+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:29.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:04:29.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T16:04:59.529+0000] {processor.py:186} INFO - Started process (PID=9911) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:59.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:04:59.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:59.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:59.556+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:04:59.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:59.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:04:59.602+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:04:59.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:04:59.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T16:05:29.797+0000] {processor.py:186} INFO - Started process (PID=9933) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:05:29.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:05:29.803+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:05:29.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:05:29.836+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:05:29.868+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:05:29.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:05:29.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:05:29.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:05:29.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T16:06:00.136+0000] {processor.py:186} INFO - Started process (PID=9955) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:00.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:06:00.140+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:00.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:00.173+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:00.206+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:00.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:06:00.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:00.229+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:06:00.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.138 seconds
[2025-04-14T16:06:30.911+0000] {processor.py:186} INFO - Started process (PID=9977) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:30.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:06:30.915+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:30.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:30.943+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:06:30.972+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:30.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:06:30.990+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:06:30.990+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:06:31.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T16:07:01.143+0000] {processor.py:186} INFO - Started process (PID=9999) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:01.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:07:01.147+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:01.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:01.175+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:01.205+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:01.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:07:01.222+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:01.221+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:07:01.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T16:07:31.573+0000] {processor.py:186} INFO - Started process (PID=10021) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:31.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:07:31.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:31.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:32.018+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:07:32.114+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:32.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:07:32.182+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:07:32.181+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:07:32.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.682 seconds
[2025-04-14T16:08:03.102+0000] {processor.py:186} INFO - Started process (PID=10043) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:03.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:08:03.106+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:03.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:03.129+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:03.164+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:03.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:08:03.179+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:03.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:08:03.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T16:08:33.739+0000] {processor.py:186} INFO - Started process (PID=10065) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:33.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:08:33.743+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:33.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:33.764+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:08:33.789+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:33.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:08:33.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:08:33.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:08:33.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T16:09:04.005+0000] {processor.py:186} INFO - Started process (PID=10087) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:04.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:09:04.009+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:04.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:04.040+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:04.072+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:04.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:09:04.090+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:04.090+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:09:04.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T16:09:34.261+0000] {processor.py:186} INFO - Started process (PID=10109) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:34.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:09:34.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:34.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:34.289+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:09:34.315+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:34.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:09:34.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:09:34.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:09:34.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T16:10:04.789+0000] {processor.py:186} INFO - Started process (PID=10131) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:04.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:10:04.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:04.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:04.819+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:04.851+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:04.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:10:04.871+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:04.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:10:04.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T16:10:35.172+0000] {processor.py:186} INFO - Started process (PID=10153) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:35.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:10:35.175+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:35.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:35.198+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:10:35.227+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:35.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:10:35.242+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:10:35.242+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:10:35.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T16:11:05.712+0000] {processor.py:186} INFO - Started process (PID=10175) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:05.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:11:05.715+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:05.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:05.737+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:05.763+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:05.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:11:05.778+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:05.778+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:11:05.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T16:11:36.241+0000] {processor.py:186} INFO - Started process (PID=10197) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:36.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:11:36.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:36.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:36.272+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:11:36.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:36.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:11:36.320+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:11:36.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:11:36.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T16:12:06.552+0000] {processor.py:186} INFO - Started process (PID=10219) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:06.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:12:06.557+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:06.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:06.588+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:06.622+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:06.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:12:06.640+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:06.640+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:12:06.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T16:12:37.077+0000] {processor.py:186} INFO - Started process (PID=10241) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:37.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:12:37.080+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:37.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:37.108+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:12:37.135+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:37.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:12:37.152+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:12:37.152+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:12:37.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T16:13:07.363+0000] {processor.py:186} INFO - Started process (PID=10263) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:07.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:13:07.366+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:07.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:07.390+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:07.415+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:07.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:13:07.431+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:07.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:13:07.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T16:13:37.524+0000] {processor.py:186} INFO - Started process (PID=10285) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:37.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:13:37.527+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:37.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:37.548+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:13:37.575+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:37.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:13:37.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:13:37.590+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:13:37.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T16:14:07.965+0000] {processor.py:186} INFO - Started process (PID=10307) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:07.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:14:07.968+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:07.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:07.998+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:08.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:08.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:14:08.077+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:08.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:14:08.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.149 seconds
[2025-04-14T16:14:38.319+0000] {processor.py:186} INFO - Started process (PID=10323) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:38.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:14:38.323+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:38.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:38.345+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:14:38.371+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:38.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:14:38.387+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:14:38.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:14:38.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T16:15:08.832+0000] {processor.py:186} INFO - Started process (PID=10345) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:08.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:15:08.836+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:08.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:08.860+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:08.886+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:08.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:15:08.904+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:08.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:15:08.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T16:15:39.169+0000] {processor.py:186} INFO - Started process (PID=10367) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:39.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:15:39.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:39.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:39.194+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:15:39.231+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:39.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:15:39.251+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:15:39.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:15:39.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T16:16:09.527+0000] {processor.py:186} INFO - Started process (PID=10389) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:09.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:16:09.530+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:09.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:09.552+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:09.578+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:09.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:16:09.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:09.592+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:16:09.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T16:16:40.087+0000] {processor.py:186} INFO - Started process (PID=10411) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:40.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:16:40.095+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:40.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:40.130+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:16:40.190+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:40.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:16:40.213+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:16:40.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:16:40.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.168 seconds
[2025-04-14T16:17:10.343+0000] {processor.py:186} INFO - Started process (PID=10433) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:10.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:17:10.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:10.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:10.396+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:10.444+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:10.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:17:10.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:10.467+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:17:10.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.171 seconds
[2025-04-14T16:17:40.713+0000] {processor.py:186} INFO - Started process (PID=10455) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:40.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:17:40.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:40.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:40.740+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:17:40.765+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:40.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:17:40.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:17:40.780+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:17:40.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T16:18:11.259+0000] {processor.py:186} INFO - Started process (PID=10477) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:11.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:18:11.262+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:11.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:11.286+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:11.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:11.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:18:11.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:11.325+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:18:11.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T16:18:41.546+0000] {processor.py:186} INFO - Started process (PID=10499) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:41.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:18:41.551+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:41.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:41.575+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:18:41.605+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:41.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:18:41.621+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:18:41.621+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:18:41.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T16:19:11.731+0000] {processor.py:186} INFO - Started process (PID=10521) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:11.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:19:11.735+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:11.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:11.758+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:11.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:11.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:19:11.801+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:11.801+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:19:11.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T16:19:41.970+0000] {processor.py:186} INFO - Started process (PID=10543) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:41.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:19:41.973+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:41.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:41.996+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:19:42.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:42.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:19:42.070+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:19:42.069+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:19:42.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T16:20:12.229+0000] {processor.py:186} INFO - Started process (PID=10565) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:12.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:20:12.232+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:12.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:12.257+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:12.283+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:12.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:20:12.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:12.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:20:12.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T16:20:42.632+0000] {processor.py:186} INFO - Started process (PID=10587) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:42.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:20:42.636+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:42.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:42.667+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:20:42.704+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:42.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:20:42.725+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:20:42.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:20:42.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.129 seconds
[2025-04-14T16:21:12.937+0000] {processor.py:186} INFO - Started process (PID=10609) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:12.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:21:12.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:12.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:12.974+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:13.028+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:13.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:21:13.060+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:13.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:21:13.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.179 seconds
[2025-04-14T16:21:43.251+0000] {processor.py:186} INFO - Started process (PID=10632) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:43.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:21:43.254+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:43.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:43.280+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:21:43.305+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:43.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:21:43.320+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:21:43.320+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:21:43.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T16:22:13.667+0000] {processor.py:186} INFO - Started process (PID=10654) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:13.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:22:13.671+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:13.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:13.696+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:13.739+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:13.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:22:13.759+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:13.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:22:13.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T16:22:44.187+0000] {processor.py:186} INFO - Started process (PID=10676) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:44.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:22:44.190+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:44.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:44.218+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:22:44.245+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:44.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:22:44.262+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:22:44.262+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:22:44.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T16:23:14.479+0000] {processor.py:186} INFO - Started process (PID=10698) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:14.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:23:14.482+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:14.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:14.511+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:14.543+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:14.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:23:14.563+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:14.563+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:23:14.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T16:23:44.863+0000] {processor.py:186} INFO - Started process (PID=10720) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:44.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:23:44.866+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:44.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:44.893+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:23:44.920+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:44.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:23:44.938+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:23:44.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:23:44.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T16:24:15.143+0000] {processor.py:186} INFO - Started process (PID=10742) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:15.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:24:15.147+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:15.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:15.175+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:15.201+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:15.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:24:15.216+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:15.215+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:24:15.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T16:24:45.460+0000] {processor.py:186} INFO - Started process (PID=10764) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:45.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:24:45.466+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:45.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:45.489+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:24:45.521+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:45.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:24:45.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:24:45.543+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:24:45.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T16:25:15.762+0000] {processor.py:186} INFO - Started process (PID=10786) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:15.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:25:15.765+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:15.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:15.791+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:15.822+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:15.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:25:15.839+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:15.839+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:25:15.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T16:25:46.167+0000] {processor.py:186} INFO - Started process (PID=10808) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:46.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:25:46.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:46.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:46.199+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:25:46.228+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:46.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:25:46.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:25:46.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:25:46.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T16:26:16.622+0000] {processor.py:186} INFO - Started process (PID=10830) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:16.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:26:16.627+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:16.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:16.651+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:16.679+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:16.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:26:16.694+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:16.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:26:16.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T16:26:46.917+0000] {processor.py:186} INFO - Started process (PID=10852) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:46.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:26:46.921+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:46.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:46.946+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:26:46.990+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:46.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:26:47.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:26:47.013+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:26:47.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T16:27:17.491+0000] {processor.py:186} INFO - Started process (PID=10875) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:17.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:27:17.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:17.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:17.522+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:17.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:17.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:27:17.582+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:17.582+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:27:17.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T16:27:47.774+0000] {processor.py:186} INFO - Started process (PID=10897) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:47.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:27:47.777+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:47.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:47.804+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:27:47.834+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:47.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:27:47.851+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:27:47.851+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:27:47.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:28:18.203+0000] {processor.py:186} INFO - Started process (PID=10919) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:18.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:28:18.207+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:18.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:18.234+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:18.263+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:18.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:28:18.279+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:18.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:28:18.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T16:28:48.609+0000] {processor.py:186} INFO - Started process (PID=10941) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:48.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:28:48.617+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:48.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:48.656+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:28:48.713+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:48.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:28:48.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:28:48.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:28:48.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.172 seconds
[2025-04-14T16:29:18.971+0000] {processor.py:186} INFO - Started process (PID=10963) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:18.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:29:18.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:18.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:18.999+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:19.028+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:19.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:29:19.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:19.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:29:19.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T16:29:49.169+0000] {processor.py:186} INFO - Started process (PID=10985) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:49.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:29:49.171+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:49.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:49.194+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:29:49.223+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:49.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:29:49.239+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:29:49.239+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:29:49.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T16:30:19.701+0000] {processor.py:186} INFO - Started process (PID=11001) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:19.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:30:19.705+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:19.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:19.730+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:19.773+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:19.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:30:19.791+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:19.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:30:19.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T16:30:50.465+0000] {processor.py:186} INFO - Started process (PID=11029) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:50.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:30:50.470+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:50.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:50.498+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:30:50.526+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:50.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:30:50.543+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:30:50.543+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:30:50.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T16:31:20.982+0000] {processor.py:186} INFO - Started process (PID=11051) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:20.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:31:20.987+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:20.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:21.022+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:21.056+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:21.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:31:21.077+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:21.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:31:21.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.152 seconds
[2025-04-14T16:31:51.387+0000] {processor.py:186} INFO - Started process (PID=11073) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:51.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:31:51.390+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:51.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:51.414+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:31:51.439+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:51.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:31:51.455+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:31:51.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:31:51.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T16:32:21.599+0000] {processor.py:186} INFO - Started process (PID=11095) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:21.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:32:21.602+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:21.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:21.626+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:21.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:21.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:32:21.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:21.675+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:32:21.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T16:32:51.786+0000] {processor.py:186} INFO - Started process (PID=11117) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:51.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:32:51.790+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:51.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:51.816+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:32:51.855+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:51.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:32:51.885+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:32:51.885+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:32:51.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T16:33:22.241+0000] {processor.py:186} INFO - Started process (PID=11139) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:22.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:33:22.246+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:22.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:22.284+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:22.334+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:22.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:33:22.365+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:22.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:33:22.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.160 seconds
[2025-04-14T16:33:52.632+0000] {processor.py:186} INFO - Started process (PID=11161) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:52.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:33:52.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:52.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:52.660+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:33:52.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:52.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:33:52.704+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:33:52.704+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:33:52.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T16:34:22.837+0000] {processor.py:186} INFO - Started process (PID=11183) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:22.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:34:22.841+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:22.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:22.873+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:22.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:22.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:34:22.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:22.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:34:22.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T16:34:53.221+0000] {processor.py:186} INFO - Started process (PID=11206) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:53.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:34:53.223+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:53.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:53.249+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:34:53.278+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:53.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:34:53.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:34:53.295+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:34:53.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T16:35:23.715+0000] {processor.py:186} INFO - Started process (PID=11228) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:23.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:35:23.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:23.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:23.750+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:23.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:23.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:35:23.799+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:23.798+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:35:23.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T16:35:54.253+0000] {processor.py:186} INFO - Started process (PID=11250) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:54.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:35:54.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:54.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:54.287+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:35:54.322+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:54.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:35:54.340+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:35:54.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:35:54.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T16:36:24.682+0000] {processor.py:186} INFO - Started process (PID=11272) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:24.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:36:24.685+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:24.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:24.718+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:24.758+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:24.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:36:24.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:24.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:36:24.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T16:36:55.174+0000] {processor.py:186} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:55.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:36:55.177+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:55.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:55.209+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:36:55.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:55.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:36:55.282+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:36:55.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:36:55.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T16:37:25.859+0000] {processor.py:186} INFO - Started process (PID=11326) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:25.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:37:25.862+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:25.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:25.890+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:25.928+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:25.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:37:25.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:25.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:37:25.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T16:37:56.217+0000] {processor.py:186} INFO - Started process (PID=11377) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:56.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:37:56.221+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:56.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:56.248+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:37:56.276+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:56.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:37:56.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:37:56.295+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:37:56.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T16:38:26.440+0000] {processor.py:186} INFO - Started process (PID=11418) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:26.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:38:26.443+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:26.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:26.467+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:26.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:26.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:38:26.511+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:26.511+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:38:26.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T16:38:56.803+0000] {processor.py:186} INFO - Started process (PID=11440) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:56.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:38:56.806+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:56.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:56.829+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:38:56.855+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:56.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:38:56.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:38:56.869+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:38:56.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T16:39:27.015+0000] {processor.py:186} INFO - Started process (PID=11462) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:27.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:39:27.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:27.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:27.045+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:27.072+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:27.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:39:27.087+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:27.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:39:27.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T16:39:57.355+0000] {processor.py:186} INFO - Started process (PID=11484) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:57.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:39:57.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:57.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:57.383+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:39:57.409+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:57.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:39:57.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:39:57.425+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:39:57.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T16:40:27.991+0000] {processor.py:186} INFO - Started process (PID=11506) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:27.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:40:27.997+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:27.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:28.029+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:28.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:28.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:40:28.096+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:28.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:40:28.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T16:40:58.240+0000] {processor.py:186} INFO - Started process (PID=11528) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:58.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:40:58.243+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:58.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:58.270+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:40:58.297+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:58.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:40:58.313+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:40:58.312+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:40:58.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T16:41:28.604+0000] {processor.py:186} INFO - Started process (PID=11577) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:28.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:41:28.606+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:28.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:28.633+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:28.657+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:28.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:41:28.673+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:28.673+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:41:28.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T16:41:58.768+0000] {processor.py:186} INFO - Started process (PID=11599) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:58.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:41:58.772+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:58.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:58.798+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:41:58.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:58.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:41:58.850+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:41:58.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:41:58.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T16:42:29.073+0000] {processor.py:186} INFO - Started process (PID=11621) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:29.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:42:29.076+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:29.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:29.111+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:29.143+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:29.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:42:29.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:29.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:42:29.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T16:42:59.616+0000] {processor.py:186} INFO - Started process (PID=11643) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:59.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:42:59.620+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:59.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:59.652+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:42:59.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:59.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:42:59.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:42:59.720+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:42:59.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T16:43:29.913+0000] {processor.py:186} INFO - Started process (PID=11665) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:43:29.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:43:29.917+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:43:29.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:43:29.954+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:43:29.985+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:43:29.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:43:30.004+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:43:30.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:43:30.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T16:44:00.327+0000] {processor.py:186} INFO - Started process (PID=11706) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:00.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:44:00.331+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:00.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:00.355+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:00.381+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:00.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:44:00.395+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:00.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:44:00.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T16:44:30.715+0000] {processor.py:186} INFO - Started process (PID=11728) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:30.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:44:30.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:30.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:30.748+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:44:30.778+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:30.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:44:30.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:44:30.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:44:30.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:45:00.988+0000] {processor.py:186} INFO - Started process (PID=11750) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:00.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:45:00.991+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:00.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:01.014+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:01.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:01.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:45:01.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:01.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:45:01.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T16:45:31.462+0000] {processor.py:186} INFO - Started process (PID=11784) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:31.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:45:31.465+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:31.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:31.488+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:45:31.516+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:31.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:45:31.531+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:45:31.531+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:45:31.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T16:46:01.949+0000] {processor.py:186} INFO - Started process (PID=11814) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:01.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:46:01.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:01.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:01.974+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:02.002+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:02.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:46:02.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:02.018+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:46:02.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T16:46:32.138+0000] {processor.py:186} INFO - Started process (PID=11840) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:32.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:46:32.141+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:32.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:32.166+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:46:32.196+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:32.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:46:32.212+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:46:32.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:46:32.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T16:47:02.432+0000] {processor.py:186} INFO - Started process (PID=11877) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:02.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:47:02.435+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:02.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:02.460+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:02.492+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:02.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:47:02.512+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:02.512+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:47:02.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:47:32.973+0000] {processor.py:186} INFO - Started process (PID=11899) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:32.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:47:32.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:32.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:33.007+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:47:33.038+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:33.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:47:33.054+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:47:33.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:47:33.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:48:03.377+0000] {processor.py:186} INFO - Started process (PID=11948) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:03.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:48:03.381+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:03.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:03.408+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:03.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:03.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:48:03.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:03.467+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:48:03.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T16:48:34.008+0000] {processor.py:186} INFO - Started process (PID=11970) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:34.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:48:34.015+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:34.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:34.054+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:48:34.130+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:34.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:48:34.175+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:48:34.175+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:48:34.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.252 seconds
[2025-04-14T16:49:04.411+0000] {processor.py:186} INFO - Started process (PID=11992) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:04.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:49:04.415+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:04.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:04.443+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:04.479+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:04.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:49:04.498+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:04.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:49:04.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T16:49:34.748+0000] {processor.py:186} INFO - Started process (PID=12014) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:34.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:49:34.752+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:34.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:34.778+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:49:34.809+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:34.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:49:34.827+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:49:34.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:49:34.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T16:50:05.154+0000] {processor.py:186} INFO - Started process (PID=12063) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:05.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:50:05.158+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:05.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:05.191+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:05.231+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:05.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:50:05.251+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:05.250+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:50:05.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T16:50:35.392+0000] {processor.py:186} INFO - Started process (PID=12085) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:35.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:50:35.396+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:35.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:35.423+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:50:35.452+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:35.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:50:35.470+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:50:35.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:50:35.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T16:51:06.064+0000] {processor.py:186} INFO - Started process (PID=12108) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:06.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:51:06.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:06.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:06.096+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:06.124+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:06.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:51:06.142+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:06.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:51:06.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T16:51:36.630+0000] {processor.py:186} INFO - Started process (PID=12130) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:36.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:51:36.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:36.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:36.674+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:51:36.718+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:36.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:51:36.740+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:51:36.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:51:36.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.151 seconds
[2025-04-14T16:52:07.160+0000] {processor.py:186} INFO - Started process (PID=12152) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:07.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:52:07.163+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:07.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:07.188+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:07.219+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:07.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:52:07.250+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:07.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:52:07.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T16:52:37.859+0000] {processor.py:186} INFO - Started process (PID=12193) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:37.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:52:37.863+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:37.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:37.892+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:52:37.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:37.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:52:37.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:52:37.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:52:37.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T16:53:08.322+0000] {processor.py:186} INFO - Started process (PID=12219) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:08.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:53:08.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:08.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:08.401+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:08.457+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:08.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:53:08.480+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:08.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:53:08.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.254 seconds
[2025-04-14T16:53:38.985+0000] {processor.py:186} INFO - Started process (PID=12264) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:38.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:53:38.988+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:38.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:39.012+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:53:39.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:39.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:53:39.062+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:53:39.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:53:39.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:54:09.311+0000] {processor.py:186} INFO - Started process (PID=12313) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:09.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:54:09.315+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:09.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:09.350+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:09.378+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:09.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:54:09.394+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:09.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:54:09.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T16:54:39.830+0000] {processor.py:186} INFO - Started process (PID=12335) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:39.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:54:39.834+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:39.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:39.862+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:54:39.896+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:39.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:54:39.915+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:54:39.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:54:39.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T16:55:10.372+0000] {processor.py:186} INFO - Started process (PID=12384) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:10.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:55:10.375+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:10.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:10.402+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:10.428+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:10.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:55:10.445+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:10.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:55:10.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T16:55:40.705+0000] {processor.py:186} INFO - Started process (PID=12406) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:40.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:55:40.710+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:40.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:40.746+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:55:40.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:40.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:55:40.794+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:55:40.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:55:40.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T16:56:10.934+0000] {processor.py:186} INFO - Started process (PID=12428) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:10.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:56:10.937+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:10.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:10.964+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:10.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:10.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:56:11.008+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:11.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:56:11.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T16:56:41.314+0000] {processor.py:186} INFO - Started process (PID=12450) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:41.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:56:41.319+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:41.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:41.353+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:56:41.397+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:41.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:56:41.415+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:56:41.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:56:41.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T16:57:11.677+0000] {processor.py:186} INFO - Started process (PID=12472) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:11.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:57:11.679+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:11.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:11.709+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:11.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:11.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:57:11.770+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:11.770+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:57:11.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.125 seconds
[2025-04-14T16:57:42.213+0000] {processor.py:186} INFO - Started process (PID=12515) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:42.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:57:42.216+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:42.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:42.239+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:57:42.267+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:42.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:57:42.285+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:57:42.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:57:42.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T16:58:12.562+0000] {processor.py:186} INFO - Started process (PID=12564) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:12.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:58:12.567+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:12.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:12.598+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:12.630+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:12.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:58:12.646+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:12.645+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:58:12.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T16:58:42.880+0000] {processor.py:186} INFO - Started process (PID=12586) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:42.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:58:42.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:42.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:42.909+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:58:42.935+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:42.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:58:42.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:58:42.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:58:42.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T16:59:13.470+0000] {processor.py:186} INFO - Started process (PID=12636) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:13.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:59:13.474+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:13.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:13.513+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:13.544+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:13.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:59:13.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:13.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:59:13.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T16:59:43.758+0000] {processor.py:186} INFO - Started process (PID=12679) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:43.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T16:59:43.761+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:43.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:43.794+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T16:59:43.829+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:43.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T16:59:43.851+0000] {logging_mixin.py:190} INFO - [2025-04-14T16:59:43.851+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T16:59:43.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T17:00:13.945+0000] {processor.py:186} INFO - Started process (PID=12701) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:13.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:00:13.951+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:13.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:13.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:14.019+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:14.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:00:14.042+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:14.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:00:14.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T17:00:44.362+0000] {processor.py:186} INFO - Started process (PID=12729) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:44.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:00:44.370+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:44.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:44.434+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:00:44.529+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:44.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:00:44.589+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:00:44.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:00:45.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 1.297 seconds
[2025-04-14T17:01:16.076+0000] {processor.py:186} INFO - Started process (PID=12766) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:16.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:01:16.079+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:16.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:16.101+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:16.127+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:16.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:01:16.142+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:16.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:01:16.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T17:01:46.434+0000] {processor.py:186} INFO - Started process (PID=12788) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:46.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:01:46.438+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:46.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:46.475+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:01:46.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:46.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:01:46.534+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:01:46.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:01:46.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T17:02:17.035+0000] {processor.py:186} INFO - Started process (PID=12815) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:17.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:02:17.040+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:17.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:17.091+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:17.132+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:17.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:02:17.150+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:17.150+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:02:17.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.151 seconds
[2025-04-14T17:02:47.670+0000] {processor.py:186} INFO - Started process (PID=12861) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:47.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:02:47.674+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:47.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:47.700+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:02:47.725+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:47.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:02:47.741+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:02:47.741+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:02:47.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T17:03:17.960+0000] {processor.py:186} INFO - Started process (PID=12883) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:17.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:03:17.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:17.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:17.993+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:18.029+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:18.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:03:18.047+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:18.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:03:18.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T17:03:48.298+0000] {processor.py:186} INFO - Started process (PID=12906) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:48.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:03:48.301+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:48.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:48.325+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:03:48.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:48.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:03:48.365+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:03:48.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:03:48.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T17:04:18.648+0000] {processor.py:186} INFO - Started process (PID=12928) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:18.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:04:18.651+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:18.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:18.675+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:18.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:18.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:04:18.730+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:18.729+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:04:18.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T17:04:49.069+0000] {processor.py:186} INFO - Started process (PID=12956) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:49.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:04:49.072+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:49.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:49.095+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:04:49.131+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:49.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:04:49.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:04:49.149+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:04:49.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T17:05:19.608+0000] {processor.py:186} INFO - Started process (PID=12999) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:19.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:05:19.611+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:19.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:19.637+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:19.663+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:19.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:05:19.678+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:19.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:05:19.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:05:49.992+0000] {processor.py:186} INFO - Started process (PID=13036) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:49.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:05:49.995+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:49.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:50.020+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:05:50.048+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:50.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:05:50.065+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:05:50.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:05:50.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T17:06:20.507+0000] {processor.py:186} INFO - Started process (PID=13058) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:20.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:06:20.510+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:20.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:20.543+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:20.574+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:20.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:06:20.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:20.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:06:20.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T17:06:51.284+0000] {processor.py:186} INFO - Started process (PID=13086) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:51.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:06:51.296+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:51.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:51.339+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:06:51.402+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:51.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:06:51.442+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:06:51.441+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:06:52.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 1.142 seconds
[2025-04-14T17:07:22.906+0000] {processor.py:186} INFO - Started process (PID=13142) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:22.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:07:22.912+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:22.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:22.955+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:22.992+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:22.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:07:23.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:23.015+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:07:23.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.155 seconds
[2025-04-14T17:07:53.261+0000] {processor.py:186} INFO - Started process (PID=13164) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:53.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:07:53.264+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:53.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:53.293+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:07:53.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:53.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:07:53.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:07:53.357+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:07:53.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
[2025-04-14T17:08:23.541+0000] {processor.py:186} INFO - Started process (PID=13186) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:23.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:08:23.545+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:23.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:23.568+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:23.595+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:23.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:08:23.614+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:23.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:08:23.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:08:53.898+0000] {processor.py:186} INFO - Started process (PID=13208) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:53.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:08:53.902+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:53.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:53.925+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:08:53.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:53.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:08:53.969+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:08:53.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:08:53.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T17:09:24.907+0000] {processor.py:186} INFO - Started process (PID=13230) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:24.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:09:24.911+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:24.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:24.953+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:25.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:25.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:09:25.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:25.018+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:09:25.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.308 seconds
[2025-04-14T17:09:55.970+0000] {processor.py:186} INFO - Started process (PID=13286) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:55.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:09:55.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:55.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:56.007+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:09:56.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:56.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:09:56.085+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:09:56.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:09:56.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.172 seconds
[2025-04-14T17:10:26.243+0000] {processor.py:186} INFO - Started process (PID=13314) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:26.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:10:26.247+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:26.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:26.280+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:26.312+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:26.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:10:26.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:26.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:10:26.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.128 seconds
[2025-04-14T17:10:56.626+0000] {processor.py:186} INFO - Started process (PID=13336) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:56.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:10:56.632+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:56.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:56.667+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:10:56.705+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:56.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:10:56.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:10:56.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:10:56.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.148 seconds
[2025-04-14T17:11:26.992+0000] {processor.py:186} INFO - Started process (PID=13358) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:26.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:11:26.997+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:26.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:27.021+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:27.048+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:27.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:11:27.063+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:27.063+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:11:27.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T17:11:57.277+0000] {processor.py:186} INFO - Started process (PID=13380) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:57.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:11:57.280+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:57.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:57.305+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:11:57.331+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:57.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:11:57.346+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:11:57.346+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:11:57.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T17:12:27.836+0000] {processor.py:186} INFO - Started process (PID=13402) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:27.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:12:27.840+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:27.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:27.864+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:27.893+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:27.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:12:27.914+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:27.914+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:12:27.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T17:12:58.067+0000] {processor.py:186} INFO - Started process (PID=13424) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:58.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:12:58.072+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:58.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:58.104+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:12:58.132+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:58.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:12:58.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:12:58.149+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:12:58.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T17:13:28.613+0000] {processor.py:186} INFO - Started process (PID=13444) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:28.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:13:28.617+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:28.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:28.651+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:28.675+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:28.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:13:28.693+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:28.693+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:13:28.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T17:13:59.551+0000] {processor.py:186} INFO - Started process (PID=13462) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:59.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:13:59.554+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:59.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:59.585+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:13:59.623+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:59.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:13:59.646+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:13:59.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:13:59.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T17:14:30.439+0000] {processor.py:186} INFO - Started process (PID=13483) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:14:30.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:14:30.444+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:14:30.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:14:30.480+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:14:30.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:14:30.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:14:30.539+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:14:30.539+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:14:30.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T17:15:01.059+0000] {processor.py:186} INFO - Started process (PID=13505) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:01.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:15:01.063+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:01.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:01.097+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:01.139+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:01.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:15:01.159+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:01.158+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:15:01.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T17:15:31.393+0000] {processor.py:186} INFO - Started process (PID=13527) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:31.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:15:31.396+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:31.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:31.418+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:15:31.444+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:31.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:15:31.459+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:15:31.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:15:31.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T17:16:01.574+0000] {processor.py:186} INFO - Started process (PID=13550) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:01.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:16:01.577+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:01.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:01.602+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:01.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:01.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:16:01.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:01.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:16:01.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.137 seconds
[2025-04-14T17:16:32.300+0000] {processor.py:186} INFO - Started process (PID=13572) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:32.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:16:32.305+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:32.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:32.327+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:16:32.353+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:32.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:16:32.368+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:16:32.368+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:16:32.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T17:17:02.705+0000] {processor.py:186} INFO - Started process (PID=13594) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:02.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:17:02.709+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:02.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:02.730+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:02.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:02.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:17:02.770+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:02.770+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:17:02.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T17:17:32.945+0000] {processor.py:186} INFO - Started process (PID=13616) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:32.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:17:32.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:32.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:32.984+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:17:33.015+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:33.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:17:33.035+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:17:33.035+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:17:33.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T17:18:03.161+0000] {processor.py:186} INFO - Started process (PID=13638) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:03.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:18:03.166+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:03.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:03.195+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:03.230+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:03.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:18:03.255+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:03.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:18:03.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T17:18:33.493+0000] {processor.py:186} INFO - Started process (PID=13660) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:33.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:18:33.497+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:33.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:33.520+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:18:33.547+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:33.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:18:33.561+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:18:33.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:18:33.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T17:19:04.007+0000] {processor.py:186} INFO - Started process (PID=13682) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:04.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:19:04.011+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:04.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:04.037+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:04.064+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:04.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:19:04.083+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:04.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:19:04.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T17:19:34.530+0000] {processor.py:186} INFO - Started process (PID=13705) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:34.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:19:34.533+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:34.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:34.567+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:19:34.597+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:34.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:19:34.615+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:19:34.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:19:34.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T17:20:05.219+0000] {processor.py:186} INFO - Started process (PID=13728) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:05.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:20:05.223+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:05.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:05.250+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:05.275+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:05.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:20:05.293+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:05.293+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:20:05.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T17:20:35.388+0000] {processor.py:186} INFO - Started process (PID=13755) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:35.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:20:35.393+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:35.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:35.426+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:20:35.457+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:35.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:20:35.474+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:20:35.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:20:35.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.122 seconds
[2025-04-14T17:21:06.375+0000] {processor.py:186} INFO - Started process (PID=13831) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:06.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:21:06.380+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:06.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:06.415+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:06.448+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:06.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:21:06.471+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:06.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:21:06.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T17:21:36.809+0000] {processor.py:186} INFO - Started process (PID=13853) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:36.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:21:36.812+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:36.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:36.844+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:21:36.875+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:36.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:21:36.892+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:21:36.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:21:36.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T17:22:07.484+0000] {processor.py:186} INFO - Started process (PID=13894) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:07.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:22:07.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:07.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:07.511+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:07.548+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:07.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:22:07.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:07.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:22:07.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.132 seconds
[2025-04-14T17:22:37.751+0000] {processor.py:186} INFO - Started process (PID=13916) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:37.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:22:37.754+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:37.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:37.778+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:22:37.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:37.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:22:37.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:22:37.820+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:22:37.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T17:23:08.266+0000] {processor.py:186} INFO - Started process (PID=13965) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:08.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:23:08.270+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:08.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:08.293+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:08.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:08.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:23:08.346+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:08.346+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:23:08.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.119 seconds
[2025-04-14T17:23:38.821+0000] {processor.py:186} INFO - Started process (PID=13987) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:38.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:23:38.825+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:38.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:38.850+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:23:38.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:38.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:23:38.920+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:23:38.919+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:23:38.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.144 seconds
[2025-04-14T17:24:09.415+0000] {processor.py:186} INFO - Started process (PID=14036) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:09.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:24:09.420+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:09.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:09.443+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:09.475+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:09.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:24:09.496+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:09.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:24:09.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T17:24:39.878+0000] {processor.py:186} INFO - Started process (PID=14064) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:39.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:24:39.880+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:39.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:39.904+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:24:39.934+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:39.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:24:39.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:24:39.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:24:39.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T17:25:10.074+0000] {processor.py:186} INFO - Started process (PID=14086) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:10.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:25:10.077+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:10.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:10.104+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:10.138+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:10.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:25:10.156+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:10.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:25:10.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T17:25:40.592+0000] {processor.py:186} INFO - Started process (PID=14132) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:40.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:25:40.602+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:40.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:40.638+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:25:40.677+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:40.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:25:40.697+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:25:40.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:25:40.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T17:26:10.801+0000] {processor.py:186} INFO - Started process (PID=14197) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:10.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:26:10.804+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:10.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:10.831+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:10.856+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:10.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:26:10.872+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:10.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:26:10.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:26:41.012+0000] {processor.py:186} INFO - Started process (PID=14219) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:41.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:26:41.016+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:41.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:41.041+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:26:41.066+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:41.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:26:41.081+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:26:41.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:26:41.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:27:11.175+0000] {processor.py:186} INFO - Started process (PID=14241) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:11.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:27:11.178+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:11.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:11.206+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:11.233+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:11.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:27:11.251+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:11.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:27:11.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T17:27:41.472+0000] {processor.py:186} INFO - Started process (PID=14263) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:41.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:27:41.475+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:41.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:41.501+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:27:41.528+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:41.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:27:41.543+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:27:41.542+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:27:41.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:28:11.683+0000] {processor.py:186} INFO - Started process (PID=14285) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:11.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:28:11.686+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:11.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:11.711+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:11.738+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:11.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:28:11.754+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:11.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:28:11.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:28:41.902+0000] {processor.py:186} INFO - Started process (PID=14307) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:41.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:28:41.905+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:41.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:41.928+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:28:41.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:41.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:28:41.969+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:28:41.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:28:41.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T17:29:12.365+0000] {processor.py:186} INFO - Started process (PID=14336) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:12.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:29:12.369+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:12.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:12.395+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:12.426+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:12.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:29:12.444+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:12.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:29:12.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T17:29:42.582+0000] {processor.py:186} INFO - Started process (PID=14364) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:42.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:29:42.585+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:42.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:42.610+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:29:42.637+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:42.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:29:42.654+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:29:42.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:29:42.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T17:30:12.812+0000] {processor.py:186} INFO - Started process (PID=14386) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:12.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:30:12.815+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:12.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:12.839+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:12.864+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:12.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:30:12.879+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:12.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:30:12.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:30:43.289+0000] {processor.py:186} INFO - Started process (PID=14408) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:43.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:30:43.297+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:43.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:43.331+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:30:43.358+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:43.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:30:43.386+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:30:43.385+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:30:43.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T17:31:13.466+0000] {processor.py:186} INFO - Started process (PID=14443) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:13.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:31:13.469+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:13.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:13.495+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:13.539+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:13.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:31:13.557+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:13.557+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:31:13.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T17:31:43.669+0000] {processor.py:186} INFO - Started process (PID=14471) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:43.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:31:43.672+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:43.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:43.696+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:31:43.738+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:43.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:31:43.757+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:31:43.757+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:31:43.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T17:32:14.183+0000] {processor.py:186} INFO - Started process (PID=14493) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:14.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:32:14.186+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:14.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:14.211+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:14.237+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:14.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:32:14.251+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:14.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:32:14.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T17:32:44.354+0000] {processor.py:186} INFO - Started process (PID=14515) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:44.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:32:44.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:44.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:44.380+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:32:44.406+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:44.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:32:44.421+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:32:44.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:32:44.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T17:33:14.536+0000] {processor.py:186} INFO - Started process (PID=14537) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:14.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:33:14.539+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:14.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:14.564+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:14.590+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:14.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:33:14.605+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:14.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:33:14.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:33:44.695+0000] {processor.py:186} INFO - Started process (PID=14559) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:44.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:33:44.698+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:44.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:44.717+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:33:44.742+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:44.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:33:44.913+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:33:44.912+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:33:44.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.244 seconds
[2025-04-14T17:34:15.329+0000] {processor.py:186} INFO - Started process (PID=14581) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:15.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:34:15.332+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:15.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:15.357+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:15.382+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:15.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:34:15.397+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:15.397+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:34:15.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T17:34:45.537+0000] {processor.py:186} INFO - Started process (PID=14603) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:45.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:34:45.540+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:45.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:45.563+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:34:45.589+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:45.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:34:45.605+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:34:45.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:34:45.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T17:35:15.710+0000] {processor.py:186} INFO - Started process (PID=14625) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:15.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:35:15.713+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:15.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:15.735+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:15.760+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:15.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:35:15.777+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:15.777+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:35:15.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:35:45.880+0000] {processor.py:186} INFO - Started process (PID=14647) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:45.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:35:45.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:45.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:45.907+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:35:45.932+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:45.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:35:45.948+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:35:45.948+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:35:46.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.268 seconds
[2025-04-14T17:36:16.282+0000] {processor.py:186} INFO - Started process (PID=14669) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:16.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:36:16.284+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:16.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:16.309+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:16.334+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:16.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:36:16.349+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:16.348+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:36:16.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T17:36:46.460+0000] {processor.py:186} INFO - Started process (PID=14692) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:46.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:36:46.464+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:46.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:46.488+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:36:46.518+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:46.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:36:46.533+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:36:46.533+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:36:46.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T17:37:16.646+0000] {processor.py:186} INFO - Started process (PID=14714) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:16.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:37:16.649+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:16.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:16.671+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:16.700+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:16.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:37:16.716+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:16.715+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:37:16.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T17:37:47.137+0000] {processor.py:186} INFO - Started process (PID=14736) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:47.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:37:47.141+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:47.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:47.165+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:37:47.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:47.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:37:47.212+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:37:47.212+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:37:47.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.265 seconds
[2025-04-14T17:38:17.561+0000] {processor.py:186} INFO - Started process (PID=14758) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:17.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:38:17.564+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:17.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:17.588+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:17.764+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:17.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:38:17.776+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:17.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:38:17.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.242 seconds
[2025-04-14T17:38:48.590+0000] {processor.py:186} INFO - Started process (PID=14780) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:48.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:38:48.592+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:48.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:48.614+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:38:48.640+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:48.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:38:48.654+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:38:48.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:38:48.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T17:39:18.782+0000] {processor.py:186} INFO - Started process (PID=14802) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:18.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:39:18.785+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:18.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:18.833+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:18.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:18.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:39:18.954+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:18.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:39:19.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.232 seconds
[2025-04-14T17:39:49.413+0000] {processor.py:186} INFO - Started process (PID=14824) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:49.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:39:49.418+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:49.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:49.443+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:39:49.469+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:49.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:39:49.491+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:39:49.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:39:49.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.291 seconds
[2025-04-14T17:40:20.154+0000] {processor.py:186} INFO - Started process (PID=14851) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:20.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:40:20.160+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:20.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:20.204+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:20.498+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:20.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:40:20.519+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:20.518+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:40:20.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.403 seconds
[2025-04-14T17:40:51.060+0000] {processor.py:186} INFO - Started process (PID=14902) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:51.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:40:51.342+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:51.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:51.364+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:40:51.396+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:51.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:40:51.410+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:40:51.409+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:40:51.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.382 seconds
[2025-04-14T17:41:21.631+0000] {processor.py:186} INFO - Started process (PID=14957) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:21.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:41:21.635+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:21.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:21.665+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:21.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:21.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:41:21.723+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:21.723+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:41:21.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.135 seconds
[2025-04-14T17:41:52.227+0000] {processor.py:186} INFO - Started process (PID=14979) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:52.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:41:52.232+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:52.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:52.266+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:41:52.317+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:52.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:41:52.350+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:41:52.350+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:41:52.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.184 seconds
[2025-04-14T17:42:22.833+0000] {processor.py:186} INFO - Started process (PID=15014) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:22.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:42:22.837+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:22.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:22.868+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:22.901+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:22.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:42:22.919+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:22.919+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:42:22.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.140 seconds
[2025-04-14T17:42:53.264+0000] {processor.py:186} INFO - Started process (PID=15042) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:53.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:42:53.268+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:53.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:53.294+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:42:53.326+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:53.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:42:53.345+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:42:53.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:42:53.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T17:43:23.567+0000] {processor.py:186} INFO - Started process (PID=15064) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:23.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:43:23.570+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:23.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:23.595+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:23.639+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:23.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:43:23.664+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:23.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:43:23.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T17:43:54.176+0000] {processor.py:186} INFO - Started process (PID=15101) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:54.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:43:54.181+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:54.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:54.211+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:43:54.239+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:54.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:43:54.256+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:43:54.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:43:54.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T17:44:24.378+0000] {processor.py:186} INFO - Started process (PID=15138) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:24.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:44:24.383+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:24.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:24.411+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:24.449+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:24.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:44:24.467+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:24.466+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:44:24.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.121 seconds
[2025-04-14T17:44:54.784+0000] {processor.py:186} INFO - Started process (PID=15191) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:54.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:44:54.795+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:54.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:54.834+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:44:54.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:54.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:44:54.903+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:44:54.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:44:54.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.157 seconds
[2025-04-14T17:45:25.420+0000] {processor.py:186} INFO - Started process (PID=15242) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:25.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:45:25.424+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:25.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:25.446+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:25.471+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:25.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:45:25.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:25.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:45:25.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:45:55.980+0000] {processor.py:186} INFO - Started process (PID=15298) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:55.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:45:55.983+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:55.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:56.010+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:45:56.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:56.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:45:56.057+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:45:56.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:45:56.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T17:46:26.497+0000] {processor.py:186} INFO - Started process (PID=15320) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:26.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:46:26.500+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:26.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:26.522+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:26.550+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:26.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:46:26.565+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:26.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:46:26.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T17:46:57.047+0000] {processor.py:186} INFO - Started process (PID=15342) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:57.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:46:57.052+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:57.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:57.101+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:46:57.145+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:57.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:46:57.170+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:46:57.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:46:57.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.162 seconds
[2025-04-14T17:47:27.435+0000] {processor.py:186} INFO - Started process (PID=15364) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:27.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:47:27.439+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:27.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:27.467+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:27.495+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:27.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:47:27.512+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:27.512+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:47:27.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T17:47:57.955+0000] {processor.py:186} INFO - Started process (PID=15386) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:57.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:47:57.959+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:57.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:57.983+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:47:58.009+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:58.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:47:58.023+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:47:58.023+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:47:58.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:48:28.180+0000] {processor.py:186} INFO - Started process (PID=15408) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:28.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:48:28.184+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:28.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:28.214+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:28.247+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:28.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:48:28.267+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:28.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:48:28.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.130 seconds
[2025-04-14T17:48:58.803+0000] {processor.py:186} INFO - Started process (PID=15431) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:58.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:48:58.806+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:58.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:58.834+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:48:58.868+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:58.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:48:58.888+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:48:58.887+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:48:58.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T17:49:29.368+0000] {processor.py:186} INFO - Started process (PID=15453) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:29.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:49:29.374+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:29.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:29.417+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:29.464+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:29.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:49:29.486+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:29.486+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:49:29.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.157 seconds
[2025-04-14T17:49:59.724+0000] {processor.py:186} INFO - Started process (PID=15475) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:59.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:49:59.731+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:59.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:59.776+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:49:59.813+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:59.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:49:59.836+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:49:59.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:49:59.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.156 seconds
[2025-04-14T17:50:30.027+0000] {processor.py:186} INFO - Started process (PID=15497) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:50:30.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:50:30.030+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:50:30.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:50:30.054+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:50:30.082+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:50:30.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:50:30.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:50:30.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:50:30.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T17:51:00.536+0000] {processor.py:186} INFO - Started process (PID=15519) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:00.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:51:00.539+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:00.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:00.563+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:00.591+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:00.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:51:00.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:00.609+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:51:00.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T17:51:31.317+0000] {processor.py:186} INFO - Started process (PID=15541) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:31.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:51:31.320+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:31.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:31.347+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:51:31.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:31.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:51:31.410+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:51:31.409+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:51:31.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.147 seconds
[2025-04-14T17:52:02.148+0000] {processor.py:186} INFO - Started process (PID=15563) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:02.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:52:02.157+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:02.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:02.193+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:02.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:02.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:52:02.256+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:02.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:52:02.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.149 seconds
[2025-04-14T17:52:32.503+0000] {processor.py:186} INFO - Started process (PID=15585) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:32.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:52:32.506+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:32.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:32.540+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:52:32.573+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:32.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:52:32.595+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:52:32.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:52:32.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T17:53:03.256+0000] {processor.py:186} INFO - Started process (PID=15607) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:03.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:53:03.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:03.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:03.284+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:03.349+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:03.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:53:03.393+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:03.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:53:03.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.200 seconds
[2025-04-14T17:53:34.086+0000] {processor.py:186} INFO - Started process (PID=15629) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:34.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:53:34.094+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:34.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:34.126+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:53:34.166+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:34.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:53:34.191+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:53:34.189+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:53:34.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.139 seconds
[2025-04-14T17:54:04.720+0000] {processor.py:186} INFO - Started process (PID=15651) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:04.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:54:04.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:04.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:04.751+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:04.782+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:04.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:54:04.802+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:04.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:54:04.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T17:54:35.830+0000] {processor.py:186} INFO - Started process (PID=15673) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:35.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:54:35.836+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:35.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:35.871+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:54:35.922+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:35.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:54:35.967+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:54:35.965+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:54:36.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.230 seconds
[2025-04-14T17:55:06.514+0000] {processor.py:186} INFO - Started process (PID=15695) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:06.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:55:06.517+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:06.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:06.540+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:06.566+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:06.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:55:06.581+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:06.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:55:06.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T17:55:37.182+0000] {processor.py:186} INFO - Started process (PID=15717) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:37.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:55:37.185+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:37.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:37.209+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:55:37.244+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:37.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:55:37.274+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:55:37.274+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:55:37.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T17:56:07.687+0000] {processor.py:186} INFO - Started process (PID=15739) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:07.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:56:07.690+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:07.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:07.713+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:07.740+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:07.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:56:07.755+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:07.755+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:56:07.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T17:56:38.048+0000] {processor.py:186} INFO - Started process (PID=15761) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:38.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:56:38.051+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:38.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:38.075+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:56:38.110+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:38.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:56:38.128+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:56:38.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:56:38.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T17:57:08.362+0000] {processor.py:186} INFO - Started process (PID=15783) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:08.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:57:08.366+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:08.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:08.407+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:08.452+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:08.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:57:08.478+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:08.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:57:08.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.159 seconds
[2025-04-14T17:57:38.994+0000] {processor.py:186} INFO - Started process (PID=15805) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:38.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:57:39.001+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:39.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:39.043+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:57:39.083+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:39.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:57:39.110+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:57:39.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:57:39.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.167 seconds
[2025-04-14T17:58:09.708+0000] {processor.py:186} INFO - Started process (PID=15827) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:09.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:58:09.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:09.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:09.735+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:09.762+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:09.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:58:09.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:09.779+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:58:09.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T17:58:40.274+0000] {processor.py:186} INFO - Started process (PID=15849) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:40.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:58:40.277+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:40.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:40.306+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:58:40.341+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:40.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:58:40.360+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:58:40.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:58:40.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T17:59:10.846+0000] {processor.py:186} INFO - Started process (PID=15871) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:10.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:59:10.850+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:10.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:10.882+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:10.919+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:10.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:59:10.940+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:10.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:59:10.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.131 seconds
[2025-04-14T17:59:41.207+0000] {processor.py:186} INFO - Started process (PID=15893) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:41.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T17:59:41.211+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:41.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:41.252+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T17:59:41.292+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:41.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T17:59:41.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T17:59:41.311+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T17:59:41.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.145 seconds
[2025-04-14T18:00:11.851+0000] {processor.py:186} INFO - Started process (PID=15915) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:11.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:00:11.859+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:11.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:11.908+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:11.937+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:11.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:00:11.955+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:11.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:00:11.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.136 seconds
[2025-04-14T18:00:42.483+0000] {processor.py:186} INFO - Started process (PID=15937) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:42.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:00:42.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:42.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:42.511+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:00:42.540+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:42.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:00:42.558+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:00:42.558+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:00:42.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T18:01:12.946+0000] {processor.py:186} INFO - Started process (PID=15959) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:12.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:01:12.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:12.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:12.974+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:13.000+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:12.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:01:13.017+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:13.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:01:13.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T18:01:43.226+0000] {processor.py:186} INFO - Started process (PID=15981) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:43.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:01:43.229+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:43.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:43.252+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:01:43.279+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:43.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:01:43.294+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:01:43.294+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:01:43.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:02:13.419+0000] {processor.py:186} INFO - Started process (PID=16003) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:13.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:02:13.423+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:13.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:13.452+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:13.483+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:13.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:02:13.501+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:13.501+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:02:13.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T18:02:43.695+0000] {processor.py:186} INFO - Started process (PID=16025) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:43.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:02:43.699+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:43.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:43.722+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:02:43.750+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:43.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:02:43.767+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:02:43.766+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:02:43.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T18:03:14.338+0000] {processor.py:186} INFO - Started process (PID=16047) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:14.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:03:14.342+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:14.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:14.367+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:14.399+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:14.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:03:14.417+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:14.416+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:03:14.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T18:03:44.721+0000] {processor.py:186} INFO - Started process (PID=16069) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:44.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:03:44.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:44.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:44.747+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:03:44.794+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:44.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:03:44.827+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:03:44.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:03:44.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.169 seconds
[2025-04-14T18:04:15.070+0000] {processor.py:186} INFO - Started process (PID=16091) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:15.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:04:15.074+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:15.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:15.100+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:15.135+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:15.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:04:15.155+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:15.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:04:15.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.140 seconds
[2025-04-14T18:04:45.671+0000] {processor.py:186} INFO - Started process (PID=16107) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:45.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:04:45.675+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:45.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:45.701+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:04:45.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:45.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:04:45.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:04:45.746+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:04:45.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T18:05:16.274+0000] {processor.py:186} INFO - Started process (PID=16129) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:16.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:05:16.277+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:16.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:16.306+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:16.336+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:16.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:05:16.352+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:16.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:05:16.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T18:05:46.529+0000] {processor.py:186} INFO - Started process (PID=16151) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:46.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:05:46.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:46.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:46.556+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:05:46.588+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:46.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:05:46.608+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:05:46.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:05:46.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T18:06:17.130+0000] {processor.py:186} INFO - Started process (PID=16173) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:17.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:06:17.135+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:17.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:17.160+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:17.188+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:17.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:06:17.203+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:17.203+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:06:17.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T18:06:47.325+0000] {processor.py:186} INFO - Started process (PID=16195) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:47.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:06:47.330+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:47.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:47.355+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:06:47.384+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:47.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:06:47.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:06:47.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:06:47.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T18:07:17.993+0000] {processor.py:186} INFO - Started process (PID=16217) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:17.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:07:17.996+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:17.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:18.020+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:18.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:18.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:07:18.061+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:18.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:07:18.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:07:48.165+0000] {processor.py:186} INFO - Started process (PID=16239) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:48.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:07:48.168+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:48.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:48.191+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:07:48.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:48.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:07:48.240+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:07:48.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:07:48.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.106 seconds
[2025-04-14T18:08:18.652+0000] {processor.py:186} INFO - Started process (PID=16261) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:18.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:08:18.656+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:18.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:18.679+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:18.706+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:18.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:08:18.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:18.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:08:18.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T18:08:49.138+0000] {processor.py:186} INFO - Started process (PID=16284) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:49.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:08:49.141+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:49.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:49.164+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:08:49.191+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:49.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:08:49.207+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:08:49.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:08:49.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:09:19.757+0000] {processor.py:186} INFO - Started process (PID=16306) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:19.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:09:19.760+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:19.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:19.784+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:19.820+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:19.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:09:19.841+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:19.840+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:09:19.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.115 seconds
[2025-04-14T18:09:50.292+0000] {processor.py:186} INFO - Started process (PID=16329) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:50.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:09:50.295+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:50.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:50.321+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:09:50.347+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:50.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:09:50.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:09:50.361+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:09:50.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:10:20.806+0000] {processor.py:186} INFO - Started process (PID=16352) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:20.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:10:20.809+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:20.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:20.835+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:20.865+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:20.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:10:20.883+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:20.882+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:10:20.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T18:10:51.159+0000] {processor.py:186} INFO - Started process (PID=16374) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:51.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:10:51.162+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:51.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:51.192+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:10:51.219+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:51.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:10:51.235+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:10:51.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:10:51.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T18:11:21.426+0000] {processor.py:186} INFO - Started process (PID=16396) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:21.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:11:21.430+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:21.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:21.455+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:21.482+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:21.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:11:21.497+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:21.497+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:11:21.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:11:51.717+0000] {processor.py:186} INFO - Started process (PID=16418) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:51.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:11:51.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:51.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:51.777+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:11:51.830+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:51.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:11:51.860+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:11:51.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:11:51.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.196 seconds
[2025-04-14T18:12:22.269+0000] {processor.py:186} INFO - Started process (PID=16440) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:22.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:12:22.271+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:22.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:22.313+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:22.352+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:22.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:12:22.383+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:22.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:12:22.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.156 seconds
[2025-04-14T18:12:53.200+0000] {processor.py:186} INFO - Started process (PID=16463) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:53.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:12:53.207+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:53.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:53.256+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:12:53.302+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:53.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:12:53.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:12:53.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:12:53.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.181 seconds
[2025-04-14T18:13:23.660+0000] {processor.py:186} INFO - Started process (PID=16485) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:23.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:13:23.667+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:23.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:23.697+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:23.735+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:23.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:13:23.761+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:23.760+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:13:23.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.141 seconds
[2025-04-14T18:13:53.938+0000] {processor.py:186} INFO - Started process (PID=16513) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:53.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:13:53.941+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:53.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:53.967+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:13:54.014+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:54.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:13:54.037+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:13:54.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:13:54.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T18:14:24.686+0000] {processor.py:186} INFO - Started process (PID=16535) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:24.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:14:24.689+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:24.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:24.714+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:24.745+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:24.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:14:24.764+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:24.764+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:14:24.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.114 seconds
[2025-04-14T18:14:54.863+0000] {processor.py:186} INFO - Started process (PID=16557) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:54.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:14:54.865+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:54.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:54.886+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:14:54.916+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:54.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:14:54.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:14:54.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:14:54.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T18:15:25.095+0000] {processor.py:186} INFO - Started process (PID=16579) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:25.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:15:25.098+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:25.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:25.122+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:25.153+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:25.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:15:25.172+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:25.172+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:15:25.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T18:15:55.348+0000] {processor.py:186} INFO - Started process (PID=16601) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:55.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:15:55.351+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:55.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:55.389+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:15:55.432+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:55.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:15:55.459+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:15:55.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:15:55.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.148 seconds
[2025-04-14T18:16:25.656+0000] {processor.py:186} INFO - Started process (PID=16623) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:25.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:16:25.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:25.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:25.683+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:25.709+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:25.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:16:25.724+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:25.724+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:16:25.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:16:55.807+0000] {processor.py:186} INFO - Started process (PID=16645) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:55.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:16:55.811+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:55.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:55.838+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:16:55.870+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:55.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:16:55.889+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:16:55.889+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:16:55.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T18:17:26.484+0000] {processor.py:186} INFO - Started process (PID=16667) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:26.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:17:26.487+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:26.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:26.512+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:26.537+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:26.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:17:26.552+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:26.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:17:26.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T18:17:57.300+0000] {processor.py:186} INFO - Started process (PID=16689) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:57.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:17:57.309+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:57.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:57.349+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:17:57.383+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:57.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:17:57.406+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:17:57.406+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:17:57.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.158 seconds
[2025-04-14T18:18:27.898+0000] {processor.py:186} INFO - Started process (PID=16711) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:27.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:18:27.902+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:27.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:27.935+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:27.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:27.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:18:28.004+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:28.003+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:18:28.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.157 seconds
[2025-04-14T18:18:58.415+0000] {processor.py:186} INFO - Started process (PID=16733) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:58.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:18:58.418+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:58.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:58.440+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:18:58.468+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:58.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:18:58.485+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:18:58.485+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:18:58.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:19:28.775+0000] {processor.py:186} INFO - Started process (PID=16755) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:28.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:19:28.780+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:28.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:28.805+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:28.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:28.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:19:28.847+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:28.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:19:28.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.101 seconds
[2025-04-14T18:19:58.950+0000] {processor.py:186} INFO - Started process (PID=16777) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:58.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:19:58.956+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:58.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:58.982+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:19:59.015+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:59.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:19:59.036+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:19:59.035+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:19:59.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.126 seconds
[2025-04-14T18:20:29.308+0000] {processor.py:186} INFO - Started process (PID=16799) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:29.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:20:29.311+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:29.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:29.339+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:29.367+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:29.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:20:29.383+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:29.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:20:29.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T18:20:59.909+0000] {processor.py:186} INFO - Started process (PID=16821) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:59.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:20:59.913+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:59.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:59.950+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:20:59.980+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:59.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:20:59.998+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:20:59.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:21:00.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.127 seconds
[2025-04-14T18:21:30.097+0000] {processor.py:186} INFO - Started process (PID=16843) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:21:30.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:21:30.100+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:21:30.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:21:30.124+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:21:30.149+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:21:30.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:21:30.164+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:21:30.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:21:30.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T18:22:00.654+0000] {processor.py:186} INFO - Started process (PID=16865) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:00.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:22:00.657+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:00.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:00.684+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:00.712+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:00.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:22:00.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:00.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:22:00.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T18:22:30.870+0000] {processor.py:186} INFO - Started process (PID=16887) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:30.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:22:30.874+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:30.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:30.910+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:22:30.953+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:30.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:22:30.975+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:22:30.974+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:22:31.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.143 seconds
[2025-04-14T18:23:01.529+0000] {processor.py:186} INFO - Started process (PID=16909) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:01.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:23:01.532+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:01.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:01.554+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:01.581+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:01.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:23:01.596+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:01.596+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:23:01.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T18:23:31.754+0000] {processor.py:186} INFO - Started process (PID=16931) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:31.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:23:31.757+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:31.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:31.788+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:23:31.824+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:31.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:23:31.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:23:31.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:23:31.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.133 seconds
[2025-04-14T18:24:02.354+0000] {processor.py:186} INFO - Started process (PID=16953) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:02.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:24:02.357+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:02.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:02.381+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:02.409+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:02.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:24:02.425+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:02.425+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:24:02.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T18:24:32.866+0000] {processor.py:186} INFO - Started process (PID=16975) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:32.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:24:32.869+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:32.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:32.896+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:24:32.923+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:32.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:24:32.938+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:24:32.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:24:32.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.102 seconds
[2025-04-14T18:25:03.108+0000] {processor.py:186} INFO - Started process (PID=16997) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:03.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:25:03.111+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:03.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:03.150+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:03.194+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:03.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:25:03.222+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:03.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:25:03.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.168 seconds
[2025-04-14T18:25:33.700+0000] {processor.py:186} INFO - Started process (PID=17019) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:33.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:25:33.703+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:33.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:33.728+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:25:33.757+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:33.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:25:33.781+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:25:33.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:25:33.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T18:26:04.239+0000] {processor.py:186} INFO - Started process (PID=17035) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:04.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:26:04.245+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:04.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:04.274+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:04.308+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:04.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:26:04.341+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:04.341+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:26:04.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.138 seconds
[2025-04-14T18:26:34.532+0000] {processor.py:186} INFO - Started process (PID=17057) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:34.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:26:34.536+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:34.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:34.564+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:26:34.598+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:34.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:26:34.616+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:26:34.616+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:26:34.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T18:27:04.831+0000] {processor.py:186} INFO - Started process (PID=17080) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:04.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:27:04.835+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:04.865+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:04.896+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:27:04.918+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:27:04.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.124 seconds
[2025-04-14T18:27:35.410+0000] {processor.py:186} INFO - Started process (PID=17102) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:35.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:27:35.413+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:35.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:35.438+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:27:35.463+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:35.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:27:35.478+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:27:35.478+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:27:35.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:28:05.969+0000] {processor.py:186} INFO - Started process (PID=17124) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:05.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:28:05.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:05.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:06.011+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:06.049+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:06.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:28:06.067+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:06.067+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:28:06.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.134 seconds
[2025-04-14T18:28:36.245+0000] {processor.py:186} INFO - Started process (PID=17146) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:36.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:28:36.248+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:36.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:36.274+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:28:36.299+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:36.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:28:36.314+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:28:36.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:28:36.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:29:06.744+0000] {processor.py:186} INFO - Started process (PID=17168) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:06.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:29:06.747+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:06.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:06.772+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:06.799+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:06.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:29:06.821+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:06.820+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:29:06.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T18:29:37.296+0000] {processor.py:186} INFO - Started process (PID=17190) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:37.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:29:37.300+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:37.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:37.328+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:29:37.354+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:37.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:29:37.371+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:29:37.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:29:37.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T18:30:08.256+0000] {processor.py:186} INFO - Started process (PID=17212) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:08.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:30:08.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:08.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:08.284+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:08.309+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:08.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:30:08.324+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:08.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:30:08.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:30:38.764+0000] {processor.py:186} INFO - Started process (PID=17234) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:38.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:30:38.767+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:38.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:38.788+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:30:38.814+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:38.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:30:38.832+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:30:38.832+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:30:38.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T18:31:08.961+0000] {processor.py:186} INFO - Started process (PID=17256) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:08.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:31:08.964+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:08.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:08.987+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:09.018+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:09.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:31:09.036+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:09.035+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:31:09.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T18:31:39.603+0000] {processor.py:186} INFO - Started process (PID=17278) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:39.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:31:39.608+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:39.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:39.638+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:31:39.688+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:39.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:31:39.719+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:31:39.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:31:39.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.164 seconds
[2025-04-14T18:32:09.946+0000] {processor.py:186} INFO - Started process (PID=17300) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:09.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:32:09.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:09.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:09.991+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:10.031+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:10.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:32:10.055+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:10.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:32:10.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.152 seconds
[2025-04-14T18:32:40.266+0000] {processor.py:186} INFO - Started process (PID=17322) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:40.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:32:40.271+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:40.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:40.302+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:32:40.335+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:40.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:32:40.361+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:32:40.361+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:32:40.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.147 seconds
[2025-04-14T18:33:11.314+0000] {processor.py:186} INFO - Started process (PID=17344) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:11.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:33:11.317+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:11.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:11.339+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:11.364+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:11.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:33:11.379+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:11.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:33:11.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.093 seconds
[2025-04-14T18:33:41.846+0000] {processor.py:186} INFO - Started process (PID=17366) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:41.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:33:41.849+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:41.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:41.879+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:33:41.915+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:41.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:33:41.934+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:33:41.934+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:33:41.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.120 seconds
[2025-04-14T18:34:12.089+0000] {processor.py:186} INFO - Started process (PID=17388) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:12.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:34:12.092+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:12.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:12.120+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:12.151+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:12.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:34:12.169+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:12.169+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:34:12.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.112 seconds
[2025-04-14T18:34:42.270+0000] {processor.py:186} INFO - Started process (PID=17410) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:42.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:34:42.273+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:42.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:42.297+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:34:42.323+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:42.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:34:42.337+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:34:42.337+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:34:42.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T18:35:12.820+0000] {processor.py:186} INFO - Started process (PID=17432) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:12.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:35:12.822+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:12.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:12.850+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:12.879+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:12.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:35:12.898+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:12.897+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:35:12.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.109 seconds
[2025-04-14T18:35:43.188+0000] {processor.py:186} INFO - Started process (PID=17454) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:43.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:35:43.191+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:43.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:43.216+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:35:43.243+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:43.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:35:43.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:35:43.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:35:43.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.100 seconds
[2025-04-14T18:36:13.868+0000] {processor.py:186} INFO - Started process (PID=17476) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:13.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:36:13.871+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:13.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:13.909+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:13.952+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:13.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:36:13.980+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:13.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:36:14.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.153 seconds
[2025-04-14T18:36:44.199+0000] {processor.py:186} INFO - Started process (PID=17498) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:44.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:36:44.202+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:44.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:44.229+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:36:44.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:44.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:36:44.274+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:36:44.274+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:36:44.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.111 seconds
[2025-04-14T18:37:14.430+0000] {processor.py:186} INFO - Started process (PID=17520) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:14.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:37:14.433+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:14.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:14.461+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:14.494+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:14.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:37:14.511+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:14.511+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:37:14.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T18:37:44.971+0000] {processor.py:186} INFO - Started process (PID=17542) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:44.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:37:44.974+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:44.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:44.998+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:37:45.027+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:45.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:37:45.044+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:37:45.043+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:37:45.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.107 seconds
[2025-04-14T18:38:15.256+0000] {processor.py:186} INFO - Started process (PID=17564) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:15.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:38:15.259+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:15.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:15.280+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:15.306+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:15.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:38:15.321+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:15.321+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:38:15.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.095 seconds
[2025-04-14T18:38:45.684+0000] {processor.py:186} INFO - Started process (PID=17586) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:45.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:38:45.687+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:45.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:45.708+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:38:45.736+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:45.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:38:45.763+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:38:45.763+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:38:45.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T18:39:15.891+0000] {processor.py:186} INFO - Started process (PID=17608) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:15.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:39:15.895+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:15.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:15.920+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:15.950+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:15.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:39:15.971+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:15.971+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:39:15.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.118 seconds
[2025-04-14T18:39:46.506+0000] {processor.py:186} INFO - Started process (PID=17630) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:46.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:39:46.509+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:46.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:46.533+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:39:46.559+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:46.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:39:46.574+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:39:46.574+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:39:46.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T18:40:17.042+0000] {processor.py:186} INFO - Started process (PID=17652) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:17.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:40:17.045+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:17.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:17.069+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:17.096+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:17.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:40:17.112+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:17.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:40:17.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T18:40:47.567+0000] {processor.py:186} INFO - Started process (PID=17674) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:47.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:40:47.570+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:47.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:47.592+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:40:47.619+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:47.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:40:47.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:40:47.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:40:47.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T18:41:18.114+0000] {processor.py:186} INFO - Started process (PID=17696) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:18.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:41:18.117+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:18.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:18.142+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:18.167+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:18.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:41:18.182+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:18.181+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:41:18.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:41:48.606+0000] {processor.py:186} INFO - Started process (PID=17718) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:48.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:41:48.609+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:48.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:48.634+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:41:48.661+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:48.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:41:48.680+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:41:48.680+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:41:48.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.103 seconds
[2025-04-14T18:42:19.111+0000] {processor.py:186} INFO - Started process (PID=17740) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:19.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:42:19.115+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:19.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:19.140+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:19.170+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:19.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:42:19.188+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:19.188+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:42:19.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.110 seconds
[2025-04-14T18:42:49.623+0000] {processor.py:186} INFO - Started process (PID=17762) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:49.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:42:49.626+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:49.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:49.649+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:42:49.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:49.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:42:49.692+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:42:49.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:42:49.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T18:43:20.124+0000] {processor.py:186} INFO - Started process (PID=17784) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:20.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:43:20.127+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:20.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:20.151+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:20.177+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:20.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:43:20.191+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:20.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:43:20.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:43:50.328+0000] {processor.py:186} INFO - Started process (PID=17806) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:50.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:43:50.333+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:50.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:50.366+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:43:50.396+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:50.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:43:50.414+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:43:50.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:43:50.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T18:44:21.049+0000] {processor.py:186} INFO - Started process (PID=17828) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:21.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:44:21.053+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:21.076+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:21.102+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:44:21.116+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.115+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:44:21.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:44:51.589+0000] {processor.py:186} INFO - Started process (PID=17850) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:51.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:44:51.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:51.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:51.615+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:44:51.641+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:51.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:44:51.655+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:44:51.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:44:51.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.094 seconds
[2025-04-14T18:45:21.845+0000] {processor.py:186} INFO - Started process (PID=17872) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:21.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:45:21.848+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:21.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:21.873+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:21.908+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:21.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:45:21.924+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:21.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:45:21.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.113 seconds
[2025-04-14T18:45:52.335+0000] {processor.py:186} INFO - Started process (PID=17894) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:52.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:45:52.338+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:52.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:52.361+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:45:52.399+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:52.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:45:52.419+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:45:52.418+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:45:52.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.123 seconds
[2025-04-14T18:46:22.838+0000] {processor.py:186} INFO - Started process (PID=17916) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:22.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:46:22.841+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:22.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:22.863+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:22.891+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:22.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:46:22.906+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:22.906+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:46:22.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.099 seconds
[2025-04-14T18:46:53.400+0000] {processor.py:186} INFO - Started process (PID=17938) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:53.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:46:53.403+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:53.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:53.431+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:46:53.460+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:53.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:46:53.477+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:46:53.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:46:53.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.108 seconds
[2025-04-14T18:47:23.590+0000] {processor.py:186} INFO - Started process (PID=17960) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:23.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:47:23.593+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:23.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:23.617+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:23.650+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:23.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:47:23.671+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:23.671+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:47:23.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.116 seconds
[2025-04-14T18:47:54.125+0000] {processor.py:186} INFO - Started process (PID=17982) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:54.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:47:54.128+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:54.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:54.161+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:47:54.203+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:54.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:47:54.225+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:47:54.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:47:54.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.140 seconds
[2025-04-14T18:48:24.632+0000] {processor.py:186} INFO - Started process (PID=18004) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:24.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:48:24.634+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:24.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:24.658+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:24.690+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:24.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:48:24.707+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:24.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:48:24.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T18:48:55.187+0000] {processor.py:186} INFO - Started process (PID=18026) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:55.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:48:55.189+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:55.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:55.214+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:48:55.242+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:55.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:48:55.257+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:48:55.257+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:48:55.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.097 seconds
[2025-04-14T18:49:25.660+0000] {processor.py:186} INFO - Started process (PID=18048) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:25.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:49:25.663+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:25.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:25.688+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:25.714+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:25.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:49:25.728+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:25.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:49:25.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.096 seconds
[2025-04-14T18:49:56.168+0000] {processor.py:186} INFO - Started process (PID=18071) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:56.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:49:56.170+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:56.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:56.194+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:49:56.220+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:56.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:49:56.237+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:49:56.237+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:49:56.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.098 seconds
[2025-04-14T18:50:26.666+0000] {processor.py:186} INFO - Started process (PID=18087) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:26.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:50:26.669+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:26.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:26.691+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:26.720+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:26.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:50:26.737+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:26.737+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:50:26.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.105 seconds
[2025-04-14T18:50:57.238+0000] {processor.py:186} INFO - Started process (PID=18109) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:57.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:50:57.244+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:57.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:57.273+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:50:57.329+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:57.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:50:57.355+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:50:57.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:50:57.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.172 seconds
[2025-04-14T18:51:28.072+0000] {processor.py:186} INFO - Started process (PID=18131) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:28.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:51:28.076+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:28.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:28.103+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:28.136+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:28.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:51:28.156+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:28.156+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:51:28.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.117 seconds
[2025-04-14T18:51:58.605+0000] {processor.py:186} INFO - Started process (PID=18153) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:58.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:51:58.608+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:58.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:58.631+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:51:58.659+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:58.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:51:58.676+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:51:58.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:51:58.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.104 seconds
[2025-04-14T18:52:28.833+0000] {processor.py:186} INFO - Started process (PID=18239) to work on /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:52:28.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job/spark_job.py for tasks to queue
[2025-04-14T18:52:28.838+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:52:28.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:52:28.866+0000] {processor.py:925} INFO - DAG(s) 'spark_csv_to_bigquery' retrieved from /opt/airflow/dags/spark_job/spark_job.py
[2025-04-14T18:52:28.908+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:52:28.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:52:28.936+0000] {logging_mixin.py:190} INFO - [2025-04-14T18:52:28.935+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_csv_to_bigquery to None, run_after=None
[2025-04-14T18:52:28.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job/spark_job.py took 0.146 seconds
